<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/4cf2300e9c8272f7-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/de70bee13400563f.css?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/7da0a892b4ad83db.css?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-5400bf868d87f903.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7"/><script src="/_next/static/chunks/87c73c54-dd8d81ac9604067c.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/18-2224119117d14cba.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/main-app-57aa1716f0d0f500.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/b1298b8d-5cac6cd7c8e952ff.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/378e5a93-860e027c5a5e0c0d.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/f7f68e2d-d8bf979db5ff4e9d.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/7963-b29c27a8b53c3f2a.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/1265-fa8a95d3842768f5.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/9885-b57089f03806c3b8.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/659-ee9e1e775e30dcef.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/app/layout-0537c2076823e553.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/7bf36345-1ac10ec2f0e0c88f.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/c16f53c3-b390b6f98a69dcec.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/6212-505c2fc95d1a35ae.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/4336-624d5ae6f4cc1cc7.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/8461-369a9f0c48ea2626.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/7198-985a49f2b6072d25.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/5462-08221e91030fd747.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/4429-943205658cbafffe.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/9976-9250854d58eefaa3.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/1481-25d5bbc4f2d9524a.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/app/%5Borg%5D/%5Brepo%5D/%5B%5B...wikiRoutes%5D%5D/page-6651f8cd8321a0db.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/25-9f305b682cea7558.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/7391-f64e18878e224268.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/6373-d56a493968555802.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/6375-7e0e75eb09fc9abe.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/9437-be873d1907eef4d4.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><script src="/_next/static/chunks/app/%5Borg%5D/%5Brepo%5D/layout-77683f6369c5b39e.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" async=""></script><meta name="next-size-adjust" content=""/><title>EOEPCA/document-mlops | DeepWiki</title><meta name="description" content="This document provides an overview of the EOEPCA MLOps Building Block, introducing its purpose, core components, and high-level capabilities. It is intended for technical audiences seeking to understa"/><meta name="keywords" content="EOEPCA/document-mlops,EOEPCA,document-mlops,documentation,wiki,codebase,AI documentation,Devin,Overview"/><link rel="canonical" href="https://deepwiki.com/EOEPCA/document-mlops"/><meta property="og:title" content="EOEPCA/document-mlops | DeepWiki"/><meta property="og:description" content="This document provides an overview of the EOEPCA MLOps Building Block, introducing its purpose, core components, and high-level capabilities. It is intended for technical audiences seeking to understa"/><meta property="og:url" content="https://deepwiki.com/EOEPCA/document-mlops"/><meta property="og:site_name" content="DeepWiki"/><meta property="og:image" content="https://deepwiki.com/EOEPCA/document-mlops/og-image.png?page=1"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@cognition"/><meta name="twitter:creator" content="@cognition"/><meta name="twitter:title" content="EOEPCA/document-mlops | DeepWiki"/><meta name="twitter:description" content="This document provides an overview of the EOEPCA MLOps Building Block, introducing its purpose, core components, and high-level capabilities. It is intended for technical audiences seeking to understa"/><meta name="twitter:image" content="https://deepwiki.com/EOEPCA/document-mlops/og-image.png?page=1"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="48x48"/><link rel="icon" href="/icon.png?1ee4c6a68a73a205" type="image/png" sizes="48x48"/><link rel="apple-touch-icon" href="/apple-icon.png?a4f658907db0ab87" type="image/png" sizes="180x180"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" noModule=""></script></head><body class="__variable_188709 font-geist-sans relative min-h-screen __variable_9a8899 bg-background antialiased"><div hidden=""><!--$--><!--/$--></div><section aria-label="Notifications alt+T" tabindex="-1" aria-live="polite" aria-relevant="additions text" aria-atomic="false"></section><script>((a,b,c,d,e,f,g,h)=>{let i=document.documentElement,j=["light","dark"];function k(b){var c;(Array.isArray(a)?a:[a]).forEach(a=>{let c="class"===a,d=c&&f?e.map(a=>f[a]||a):e;c?(i.classList.remove(...d),i.classList.add(f&&f[b]?f[b]:b)):i.setAttribute(a,b)}),c=b,h&&j.includes(c)&&(i.style.colorScheme=c)}if(d)k(d);else try{let a=localStorage.getItem(b)||c,d=g&&"system"===a?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":a;k(d)}catch(a){}})("class","theme","light",null,["light","dark"],null,true,true)</script><!--$?--><template id="B:0"></template><div class="flex min-h-screen w-full flex-col text-white"><div class="container-wrapper flex flex-1 items-center justify-center px-4"><div class="inline-block bg-clip-text text-[#b5b5b5a4] animate-shine text-center text-lg" style="background-image:linear-gradient(120deg, rgba(255, 255, 255, 0) 40%, rgba(255, 255, 255, 0.8) 50%, rgba(255, 255, 255, 0) 60%);background-size:200% 100%;-webkit-background-clip:text;animation-duration:1s">Loading...</div></div></div><!--/$--><script>requestAnimationFrame(function(){$RT=performance.now()});</script><script src="/_next/static/chunks/webpack-5400bf868d87f903.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7" id="_R_" async=""></script><div hidden id="S:0"><div class="flex min-h-screen w-full flex-col text-white" id="codebase-wiki-repo-page"><div class="bg-background border-b-border sticky top-0 z-30 border-b border-dashed"><div class="font-geist-mono relative flex h-8 items-center justify-center text-xs font-medium sm:hidden"><div class="powered-by-devin-gradient absolute inset-0 z-[-1] h-8 w-full"></div><button class="flex items-center gap-2"><svg class="size-3 [&amp;_path]:stroke-0 [&amp;_path]:animate-[custom-pulse_1.8s_infinite_var(--delay,0s)]" xmlns="http://www.w3.org/2000/svg" viewBox="110 110 460 500"><path style="fill:#21c19a" class="[--delay:0.6s]" d="M418.73,332.37c9.84-5.68,22.07-5.68,31.91,0l25.49,14.71c.82.48,1.69.8,2.58,1.06.19.06.37.11.55.16.87.21,1.76.34,2.65.35.04,0,.08.02.13.02.1,0,.19-.03.29-.04.83-.02,1.64-.13,2.45-.32.14-.03.28-.05.42-.09.87-.24,1.7-.59,2.5-1.03.08-.04.17-.06.25-.1l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22l-50.97-29.43c-3.65-2.11-8.15-2.11-11.81,0l-50.97,29.43c-.08.04-.13.11-.2.16-.78.48-1.51,1.02-2.15,1.66-.1.1-.18.21-.28.31-.57.6-1.08,1.26-1.51,1.97-.07.12-.15.22-.22.34-.44.77-.77,1.6-1.03,2.47-.05.19-.1.37-.14.56-.22.89-.37,1.81-.37,2.76v29.43c0,11.36-6.11,21.95-15.95,27.63-9.84,5.68-22.06,5.68-31.91,0l-25.49-14.71c-.82-.48-1.69-.8-2.57-1.06-.19-.06-.37-.11-.56-.16-.88-.21-1.76-.34-2.65-.34-.13,0-.26.02-.4.02-.84.02-1.66.13-2.47.32-.13.03-.27.05-.4.09-.87.24-1.71.6-2.51,1.04-.08.04-.16.06-.24.1l-50.97,29.43c-3.65,2.11-5.9,6.01-5.9,10.22v58.86c0,4.22,2.25,8.11,5.9,10.22l50.97,29.43c.08.04.17.06.24.1.8.44,1.64.79,2.5,1.03.14.04.28.06.42.09.81.19,1.62.3,2.45.32.1,0,.19.04.29.04.04,0,.08-.02.13-.02.89,0,1.77-.13,2.65-.35.19-.04.37-.1.56-.16.88-.26,1.75-.59,2.58-1.06l25.49-14.71c9.84-5.68,22.06-5.68,31.91,0,9.84,5.68,15.95,16.27,15.95,27.63v29.43c0,.95.15,1.87.37,2.76.05.19.09.37.14.56.25.86.59,1.69,1.03,2.47.07.12.15.22.22.34.43.71.94,1.37,1.51,1.97.1.1.18.21.28.31.65.63,1.37,1.18,2.15,1.66.07.04.13.11.2.16l50.97,29.43c1.83,1.05,3.86,1.58,5.9,1.58s4.08-.53,5.9-1.58l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22l-50.97-29.43c-.08-.04-.16-.06-.24-.1-.8-.44-1.64-.8-2.51-1.04-.13-.04-.26-.05-.39-.09-.82-.2-1.65-.31-2.49-.33-.13,0-.25-.02-.38-.02-.89,0-1.78.13-2.66.35-.18.04-.36.1-.54.15-.88.26-1.75.59-2.58,1.07l-25.49,14.72c-9.84,5.68-22.07,5.68-31.9,0-9.84-5.68-15.95-16.27-15.95-27.63s6.11-21.95,15.95-27.63Z"></path><path style="fill:#3969ca" d="M141.09,317.65l50.97,29.43c1.83,1.05,3.86,1.58,5.9,1.58s4.08-.53,5.9-1.58l50.97-29.43c.08-.04.13-.11.2-.16.78-.48,1.51-1.02,2.15-1.66.1-.1.18-.21.28-.31.57-.6,1.08-1.26,1.51-1.97.07-.12.15-.22.22-.34.44-.77.77-1.6,1.03-2.47.05-.19.1-.37.14-.56.22-.89.37-1.81.37-2.76v-29.43c0-11.36,6.11-21.95,15.96-27.63s22.06-5.68,31.91,0l25.49,14.71c.82.48,1.69.8,2.57,1.06.19.06.37.11.56.16.87.21,1.76.34,2.64.35.04,0,.09.02.13.02.1,0,.19-.04.29-.04.83-.02,1.65-.13,2.45-.32.14-.03.28-.05.41-.09.87-.24,1.71-.6,2.51-1.04.08-.04.16-.06.24-.1l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22l-50.97-29.43c-3.65-2.11-8.15-2.11-11.81,0l-50.97,29.43c-.08.04-.13.11-.2.16-.78.48-1.51,1.02-2.15,1.66-.1.1-.18.21-.28.31-.57.6-1.08,1.26-1.51,1.97-.07.12-.15.22-.22.34-.44.77-.77,1.6-1.03,2.47-.05.19-.1.37-.14.56-.22.89-.37,1.81-.37,2.76v29.43c0,11.36-6.11,21.95-15.95,27.63-9.84,5.68-22.07,5.68-31.91,0l-25.49-14.71c-.82-.48-1.69-.8-2.58-1.06-.19-.06-.37-.11-.55-.16-.88-.21-1.76-.34-2.65-.35-.13,0-.26.02-.4.02-.83.02-1.66.13-2.47.32-.13.03-.27.05-.4.09-.87.24-1.71.6-2.51,1.04-.08.04-.16.06-.24.1l-50.97,29.43c-3.65,2.11-5.9,6.01-5.9,10.22v58.86c0,4.22,2.25,8.11,5.9,10.22Z"></path><path style="fill:#0294de" class="[--delay:1.2s]" d="M396.88,484.35l-50.97-29.43c-.08-.04-.17-.06-.24-.1-.8-.44-1.64-.79-2.51-1.03-.14-.04-.27-.06-.41-.09-.81-.19-1.64-.3-2.47-.32-.13,0-.26-.02-.39-.02-.89,0-1.78.13-2.66.35-.18.04-.36.1-.54.15-.88.26-1.76.59-2.58,1.07l-25.49,14.72c-9.84,5.68-22.06,5.68-31.9,0-9.84-5.68-15.96-16.27-15.96-27.63v-29.43c0-.95-.15-1.87-.37-2.76-.05-.19-.09-.37-.14-.56-.25-.86-.59-1.69-1.03-2.47-.07-.12-.15-.22-.22-.34-.43-.71-.94-1.37-1.51-1.97-.1-.1-.18-.21-.28-.31-.65-.63-1.37-1.18-2.15-1.66-.07-.04-.13-.11-.2-.16l-50.97-29.43c-3.65-2.11-8.15-2.11-11.81,0l-50.97,29.43c-3.65,2.11-5.9,6.01-5.9,10.22v58.86c0,4.22,2.25,8.11,5.9,10.22l50.97,29.43c.08.04.17.06.25.1.8.44,1.63.79,2.5,1.03.14.04.29.06.43.09.8.19,1.61.3,2.43.32.1,0,.2.04.3.04.04,0,.09-.02.13-.02.88,0,1.77-.13,2.64-.34.19-.04.37-.1.56-.16.88-.26,1.75-.59,2.57-1.06l25.49-14.71c9.84-5.68,22.06-5.68,31.91,0,9.84,5.68,15.95,16.27,15.95,27.63v29.43c0,.95.15,1.87.37,2.76.05.19.09.37.14.56.25.86.59,1.69,1.03,2.47.07.12.15.22.22.34.43.71.94,1.37,1.51,1.97.1.1.18.21.28.31.65.63,1.37,1.18,2.15,1.66.07.04.13.11.2.16l50.97,29.43c1.83,1.05,3.86,1.58,5.9,1.58s4.08-.53,5.9-1.58l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22Z"></path></svg>Index your code with Devin</button></div><div class="container-wrapper"><div class="container mx-auto flex w-full flex-row items-center gap-2 py-4 md:py-6"><a class="flex items-center gap-3" href="/"><span class="text-base font-medium leading-none md:text-lg hidden sm:block">DeepWiki</span></a><div class="flex-1"><div class="flex flex-row items-center gap-2"><a class="block text-xs font-medium leading-none text-white sm:hidden md:text-lg" href="/">DeepWiki</a><p class="text-sm font-normal leading-none md:text-lg"><a href="https://github.com/EOEPCA/document-mlops" target="_blank" rel="noopener noreferrer" title="Open repository" class="text-muted-foreground hover:text-muted-foreground/80 group inline-flex items-center gap-1 transition-colors">EOEPCA/document-mlops<!-- --> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 256 256" class="opacity-0 transition-opacity group-hover:opacity-100"><path d="M224,104a8,8,0,0,1-16,0V59.32l-66.33,66.34a8,8,0,0,1-11.32-11.32L196.68,48H152a8,8,0,0,1,0-16h64a8,8,0,0,1,8,8Zm-40,24a8,8,0,0,0-8,8v72H48V80h72a8,8,0,0,0,0-16H48A16,16,0,0,0,32,80V208a16,16,0,0,0,16,16H176a16,16,0,0,0,16-16V136A8,8,0,0,0,184,128Z"></path></svg></a></p></div></div><div class="flex items-center gap-4"><button class="group hidden items-center gap-1.5 md:flex"><div class="relative"><span class="text-foreground/70 group-hover:text-foreground text-xs font-light transition-colors">Index your code with</span><div class="bg-foreground/30 absolute bottom-0 left-0 h-[1px] w-0 transition-all duration-300 group-hover:w-full"></div></div><div class="flex items-center gap-1 transition-transform duration-300 group-hover:translate-x-0.5"><svg class="size-4 transform transition-transform duration-700 group-hover:rotate-180 [&amp;_path]:stroke-0" xmlns="http://www.w3.org/2000/svg" viewBox="110 110 460 500"><path style="fill:#21c19a" class="" d="M418.73,332.37c9.84-5.68,22.07-5.68,31.91,0l25.49,14.71c.82.48,1.69.8,2.58,1.06.19.06.37.11.55.16.87.21,1.76.34,2.65.35.04,0,.08.02.13.02.1,0,.19-.03.29-.04.83-.02,1.64-.13,2.45-.32.14-.03.28-.05.42-.09.87-.24,1.7-.59,2.5-1.03.08-.04.17-.06.25-.1l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22l-50.97-29.43c-3.65-2.11-8.15-2.11-11.81,0l-50.97,29.43c-.08.04-.13.11-.2.16-.78.48-1.51,1.02-2.15,1.66-.1.1-.18.21-.28.31-.57.6-1.08,1.26-1.51,1.97-.07.12-.15.22-.22.34-.44.77-.77,1.6-1.03,2.47-.05.19-.1.37-.14.56-.22.89-.37,1.81-.37,2.76v29.43c0,11.36-6.11,21.95-15.95,27.63-9.84,5.68-22.06,5.68-31.91,0l-25.49-14.71c-.82-.48-1.69-.8-2.57-1.06-.19-.06-.37-.11-.56-.16-.88-.21-1.76-.34-2.65-.34-.13,0-.26.02-.4.02-.84.02-1.66.13-2.47.32-.13.03-.27.05-.4.09-.87.24-1.71.6-2.51,1.04-.08.04-.16.06-.24.1l-50.97,29.43c-3.65,2.11-5.9,6.01-5.9,10.22v58.86c0,4.22,2.25,8.11,5.9,10.22l50.97,29.43c.08.04.17.06.24.1.8.44,1.64.79,2.5,1.03.14.04.28.06.42.09.81.19,1.62.3,2.45.32.1,0,.19.04.29.04.04,0,.08-.02.13-.02.89,0,1.77-.13,2.65-.35.19-.04.37-.1.56-.16.88-.26,1.75-.59,2.58-1.06l25.49-14.71c9.84-5.68,22.06-5.68,31.91,0,9.84,5.68,15.95,16.27,15.95,27.63v29.43c0,.95.15,1.87.37,2.76.05.19.09.37.14.56.25.86.59,1.69,1.03,2.47.07.12.15.22.22.34.43.71.94,1.37,1.51,1.97.1.1.18.21.28.31.65.63,1.37,1.18,2.15,1.66.07.04.13.11.2.16l50.97,29.43c1.83,1.05,3.86,1.58,5.9,1.58s4.08-.53,5.9-1.58l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22l-50.97-29.43c-.08-.04-.16-.06-.24-.1-.8-.44-1.64-.8-2.51-1.04-.13-.04-.26-.05-.39-.09-.82-.2-1.65-.31-2.49-.33-.13,0-.25-.02-.38-.02-.89,0-1.78.13-2.66.35-.18.04-.36.1-.54.15-.88.26-1.75.59-2.58,1.07l-25.49,14.72c-9.84,5.68-22.07,5.68-31.9,0-9.84-5.68-15.95-16.27-15.95-27.63s6.11-21.95,15.95-27.63Z"></path><path style="fill:#3969ca" d="M141.09,317.65l50.97,29.43c1.83,1.05,3.86,1.58,5.9,1.58s4.08-.53,5.9-1.58l50.97-29.43c.08-.04.13-.11.2-.16.78-.48,1.51-1.02,2.15-1.66.1-.1.18-.21.28-.31.57-.6,1.08-1.26,1.51-1.97.07-.12.15-.22.22-.34.44-.77.77-1.6,1.03-2.47.05-.19.1-.37.14-.56.22-.89.37-1.81.37-2.76v-29.43c0-11.36,6.11-21.95,15.96-27.63s22.06-5.68,31.91,0l25.49,14.71c.82.48,1.69.8,2.57,1.06.19.06.37.11.56.16.87.21,1.76.34,2.64.35.04,0,.09.02.13.02.1,0,.19-.04.29-.04.83-.02,1.65-.13,2.45-.32.14-.03.28-.05.41-.09.87-.24,1.71-.6,2.51-1.04.08-.04.16-.06.24-.1l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22l-50.97-29.43c-3.65-2.11-8.15-2.11-11.81,0l-50.97,29.43c-.08.04-.13.11-.2.16-.78.48-1.51,1.02-2.15,1.66-.1.1-.18.21-.28.31-.57.6-1.08,1.26-1.51,1.97-.07.12-.15.22-.22.34-.44.77-.77,1.6-1.03,2.47-.05.19-.1.37-.14.56-.22.89-.37,1.81-.37,2.76v29.43c0,11.36-6.11,21.95-15.95,27.63-9.84,5.68-22.07,5.68-31.91,0l-25.49-14.71c-.82-.48-1.69-.8-2.58-1.06-.19-.06-.37-.11-.55-.16-.88-.21-1.76-.34-2.65-.35-.13,0-.26.02-.4.02-.83.02-1.66.13-2.47.32-.13.03-.27.05-.4.09-.87.24-1.71.6-2.51,1.04-.08.04-.16.06-.24.1l-50.97,29.43c-3.65,2.11-5.9,6.01-5.9,10.22v58.86c0,4.22,2.25,8.11,5.9,10.22Z"></path><path style="fill:#0294de" class="" d="M396.88,484.35l-50.97-29.43c-.08-.04-.17-.06-.24-.1-.8-.44-1.64-.79-2.51-1.03-.14-.04-.27-.06-.41-.09-.81-.19-1.64-.3-2.47-.32-.13,0-.26-.02-.39-.02-.89,0-1.78.13-2.66.35-.18.04-.36.1-.54.15-.88.26-1.76.59-2.58,1.07l-25.49,14.72c-9.84,5.68-22.06,5.68-31.9,0-9.84-5.68-15.96-16.27-15.96-27.63v-29.43c0-.95-.15-1.87-.37-2.76-.05-.19-.09-.37-.14-.56-.25-.86-.59-1.69-1.03-2.47-.07-.12-.15-.22-.22-.34-.43-.71-.94-1.37-1.51-1.97-.1-.1-.18-.21-.28-.31-.65-.63-1.37-1.18-2.15-1.66-.07-.04-.13-.11-.2-.16l-50.97-29.43c-3.65-2.11-8.15-2.11-11.81,0l-50.97,29.43c-3.65,2.11-5.9,6.01-5.9,10.22v58.86c0,4.22,2.25,8.11,5.9,10.22l50.97,29.43c.08.04.17.06.25.1.8.44,1.63.79,2.5,1.03.14.04.29.06.43.09.8.19,1.61.3,2.43.32.1,0,.2.04.3.04.04,0,.09-.02.13-.02.88,0,1.77-.13,2.64-.34.19-.04.37-.1.56-.16.88-.26,1.75-.59,2.57-1.06l25.49-14.71c9.84-5.68,22.06-5.68,31.91,0,9.84,5.68,15.95,16.27,15.95,27.63v29.43c0,.95.15,1.87.37,2.76.05.19.09.37.14.56.25.86.59,1.69,1.03,2.47.07.12.15.22.22.34.43.71.94,1.37,1.51,1.97.1.1.18.21.28.31.65.63,1.37,1.18,2.15,1.66.07.04.13.11.2.16l50.97,29.43c1.83,1.05,3.86,1.58,5.9,1.58s4.08-.53,5.9-1.58l50.97-29.43c3.65-2.11,5.9-6.01,5.9-10.22v-58.86c0-4.22-2.25-8.11-5.9-10.22Z"></path></svg><span class="text-sm font-medium">Devin</span></div></button><button aria-label="Edit Wiki" class="flex items-center rounded-md cursor-pointer transition-all border border-border bg-surface hover:border-border-hover hover:bg-component disabled:cursor-default disabled:opacity-50 disabled:hover:border-border disabled:hover:bg-surface gap-2 px-3 py-1.5 text-sm"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 256 256"><path d="M227.32,73.37,182.63,28.69a16,16,0,0,0-22.63,0L36.69,152A15.86,15.86,0,0,0,32,163.31V208a16,16,0,0,0,16,16H216a8,8,0,0,0,0-16H115.32l112-112A16,16,0,0,0,227.32,73.37ZM92.69,208H48V163.31l88-88L180.69,120ZM192,108.69,147.32,64l24-24L216,84.69Z"></path></svg>Edit Wiki</button><button class="flex items-center rounded-md !text-white cursor-pointer transition-all border bg-blue-500 hover:bg-blue-600 border-blue-500 hover:border-blue-600 dark:bg-blue-900 dark:hover:bg-blue-800 dark:border-blue-900 dark:hover:border-blue-800 disabled:cursor-default disabled:opacity-50 disabled:hover:bg-blue-500 disabled:hover:border-blue-500 dark:disabled:hover:bg-blue-900 dark:disabled:hover:border-blue-900 gap-1.5 px-3 py-1.5 text-sm" aria-label="Share" data-state="closed" data-slot="tooltip-trigger"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-4 w-4"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg><span>Share</span></button><div class="h-8 w-8"></div></div></div></div></div><!--$?--><template id="B:1"></template><div class="container-wrapper flex flex-1 items-center justify-center px-4"><div class="inline-block bg-clip-text text-[#b5b5b5a4] animate-shine text-center text-lg" style="background-image:linear-gradient(120deg, rgba(255, 255, 255, 0) 40%, rgba(255, 255, 255, 0.8) 50%, rgba(255, 255, 255, 0) 60%);background-size:200% 100%;-webkit-background-clip:text;animation-duration:1s">Loading...</div></div><!--/$--></div></div><script>$RB=[];$RV=function(a){$RT=performance.now();for(var b=0;b<a.length;b+=2){var c=a[b],e=a[b+1];null!==e.parentNode&&e.parentNode.removeChild(e);var f=c.parentNode;if(f){var g=c.previousSibling,h=0;do{if(c&&8===c.nodeType){var d=c.data;if("/$"===d||"/&"===d)if(0===h)break;else h--;else"$"!==d&&"$?"!==d&&"$~"!==d&&"$!"!==d&&"&"!==d||h++}d=c.nextSibling;f.removeChild(c);c=d}while(c);for(;e.firstChild;)f.insertBefore(e.firstChild,c);g.data="$";g._reactRetry&&requestAnimationFrame(g._reactRetry)}}a.length=0};
$RC=function(a,b){if(b=document.getElementById(b))(a=document.getElementById(a))?(a.previousSibling.data="$~",$RB.push(a,b),2===$RB.length&&("number"!==typeof $RT?requestAnimationFrame($RV.bind(null,$RB)):(a=performance.now(),setTimeout($RV.bind(null,$RB),2300>a&&2E3<a?2300-a:$RT+300-a)))):b.parentNode.removeChild(b)};$RC("B:0","S:0")</script><div hidden id="S:1"><script type="application/ld+json">{"@context":"https://schema.org","@type":"TechArticle","headline":"Overview","description":"This document provides an overview of the EOEPCA MLOps Building Block, introducing its purpose, core components, and high-level capabilities. It is intended for technical audiences seeking to understa","image":"https://deepwiki.com/EOEPCA/document-mlops/og-image.png","datePublished":"2026-01-13T11:20:20.366354","dateModified":"2026-01-13T11:20:20.366354","author":{"@type":"Organization","name":"DeepWiki","url":"https://deepwiki.com"},"publisher":{"@type":"Organization","name":"DeepWiki","logo":{"@type":"ImageObject","url":"https://deepwiki.com/icon.png"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://deepwiki.com/EOEPCA/document-mlops"}}</script><div class="w-full flex-1"><div class="container-wrapper relative mx-auto h-full px-0"><div class="container relative mx-auto flex h-full w-full flex-col gap-0 max-md:!px-0 md:flex-row md:gap-6 lg:gap-10"><div class="border-r-border hidden max-h-screen border-r border-dashed py-6 pr-4 transition-[border-radius] md:sticky md:left-0 md:top-20 md:block md:h-[calc(100vh-82px)] md:w-64 md:flex-shrink-0 md:overflow-y-auto lg:py-9 xl:w-72"><div class="flex h-full w-full max-w-full flex-shrink-0 flex-col overflow-hidden" style="scrollbar-color:var(--color-border) transparent"><div class="flex-shrink-0 px-2"><div class="text-secondary pb-1 text-xs">Last indexed: <!-- -->13 January 2026<!-- --> (<a href="https://github.com/EOEPCA/document-mlops/commits/35fba4e4" target="_blank" rel="noopener noreferrer" class="underline-offset-2 hover:underline">35fba4</a>)</div></div><ul class="flex-1 flex-shrink-0 space-y-1 overflow-y-auto py-1" style="scrollbar-width:none"><li style="padding-left:0"><a data-selected="true" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/1-overview">Overview</a></li><li style="padding-left:0"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/2-architecture">Architecture</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/2.1-requirements">Requirements</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/2.2-use-cases">Use Cases</a></li><li style="padding-left:0"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/3-core-components">Core Components</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/3.1-gitlab">GitLab</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/3.2-sharinghub">SharingHub</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/3.3-mlflow-sharinghub">MLflow SharingHub</a></li><li style="padding-left:0"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/4-workflows-and-scenarios">Workflows and Scenarios</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/4.1-model-training-workflow">Model Training Workflow</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/4.2-dataset-management">Dataset Management</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/4.3-flood-detection-example">Flood Detection Example</a></li><li style="padding-left:0"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/5-deployment-guide">Deployment Guide</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/5.1-prerequisites-and-architecture">Prerequisites and Architecture</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/5.2-gitlab-deployment">GitLab Deployment</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/5.3-sharinghub-deployment">SharingHub Deployment</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/5.4-mlflow-sharinghub-deployment">MLflow SharingHub Deployment</a></li><li style="padding-left:0"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/6-configuration-reference">Configuration Reference</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/6.1-sharinghub-configuration">SharingHub Configuration</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/6.2-mlflow-sharinghub-configuration">MLflow SharingHub Configuration</a></li><li style="padding-left:0"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/7-api-reference">API Reference</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/7.1-stac-api-specification">STAC API Specification</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/7.2-using-the-stac-api">Using the STAC API</a></li><li style="padding-left:0"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/8-operations-and-maintenance">Operations and Maintenance</a></li><li style="padding-left:12px"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/8.1-maintenance-guidelines">Maintenance Guidelines</a></li><li style="padding-left:0"><a data-selected="false" class="hover:bg-hover block w-full rounded px-2 py-1.5 text-left text-sm transition-none text-secondary data-[selected=true]:bg-hover data-[selected=true]:text-primary font-normal data-[selected=true]:font-normal" href="/EOEPCA/document-mlops/9-documentation-system">Documentation System</a></li></ul></div></div><div class="flex h-full flex-1 flex-col overflow-hidden"><div class="bg-background border-b-border sticky top-0 z-10 border-b border-dashed md:hidden"><div class="flex cursor-pointer items-center gap-2 p-3"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 256 256" class="transition-transform"><path d="M184.49,136.49l-80,80a12,12,0,0,1-17-17L159,128,87.51,56.49a12,12,0,1,1,17-17l80,80A12,12,0,0,1,184.49,136.49Z"></path></svg><span class="truncate text-base font-normal">Menu</span></div></div><div class="relative flex-1 overflow-y-auto px-3 pt-3 md:rounded-md md:px-0 md:pt-0 [&amp;_::selection]:bg-purple-500/40" style="scrollbar-color:var(--color-night) transparent"><div class="pb-30 mx-auto max-w-2xl md:pb-40 md:pt-6 lg:pt-8"><div class="prose prose-invert dark:prose-invert prose-headings:text-inherit prose-p:text-inherit max-w-none"><div><div class="prose-custom prose-custom-md prose-custom-gray !max-w-none text-neutral-300 [overflow-wrap:anywhere]"><h1 id="overview" class="group" data-header="true">Overview<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h1>
<details>
<summary>Relevant source files</summary>
<ul>
<li><a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/LICENSE" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>LICENSE</span></a></li>
<li><a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/README.md" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>README.md</span></a></li>
<li><a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/design/scenarios/flood-example.md" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/design/scenarios/flood-example.md</span></a></li>
<li><a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/design/scenarios/model-training.md" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/design/scenarios/model-training.md</span></a></li>
<li><a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/index.md" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/index.md</span></a></li>
<li><a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/mkdocs.yml" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>mkdocs.yml</span></a></li>
</ul>
</details>
<h2 id="purpose-and-scope" class="group" data-header="true">Purpose and Scope<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>This document provides an overview of the EOEPCA MLOps Building Block, introducing its purpose, core components, and high-level capabilities. It is intended for technical audiences seeking to understand the system&#x27;s architecture and functionality before diving into specific implementation details.</p>
<p>For detailed architectural design and component relationships, see <a href="/EOEPCA/document-mlops/2-architecture" class="text-neutral-300 hover:text-neutral-200 hover:underline">Architecture</a>. For deployment instructions, see <a href="/EOEPCA/document-mlops/5-deployment-guide" class="text-neutral-300 hover:text-neutral-200 hover:underline">Deployment Guide</a>. For practical usage workflows, see <a href="/EOEPCA/document-mlops/4-workflows-and-scenarios" class="text-neutral-300 hover:text-neutral-200 hover:underline">Workflows and Scenarios</a>.</p>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/mkdocs.yml#L1-L125" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>mkdocs.yml</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">1-125</span></a> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/index.md#L1-L45" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/index.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">1-45</span></a></p>
<hr/>
<h2 id="what-is-the-eoepca-mlops-building-block" class="group" data-header="true">What is the EOEPCA MLOps Building Block<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The EOEPCA MLOps Building Block is a cloud-based platform for managing the complete lifecycle of machine learning models and training datasets within the Earth Observation Processing and Analysis (EOEPCA) ecosystem. The system provides experiment tracking, model registry, and standardized discovery through STAC (SpatioTemporal Asset Catalog) APIs, integrating with existing EOEPCA Building Blocks such as Processing, Workspace, and Resource Discovery.</p>
<p>The platform is designed around three core integrated components that work together to support ML developers, data scientists, and ML users/operators in their respective workflows.</p>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/index.md#L16-L29" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/index.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">16-29</span></a></p>
<hr/>
<h2 id="core-components" class="group" data-header="true">Core Components<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The MLOps Building Block consists of three primary components, each serving a distinct role in the ML lifecycle:</p>

























<table><thead><tr><th>Component</th><th>Purpose</th><th>Key Functionality</th></tr></thead><tbody><tr><td><strong>GitLab</strong></td><td>Foundation for code and project management</td><td>Version control, CI/CD pipelines, project organization, Git LFS support, topic-based categorization</td></tr><tr><td><strong>SharingHub</strong></td><td>Discovery and collaboration platform</td><td>STAC catalog generation from GitLab projects, STAC API endpoints, metadata extraction, OAuth authentication integration</td></tr><tr><td><strong>MLflow SharingHub</strong></td><td>Experiment tracking and model registry</td><td>MLflow Tracking API, experiment logging, model versioning, artifact storage, permission delegation to SharingHub</td></tr></tbody></table>
<p>These components are deployed as separate services on Kubernetes but share infrastructure services including S3 object storage, PostgreSQL databases, cert-manager for TLS certificates, and Keycloak for identity management.</p>
<p>For detailed information about each component, see <a href="/EOEPCA/document-mlops/3-core-components" class="text-neutral-300 hover:text-neutral-200 hover:underline">Core Components</a>.</p>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/index.md#L22-L28" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/index.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">22-28</span></a> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/mkdocs.yml#L20-L23" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>mkdocs.yml</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">20-23</span></a></p>
<hr/>
<h2 id="key-capabilities" class="group" data-header="true">Key Capabilities<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The MLOps Building Block provides the following capabilities:</p>
<h3 id="model-training-and-experiment-tracking" class="group" data-header="true">Model Training and Experiment Tracking<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h3>
<ul>
<li>Remote experiment tracking via MLflow Tracking API</li>
<li>Metric logging and visualization</li>
<li>Hyperparameter recording</li>
<li>Artifact versioning and storage in S3</li>
</ul>
<h3 id="model-registry-and-versioning" class="group" data-header="true">Model Registry and Versioning<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h3>
<ul>
<li>Centralized model registry with versioning</li>
<li>ONNX format support for interoperability</li>
<li>Automatic linking between MLflow registry and STAC metadata</li>
<li>Model release management</li>
</ul>
<h3 id="dataset-management" class="group" data-header="true">Dataset Management<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h3>
<ul>
<li>DVC (Data Version Control) integration for large datasets</li>
<li>Git LFS support for medium-sized files</li>
<li>Metadata management in GitLab projects</li>
<li>Dataset versioning and tracking</li>
</ul>
<h3 id="standardized-discovery" class="group" data-header="true">Standardized Discovery<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h3>
<ul>
<li>STAC API compliance for catalog access</li>
<li>STAC ML-Model extension support</li>
<li>Dynamic catalog generation based on GitLab topics (e.g., <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">sharinghub:aimodel</code>, <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">sharinghub:dataset</code>, <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">sharinghub:processor</code>)</li>
<li>Permission-aware access control</li>
</ul>
<h3 id="integration-and-interoperability" class="group" data-header="true">Integration and Interoperability<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h3>
<ul>
<li>CWL (Common Workflow Language) support for inference workflows</li>
<li>S3-compatible object storage for artifacts</li>
<li>OAuth/OIDC authentication</li>
<li>RESTful APIs for programmatic access</li>
</ul>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/index.md#L32-L37" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/index.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">32-37</span></a> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/design/scenarios/model-training.md#L1-L53" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/design/scenarios/model-training.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">1-53</span></a></p>
<hr/>
<h2 id="system-architecture-overview" class="group" data-header="true">System Architecture Overview<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The following diagram illustrates the high-level architecture showing the three core components, shared infrastructure services, and external integrations:</p>
<pre class="px-2 py-1.5 has-[code]:rounded-md has-[code]:!bg-[#e5e5e5] has-[div]:bg-transparent has-[div]:!p-0 has-[code]:text-stone-900 dark:has-[code]:!bg-[#242424] has-[code]:dark:text-white [&amp;_code]:block [&amp;_code]:border-none [&amp;_code]:bg-transparent [&amp;_code]:p-0"><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--></pre>
<p><strong>System Architecture Overview</strong></p>
<p>This diagram shows how the three core components interact with shared infrastructure and expose standardized APIs. GitLab serves as the foundation, SharingHub provides discovery through STAC APIs, and MLflow SharingHub handles experiment tracking. All components are deployed on Kubernetes with shared S3 storage, PostgreSQL databases, and centralized authentication via Keycloak.</p>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/index.md#L22-L29" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/index.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">22-29</span></a> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/mkdocs.yml#L20-L23" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>mkdocs.yml</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">20-23</span></a></p>
<hr/>
<h2 id="component-integration-and-stac-catalog-structure" class="group" data-header="true">Component Integration and STAC Catalog Structure<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The following diagram shows how SharingHub generates its STAC catalog from GitLab projects and integrates with MLflow for model registry:</p>
<pre class="px-2 py-1.5 has-[code]:rounded-md has-[code]:!bg-[#e5e5e5] has-[div]:bg-transparent has-[div]:!p-0 has-[code]:text-stone-900 dark:has-[code]:!bg-[#242424] has-[code]:dark:text-white [&amp;_code]:block [&amp;_code]:border-none [&amp;_code]:bg-transparent [&amp;_code]:p-0"><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--></pre>
<p><strong>STAC Catalog Structure and GitLab Integration</strong></p>
<p>This diagram illustrates how SharingHub dynamically generates STAC collections from GitLab projects based on topics (e.g., <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">sharinghub:aimodel</code>, <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">sharinghub:dataset</code>). Each GitLab project becomes a STAC item with metadata extracted from its <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">README.md</code> file. MLflow-registered models are automatically linked to their corresponding STAC items, creating bidirectional traceability between the experiment tracking system and the discovery catalog.</p>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/index.md#L22-L28" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/index.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">22-28</span></a> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/design/scenarios/model-training.md#L17-L52" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/design/scenarios/model-training.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">17-52</span></a></p>
<hr/>
<h2 id="deployment-architecture-on-kubernetes" class="group" data-header="true">Deployment Architecture on Kubernetes<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The MLOps Building Block is deployed on Kubernetes using a namespaced architecture managed by ArgoCD:</p>



































<table><thead><tr><th>Namespace</th><th>Components</th><th>Purpose</th></tr></thead><tbody><tr><td><code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">argocd</code></td><td>ArgoCD Applications</td><td>GitOps control plane for declarative deployment</td></tr><tr><td><code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">gitlab</code></td><td>GitLab pods (webservice, sidekiq, kas), PostgreSQL, Redis</td><td>Code management and project hosting</td></tr><tr><td><code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">sharinghub</code></td><td>SharingHub pod</td><td>STAC catalog generation and API serving</td></tr><tr><td><code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">mlflow</code></td><td>MLflow SharingHub pod, PostgreSQL</td><td>Experiment tracking and model registry</td></tr><tr><td><code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">cert-manager</code></td><td>cert-manager controller</td><td>Automated TLS certificate management</td></tr></tbody></table>
<p>All components share:</p>
<ul>
<li><strong>NGINX Ingress Controller</strong>: Routes external traffic to services</li>
<li><strong>S3 Object Storage</strong>: Stores artifacts, datasets, and backups</li>
<li><strong>Keycloak Identity Provider</strong>: Provides OIDC authentication for GitLab</li>
</ul>
<p>For detailed deployment instructions, see <a href="/EOEPCA/document-mlops/5-deployment-guide" class="text-neutral-300 hover:text-neutral-200 hover:underline">Deployment Guide</a>.</p>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/mkdocs.yml#L18-L23" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>mkdocs.yml</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">18-23</span></a></p>
<hr/>
<h2 id="data-flow-and-integration-points" class="group" data-header="true">Data Flow and Integration Points<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The following diagram shows the key integration points and data flows between components, with specific configuration references:</p>
<pre class="px-2 py-1.5 has-[code]:rounded-md has-[code]:!bg-[#e5e5e5] has-[div]:bg-transparent has-[div]:!p-0 has-[code]:text-stone-900 dark:has-[code]:!bg-[#242424] has-[code]:dark:text-white [&amp;_code]:block [&amp;_code]:border-none [&amp;_code]:bg-transparent [&amp;_code]:p-0"><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--></pre>
<p><strong>Configuration and Integration Flow</strong></p>
<p>This diagram shows the specific configuration keys and integration points that connect the three components. SharingHub reads GitLab project topics via <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">categories[].gitlab_topic</code> to generate STAC collections. MLflow SharingHub delegates permission checks to SharingHub via <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">sharinghub.url</code> and stores artifacts in S3 via <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">default_artifact_root</code>. All components share S3 storage configured through their respective S3 configuration sections.</p>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/index.md#L22-L28" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/index.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">22-28</span></a> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/mkdocs.yml#L24-L25" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>mkdocs.yml</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">24-25</span></a></p>
<hr/>
<h2 id="user-personas-and-workflows" class="group" data-header="true">User Personas and Workflows<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The MLOps Building Block supports three primary user personas:</p>
<h3 id="ml-developer" class="group" data-header="true">ML Developer<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h3>
<ul>
<li><strong>Primary Activities</strong>: Model development, training, experiment tracking, model registration</li>
<li><strong>Key Interactions</strong>: GitLab (code), MLflow UI (metrics), SharingHub (dataset discovery)</li>
<li><strong>Workflow</strong>: Browse datasets  Clone project  Configure MLflow client  Train model  Log experiments  Register model  Auto-publish to STAC catalog</li>
</ul>
<h3 id="data-scientist" class="group" data-header="true">Data Scientist<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h3>
<ul>
<li><strong>Primary Activities</strong>: Dataset creation, data versioning, metadata management</li>
<li><strong>Key Interactions</strong>: GitLab (projects), DVC (data versioning), SharingHub (publication)</li>
<li><strong>Workflow</strong>: Create project  Add <code class="rounded-sm bg-[#e5e5e5] px-[0.25rem] py-[0.20rem] text-xs font-normal leading-[15px] before:hidden after:hidden dark:bg-[#484848]/30">sharinghub:dataset</code> topic  Version data with DVC  Store in S3  Commit metadata  Appears in catalog</li>
</ul>
<h3 id="ml-useroperator" class="group" data-header="true">ML User/Operator<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h3>
<ul>
<li><strong>Primary Activities</strong>: Model discovery, model download, inference execution</li>
<li><strong>Key Interactions</strong>: SharingHub (browse), STAC API (download), CWL (inference)</li>
<li><strong>Workflow</strong>: Browse models  Filter by tags  View details  Download via STAC API  Get ONNX model  Run inference</li>
</ul>
<p>For detailed workflows, see <a href="/EOEPCA/document-mlops/4.1-model-training-workflow" class="text-neutral-300 hover:text-neutral-200 hover:underline">Model Training Workflow</a> and <a href="/EOEPCA/document-mlops/4.3-flood-detection-example" class="text-neutral-300 hover:text-neutral-200 hover:underline">Flood Detection Example</a>.</p>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/design/scenarios/model-training.md#L1-L53" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/design/scenarios/model-training.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">1-53</span></a> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/design/scenarios/flood-example.md#L1-L72" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/design/scenarios/flood-example.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">1-72</span></a></p>
<hr/>
<h2 id="standards-and-technologies" class="group" data-header="true">Standards and Technologies<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The MLOps Building Block is built on industry-standard technologies and protocols:</p>























































<table><thead><tr><th>Standard/Technology</th><th>Purpose</th><th>Implementation</th></tr></thead><tbody><tr><td><strong>STAC</strong></td><td>Geospatial asset catalog standard</td><td>Root catalog, collections, items with ml-model extension</td></tr><tr><td><strong>MLflow</strong></td><td>ML lifecycle management</td><td>Tracking server, model registry, artifact storage</td></tr><tr><td><strong>DVC</strong></td><td>Data version control</td><td>Git-based data versioning with S3 remote storage</td></tr><tr><td><strong>ONNX</strong></td><td>Interoperable model format</td><td>Model export and inference standardization</td></tr><tr><td><strong>CWL</strong></td><td>Workflow description</td><td>Inference workflow automation</td></tr><tr><td><strong>OAuth/OIDC</strong></td><td>Authentication</td><td>Keycloak integration for GitLab and SharingHub</td></tr><tr><td><strong>S3 API</strong></td><td>Object storage</td><td>Artifact and dataset storage</td></tr><tr><td><strong>Kubernetes</strong></td><td>Container orchestration</td><td>Deployment platform with Helm charts</td></tr><tr><td><strong>ArgoCD</strong></td><td>GitOps</td><td>Declarative deployment management</td></tr></tbody></table>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/index.md#L22-L29" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/index.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">22-29</span></a> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/mkdocs.yml#L1-L125" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>mkdocs.yml</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">1-125</span></a></p>
<hr/>
<h2 id="project-templates-and-examples" class="group" data-header="true">Project Templates and Examples<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>The platform provides ready-to-use templates and demonstration projects:</p>
<ul>
<li><strong>MLOps Templates Repository</strong>: <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/`EOEPCA/mlops-templates`" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>`EOEPCA/mlops-templates`</span></a> - Project templates for ML models and datasets</li>
<li><strong>Flood Model</strong>: <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/`EOEPCA/flood-model`" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>`EOEPCA/flood-model`</span></a> - Demonstration image segmentation model for flood detection</li>
<li><strong>Sen1Floods11 Dataset</strong>: <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/`EOEPCA/Sen1Floods11-Dataset`" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4] rounded-r"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>`EOEPCA/Sen1Floods11-Dataset`</span></a> - Demonstration dataset for flood detection</li>
</ul>
<p>These resources provide starting points for creating new ML projects compatible with the platform&#x27;s workflows and conventions.</p>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/index.md#L39-L44" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/index.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">39-44</span></a> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/design/scenarios/flood-example.md#L9-L13" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/design/scenarios/flood-example.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">9-13</span></a></p>
<hr/>
<h2 id="documentation-structure" class="group" data-header="true">Documentation Structure<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>This documentation is organized into the following sections:</p>
<ol>
<li><strong>Overview</strong> (current page) - System introduction and capabilities</li>
<li><strong><a href="/EOEPCA/document-mlops/2-architecture" class="text-neutral-300 hover:text-neutral-200 hover:underline">Architecture</a></strong> - Design principles, requirements, and use cases</li>
<li><strong><a href="/EOEPCA/document-mlops/3-core-components" class="text-neutral-300 hover:text-neutral-200 hover:underline">Core Components</a></strong> - Detailed documentation of GitLab, SharingHub, and MLflow SharingHub</li>
<li><strong><a href="/EOEPCA/document-mlops/4-workflows-and-scenarios" class="text-neutral-300 hover:text-neutral-200 hover:underline">Workflows and Scenarios</a></strong> - Practical guides for model training, dataset management, and examples</li>
<li><strong><a href="/EOEPCA/document-mlops/5-deployment-guide" class="text-neutral-300 hover:text-neutral-200 hover:underline">Deployment Guide</a></strong> - Kubernetes deployment with prerequisites, component deployment steps</li>
<li><strong><a href="/EOEPCA/document-mlops/6-configuration-reference" class="text-neutral-300 hover:text-neutral-200 hover:underline">Configuration Reference</a></strong> - Comprehensive configuration documentation</li>
<li><strong><a href="/EOEPCA/document-mlops/7-api-reference" class="text-neutral-300 hover:text-neutral-200 hover:underline">API Reference</a></strong> - STAC API specification and usage examples</li>
<li><strong><a href="/EOEPCA/document-mlops/8-operations-and-maintenance" class="text-neutral-300 hover:text-neutral-200 hover:underline">Operations and Maintenance</a></strong> - Maintenance guidelines and best practices</li>
</ol>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/mkdocs.yml#L6-L33" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>mkdocs.yml</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">6-33</span></a> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/index.md#L1-L15" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/index.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">1-15</span></a></p>
<hr/>
<h2 id="next-steps" class="group" data-header="true">Next Steps<button class="relative ml-2 cursor-pointer align-baseline text-gray-400 opacity-0 transition-opacity hover:text-blue-400 focus:opacity-100 group-hover:opacity-100" aria-label="Copy link to header"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M117.18,188.74a12,12,0,0,1,0,17l-5.12,5.12A58.26,58.26,0,0,1,70.6,228h0A58.62,58.62,0,0,1,29.14,127.92L63.89,93.17a58.64,58.64,0,0,1,98.56,28.11,12,12,0,1,1-23.37,5.44,34.65,34.65,0,0,0-58.22-16.58L46.11,144.89A34.62,34.62,0,0,0,70.57,204h0a34.41,34.41,0,0,0,24.49-10.14l5.11-5.12A12,12,0,0,1,117.18,188.74ZM226.83,45.17a58.65,58.65,0,0,0-82.93,0l-5.11,5.11a12,12,0,0,0,17,17l5.12-5.12a34.63,34.63,0,1,1,49,49L175.1,145.86A34.39,34.39,0,0,1,150.61,156h0a34.63,34.63,0,0,1-33.69-26.72,12,12,0,0,0-23.38,5.44A58.64,58.64,0,0,0,150.56,180h.05a58.28,58.28,0,0,0,41.47-17.17l34.75-34.75a58.62,58.62,0,0,0,0-82.91Z"></path></svg></button></h2>
<p>To get started with the EOEPCA MLOps Building Block:</p>
<ol>
<li><strong>Understand the Architecture</strong>: Read <a href="/EOEPCA/document-mlops/2-architecture" class="text-neutral-300 hover:text-neutral-200 hover:underline">Architecture</a> to understand system design and component relationships</li>
<li><strong>Deploy the Platform</strong>: Follow <a href="/EOEPCA/document-mlops/5-deployment-guide" class="text-neutral-300 hover:text-neutral-200 hover:underline">Deployment Guide</a> for Kubernetes installation</li>
<li><strong>Explore Workflows</strong>: Review <a href="/EOEPCA/document-mlops/4.1-model-training-workflow" class="text-neutral-300 hover:text-neutral-200 hover:underline">Model Training Workflow</a> to understand the end-to-end process</li>
<li><strong>Try an Example</strong>: Work through the <a href="/EOEPCA/document-mlops/4.3-flood-detection-example" class="text-neutral-300 hover:text-neutral-200 hover:underline">Flood Detection Example</a> for hands-on experience</li>
<li><strong>Configure Your Deployment</strong>: Consult <a href="/EOEPCA/document-mlops/6-configuration-reference" class="text-neutral-300 hover:text-neutral-200 hover:underline">Configuration Reference</a> for customization options</li>
<li><strong>Use the API</strong>: Learn to interact programmatically via <a href="/EOEPCA/document-mlops/7-api-reference" class="text-neutral-300 hover:text-neutral-200 hover:underline">API Reference</a></li>
</ol>
<p><strong>Sources:</strong> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/docs/index.md#L1-L15" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>docs/index.md</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">1-15</span></a> <a href="https://github.com/EOEPCA/document-mlops/blob/35fba4e4/mkdocs.yml#L6-L33" target="_blank" rel="noopener noreferrer" class="mb-1 mr-1 inline-flex items-stretch font-mono text-xs !no-underline transition-opacity hover:opacity-75"><span class="flex items-center break-all rounded-l px-2 py-1.5 bg-[#e5e5e5] text-[#333333] dark:bg-[#252525] dark:text-[#e4e4e4]"><svg class="mr-1.5 hidden h-3.5 w-3.5 flex-shrink-0 opacity-40 md:block" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg>mkdocs.yml</span><span class="flex flex-shrink-0 items-center rounded-r border-l px-2 py-1.5 border-[#dddddd] bg-[#d8d8d8] text-[#666666] dark:border-[#333333] dark:bg-[#2a2a2a] dark:text-[#888888]">6-33</span></a></p></div></div></div></div></div></div><div class="hidden overflow-hidden transition-[border-radius] xl:sticky xl:right-0 xl:top-20 xl:block xl:h-[calc(100vh-82px)] xl:w-64 xl:flex-shrink-0 2xl:w-72" style="scrollbar-width:none"><div class="flex max-h-full w-full flex-shrink-0 flex-col py-6 pt-0 text-sm lg:pb-4 lg:pt-8 xl:w-64 2xl:w-72" style="scrollbar-color:var(--color-night) transparent"><div><div class="relative mx-4 my-4 rounded-md border border-neutral-200 bg-neutral-100 p-3 text-sm text-neutral-600 dark:border-neutral-800 dark:bg-neutral-900 dark:text-neutral-400"><button class="absolute right-2 top-2 rounded-sm p-1 opacity-70 transition-opacity hover:opacity-100 focus:outline-none focus:ring-2 focus:ring-neutral-400 focus:ring-offset-2"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256" class="h-4 w-4"><path d="M205.66,194.34a8,8,0,0,1-11.32,11.32L128,139.31,61.66,205.66a8,8,0,0,1-11.32-11.32L116.69,128,50.34,61.66A8,8,0,0,1,61.66,50.34L128,116.69l66.34-66.35a8,8,0,0,1,11.32,11.32L139.31,128Z"></path></svg><span class="sr-only">Dismiss</span></button><p class="text-sm font-medium">Refresh this wiki</p><p class="mt-2 text-sm font-light text-neutral-500 dark:text-neutral-400">This wiki was recently refreshed. Please wait<!-- --> <!-- -->7<!-- --> day<!-- -->s<!-- --> to refresh again.</p></div></div><h3 class="px-4 pb-5 text-lg font-medium leading-none">On this page</h3><ul style="scrollbar-width:none" class="min-h-0 flex-1 space-y-3 overflow-y-auto p-4 pt-0"><li class=""><a href="#overview" class="hover:text-primary pr-1 transition-all text-primary font-medium">Overview</a></li><li class="ml-3"><a href="#purpose-and-scope" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Purpose and Scope</a></li><li class="ml-3"><a href="#what-is-the-eoepca-mlops-building-block" class="hover:text-primary pr-1 font-normal transition-all text-secondary">What is the EOEPCA MLOps Building Block</a></li><li class="ml-3"><a href="#core-components" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Core Components</a></li><li class="ml-3"><a href="#key-capabilities" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Key Capabilities</a></li><li class="ml-6"><a href="#model-training-and-experiment-tracking" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Model Training and Experiment Tracking</a></li><li class="ml-6"><a href="#model-registry-and-versioning" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Model Registry and Versioning</a></li><li class="ml-6"><a href="#dataset-management" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Dataset Management</a></li><li class="ml-6"><a href="#standardized-discovery" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Standardized Discovery</a></li><li class="ml-6"><a href="#integration-and-interoperability" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Integration and Interoperability</a></li><li class="ml-3"><a href="#system-architecture-overview" class="hover:text-primary pr-1 font-normal transition-all text-secondary">System Architecture Overview</a></li><li class="ml-3"><a href="#component-integration-and-stac-catalog-structure" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Component Integration and STAC Catalog Structure</a></li><li class="ml-3"><a href="#deployment-architecture-on-kubernetes" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Deployment Architecture on Kubernetes</a></li><li class="ml-3"><a href="#data-flow-and-integration-points" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Data Flow and Integration Points</a></li><li class="ml-3"><a href="#user-personas-and-workflows" class="hover:text-primary pr-1 font-normal transition-all text-secondary">User Personas and Workflows</a></li><li class="ml-6"><a href="#ml-developer" class="hover:text-primary pr-1 font-normal transition-all text-secondary">ML Developer</a></li><li class="ml-6"><a href="#data-scientist" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Data Scientist</a></li><li class="ml-6"><a href="#ml-useroperator" class="hover:text-primary pr-1 font-normal transition-all text-secondary">ML User/Operator</a></li><li class="ml-3"><a href="#standards-and-technologies" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Standards and Technologies</a></li><li class="ml-3"><a href="#project-templates-and-examples" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Project Templates and Examples</a></li><li class="ml-3"><a href="#documentation-structure" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Documentation Structure</a></li><li class="ml-3"><a href="#next-steps" class="hover:text-primary pr-1 font-normal transition-all text-secondary">Next Steps</a></li></ul></div></div><div class="pointer-events-none fixed bottom-2 left-2 right-2 mt-2 md:bottom-4 md:left-0 md:right-0"><div class="z-10 mx-auto max-w-3xl"><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--></div></div></div></div></div><!--$--><!--/$--></div><script>$RC("B:1","S:1")</script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n"])</script><script>self.__next_f.push([1,"2:I[49138,[\"9453\",\"static/chunks/b1298b8d-5cac6cd7c8e952ff.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"8970\",\"static/chunks/378e5a93-860e027c5a5e0c0d.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"1585\",\"static/chunks/f7f68e2d-d8bf979db5ff4e9d.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"7963\",\"static/chunks/7963-b29c27a8b53c3f2a.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"1265\",\"static/chunks/1265-fa8a95d3842768f5.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"9885\",\"static/chunks/9885-b57089f03806c3b8.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"659\",\"static/chunks/659-ee9e1e775e30dcef.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"7177\",\"static/chunks/app/layout-0537c2076823e553.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\"],\"RootProvider\"]\n"])</script><script>self.__next_f.push([1,"3:I[85341,[],\"\"]\n4:I[90025,[],\"\"]\n7:I[41012,[],\"ClientPageRoot\"]\n"])</script><script>self.__next_f.push([1,"8:I[57456,[\"9453\",\"static/chunks/b1298b8d-5cac6cd7c8e952ff.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"8970\",\"static/chunks/378e5a93-860e027c5a5e0c0d.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"1585\",\"static/chunks/f7f68e2d-d8bf979db5ff4e9d.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"4129\",\"static/chunks/7bf36345-1ac10ec2f0e0c88f.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"2545\",\"static/chunks/c16f53c3-b390b6f98a69dcec.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"7963\",\"static/chunks/7963-b29c27a8b53c3f2a.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"1265\",\"static/chunks/1265-fa8a95d3842768f5.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"6212\",\"static/chunks/6212-505c2fc95d1a35ae.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"9885\",\"static/chunks/9885-b57089f03806c3b8.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"4336\",\"static/chunks/4336-624d5ae6f4cc1cc7.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"659\",\"static/chunks/659-ee9e1e775e30dcef.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"8461\",\"static/chunks/8461-369a9f0c48ea2626.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"7198\",\"static/chunks/7198-985a49f2b6072d25.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"5462\",\"static/chunks/5462-08221e91030fd747.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"4429\",\"static/chunks/4429-943205658cbafffe.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"9976\",\"static/chunks/9976-9250854d58eefaa3.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"1481\",\"static/chunks/1481-25d5bbc4f2d9524a.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"3285\",\"static/chunks/app/%5Borg%5D/%5Brepo%5D/%5B%5B...wikiRoutes%5D%5D/page-6651f8cd8321a0db.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\"],\"default\"]\n"])</script><script>self.__next_f.push([1,"b:I[15104,[],\"OutletBoundary\"]\nd:I[94777,[],\"AsyncMetadataOutlet\"]\nf:I[15104,[],\"ViewportBoundary\"]\n11:I[15104,[],\"MetadataBoundary\"]\n12:\"$Sreact.suspense\"\n14:I[34431,[],\"\"]\n:HL[\"/_next/static/media/4cf2300e9c8272f7-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/93f479601ee12b01-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/de70bee13400563f.css?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"style\"]\n:HL[\"/_next/static/css/7da0a892b4ad83db.css?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"SzzXrDjxzhDKxxD_1GShd\",\"p\":\"\",\"c\":[\"\",\"EOEPCA\",\"document-mlops\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[[\"org\",\"EOEPCA\",\"d\"],{\"children\":[[\"repo\",\"document-mlops\",\"d\"],{\"children\":[[\"wikiRoutes\",\"\",\"oc\"],{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/de70bee13400563f.css?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/7da0a892b4ad83db.css?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{}],[\"$\",\"body\",null,{\"className\":\"__variable_188709 font-geist-sans relative min-h-screen __variable_9a8899 bg-background antialiased\",\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}]]}],{\"children\":[[\"org\",\"EOEPCA\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"repo\",\"document-mlops\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,\"$L5\"]}],{\"children\":[[\"wikiRoutes\",\"\",\"oc\"],[\"$\",\"$1\",\"c\",{\"children\":[null,\"$L6\"]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L7\",null,{\"Component\":\"$8\",\"searchParams\":{},\"params\":{\"org\":\"EOEPCA\",\"repo\":\"document-mlops\"},\"promises\":[\"$@9\",\"$@a\"]}],null,[\"$\",\"$Lb\",null,{\"children\":[\"$Lc\",[\"$\",\"$Ld\",null,{\"promise\":\"$@e\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$L11\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$12\",null,{\"fallback\":null,\"children\":\"$L13\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$14\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"9:{}\na:\"$0:f:0:1:2:children:2:children:2:children:2:children:1:props:children:0:props:params\"\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nc:null\n"])</script><script>self.__next_f.push([1,"15:I[13550,[\"9453\",\"static/chunks/b1298b8d-5cac6cd7c8e952ff.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"8970\",\"static/chunks/378e5a93-860e027c5a5e0c0d.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"1585\",\"static/chunks/f7f68e2d-d8bf979db5ff4e9d.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"7963\",\"static/chunks/7963-b29c27a8b53c3f2a.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"1265\",\"static/chunks/1265-fa8a95d3842768f5.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"6212\",\"static/chunks/6212-505c2fc95d1a35ae.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"4336\",\"static/chunks/4336-624d5ae6f4cc1cc7.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"25\",\"static/chunks/25-9f305b682cea7558.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"7391\",\"static/chunks/7391-f64e18878e224268.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"6373\",\"static/chunks/6373-d56a493968555802.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"6375\",\"static/chunks/6375-7e0e75eb09fc9abe.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"9437\",\"static/chunks/9437-be873d1907eef4d4.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"2933\",\"static/chunks/app/%5Borg%5D/%5Brepo%5D/layout-77683f6369c5b39e.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\"],\"HeaderWrapperWithSuspense\"]\n"])</script><script>self.__next_f.push([1,"16:I[82188,[\"9453\",\"static/chunks/b1298b8d-5cac6cd7c8e952ff.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"8970\",\"static/chunks/378e5a93-860e027c5a5e0c0d.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"1585\",\"static/chunks/f7f68e2d-d8bf979db5ff4e9d.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"7963\",\"static/chunks/7963-b29c27a8b53c3f2a.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"1265\",\"static/chunks/1265-fa8a95d3842768f5.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"6212\",\"static/chunks/6212-505c2fc95d1a35ae.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"4336\",\"static/chunks/4336-624d5ae6f4cc1cc7.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"25\",\"static/chunks/25-9f305b682cea7558.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"7391\",\"static/chunks/7391-f64e18878e224268.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"6373\",\"static/chunks/6373-d56a493968555802.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"6375\",\"static/chunks/6375-7e0e75eb09fc9abe.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"9437\",\"static/chunks/9437-be873d1907eef4d4.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\",\"2933\",\"static/chunks/app/%5Borg%5D/%5Brepo%5D/layout-77683f6369c5b39e.js?dpl=dpl_9vWZnGgB4PqEv2xwHjFeirVQfSL7\"],\"WikiContextProvider\"]\n"])</script><script>self.__next_f.push([1,"32:I[36505,[],\"IconMark\"]\n17:T4014,"])</script><script>self.__next_f.push([1,"# Overview\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [LICENSE](LICENSE)\n- [README.md](README.md)\n- [docs/design/scenarios/flood-example.md](docs/design/scenarios/flood-example.md)\n- [docs/design/scenarios/model-training.md](docs/design/scenarios/model-training.md)\n- [docs/index.md](docs/index.md)\n- [mkdocs.yml](mkdocs.yml)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis document provides an overview of the EOEPCA MLOps Building Block, introducing its purpose, core components, and high-level capabilities. It is intended for technical audiences seeking to understand the system's architecture and functionality before diving into specific implementation details.\n\nFor detailed architectural design and component relationships, see [Architecture](#2). For deployment instructions, see [Deployment Guide](#5). For practical usage workflows, see [Workflows and Scenarios](#4).\n\n**Sources:** [mkdocs.yml:1-125](), [docs/index.md:1-45]()\n\n---\n\n## What is the EOEPCA MLOps Building Block\n\nThe EOEPCA MLOps Building Block is a cloud-based platform for managing the complete lifecycle of machine learning models and training datasets within the Earth Observation Processing and Analysis (EOEPCA) ecosystem. The system provides experiment tracking, model registry, and standardized discovery through STAC (SpatioTemporal Asset Catalog) APIs, integrating with existing EOEPCA Building Blocks such as Processing, Workspace, and Resource Discovery.\n\nThe platform is designed around three core integrated components that work together to support ML developers, data scientists, and ML users/operators in their respective workflows.\n\n**Sources:** [docs/index.md:16-29]()\n\n---\n\n## Core Components\n\nThe MLOps Building Block consists of three primary components, each serving a distinct role in the ML lifecycle:\n\n| Component | Purpose | Key Functionality |\n|-----------|---------|-------------------|\n| **GitLab** | Foundation for code and project management | Version control, CI/CD pipelines, project organization, Git LFS support, topic-based categorization |\n| **SharingHub** | Discovery and collaboration platform | STAC catalog generation from GitLab projects, STAC API endpoints, metadata extraction, OAuth authentication integration |\n| **MLflow SharingHub** | Experiment tracking and model registry | MLflow Tracking API, experiment logging, model versioning, artifact storage, permission delegation to SharingHub |\n\nThese components are deployed as separate services on Kubernetes but share infrastructure services including S3 object storage, PostgreSQL databases, cert-manager for TLS certificates, and Keycloak for identity management.\n\nFor detailed information about each component, see [Core Components](#3).\n\n**Sources:** [docs/index.md:22-28](), [mkdocs.yml:20-23]()\n\n---\n\n## Key Capabilities\n\nThe MLOps Building Block provides the following capabilities:\n\n### Model Training and Experiment Tracking\n- Remote experiment tracking via MLflow Tracking API\n- Metric logging and visualization\n- Hyperparameter recording\n- Artifact versioning and storage in S3\n\n### Model Registry and Versioning\n- Centralized model registry with versioning\n- ONNX format support for interoperability\n- Automatic linking between MLflow registry and STAC metadata\n- Model release management\n\n### Dataset Management\n- DVC (Data Version Control) integration for large datasets\n- Git LFS support for medium-sized files\n- Metadata management in GitLab projects\n- Dataset versioning and tracking\n\n### Standardized Discovery\n- STAC API compliance for catalog access\n- STAC ML-Model extension support\n- Dynamic catalog generation based on GitLab topics (e.g., `sharinghub:aimodel`, `sharinghub:dataset`, `sharinghub:processor`)\n- Permission-aware access control\n\n### Integration and Interoperability\n- CWL (Common Workflow Language) support for inference workflows\n- S3-compatible object storage for artifacts\n- OAuth/OIDC authentication\n- RESTful APIs for programmatic access\n\n**Sources:** [docs/index.md:32-37](), [docs/design/scenarios/model-training.md:1-53]()\n\n---\n\n## System Architecture Overview\n\nThe following diagram illustrates the high-level architecture showing the three core components, shared infrastructure services, and external integrations:\n\n```mermaid\ngraph TB\n    subgraph \"User Personas\"\n        MLDev[\"ML Developer\"]\n        DataSci[\"Data Scientist\"]\n        MLUser[\"ML User/Operator\"]\n    end\n    \n    subgraph \"Core MLOps Components\"\n        GitLab[\"GitLab\u003cbr/\u003eCode \u0026 Project Management\"]\n        SharingHub[\"SharingHub\u003cbr/\u003eSTAC Catalog \u0026 Discovery\"]\n        MLflowSH[\"MLflow SharingHub\u003cbr/\u003eExperiment Tracking \u0026 Registry\"]\n    end\n    \n    subgraph \"Storage Infrastructure\"\n        S3[\"S3 Object Storage\u003cbr/\u003eArtifacts \u0026 Datasets\"]\n        PostgreSQL[\"PostgreSQL\u003cbr/\u003eMetadata Storage\"]\n    end\n    \n    subgraph \"Shared Services\"\n        Keycloak[\"Keycloak\u003cbr/\u003eIdentity Provider\"]\n        CertManager[\"cert-manager\u003cbr/\u003eTLS Automation\"]\n        K8s[\"Kubernetes Cluster\u003cbr/\u003eOrchestration Platform\"]\n    end\n    \n    subgraph \"APIs \u0026 Interfaces\"\n        STACAPI[\"STAC API\u003cbr/\u003e/stac endpoints\"]\n        MLflowAPI[\"MLflow Tracking API\u003cbr/\u003e/api/2.0/mlflow\"]\n        WebUI[\"Web UI\u003cbr/\u003eUser Interface\"]\n    end\n    \n    MLDev --\u003e WebUI\n    DataSci --\u003e WebUI\n    MLUser --\u003e WebUI\n    \n    WebUI --\u003e GitLab\n    WebUI --\u003e SharingHub\n    WebUI --\u003e MLflowSH\n    \n    SharingHub --\u003e STACAPI\n    MLflowSH --\u003e MLflowAPI\n    \n    GitLab --\u003e S3\n    GitLab --\u003e PostgreSQL\n    GitLab --\u003e Keycloak\n    \n    SharingHub --\u003e GitLab\n    SharingHub --\u003e S3\n    \n    MLflowSH --\u003e SharingHub\n    MLflowSH --\u003e PostgreSQL\n    MLflowSH --\u003e S3\n    \n    K8s --\u003e GitLab\n    K8s --\u003e SharingHub\n    K8s --\u003e MLflowSH\n    \n    CertManager --\u003e GitLab\n    CertManager --\u003e SharingHub\n    CertManager --\u003e MLflowSH\n```\n\n**System Architecture Overview**\n\nThis diagram shows how the three core components interact with shared infrastructure and expose standardized APIs. GitLab serves as the foundation, SharingHub provides discovery through STAC APIs, and MLflow SharingHub handles experiment tracking. All components are deployed on Kubernetes with shared S3 storage, PostgreSQL databases, and centralized authentication via Keycloak.\n\n**Sources:** [docs/index.md:22-29](), [mkdocs.yml:20-23]()\n\n---\n\n## Component Integration and STAC Catalog Structure\n\nThe following diagram shows how SharingHub generates its STAC catalog from GitLab projects and integrates with MLflow for model registry:\n\n```mermaid\ngraph TB\n    subgraph \"GitLab Projects\"\n        GP1[\"GitLab Project\u003cbr/\u003eTopic: sharinghub:aimodel\"]\n        GP2[\"GitLab Project\u003cbr/\u003eTopic: sharinghub:dataset\"]\n        README1[\"README.md\u003cbr/\u003eSTAC metadata\"]\n        README2[\"README.md\u003cbr/\u003eSTAC metadata\"]\n        \n        GP1 --\u003e README1\n        GP2 --\u003e README2\n    end\n    \n    subgraph \"SharingHub STAC Catalog\"\n        RootCatalog[\"STAC Root Catalog\u003cbr/\u003eid: gitlab-cs\"]\n        AICollection[\"STAC Collection\u003cbr/\u003eid: aimodel\"]\n        DSCollection[\"STAC Collection\u003cbr/\u003eid: dataset\"]\n        STACItem1[\"STAC Item\u003cbr/\u003eml-model extension\u003cbr/\u003eassets: onnx files\"]\n        STACItem2[\"STAC Item\u003cbr/\u003eeo extension\u003cbr/\u003eassets: GeoTIFF\"]\n        \n        RootCatalog --\u003e AICollection\n        RootCatalog --\u003e DSCollection\n        AICollection --\u003e STACItem1\n        DSCollection --\u003e STACItem2\n    end\n    \n    subgraph \"STAC API Endpoints\"\n        STACSearch[\"/stac/search\"]\n        STACCollections[\"/stac/collections\"]\n        STACItems[\"/stac/collections/{collection}/items\"]\n    end\n    \n    subgraph \"MLflow Registry\"\n        MLflowModel[\"Registered Model\u003cbr/\u003eVersion: 1.0.0\"]\n        MLflowArtifacts[\"Artifacts in S3\u003cbr/\u003emodel.onnx\"]\n        \n        MLflowModel --\u003e MLflowArtifacts\n    end\n    \n    GP1 -.gitlab_topic filter.-\u003e AICollection\n    GP2 -.gitlab_topic filter.-\u003e DSCollection\n    \n    README1 -.metadata extraction.-\u003e STACItem1\n    README2 -.metadata extraction.-\u003e STACItem2\n    \n    STACItem1 -.auto-linked.-\u003e MLflowModel\n    \n    RootCatalog --\u003e STACSearch\n    AICollection --\u003e STACCollections\n    STACItem1 --\u003e STACItems\n    \n    MLflowArtifacts -.referenced by.-\u003e STACItem1\n```\n\n**STAC Catalog Structure and GitLab Integration**\n\nThis diagram illustrates how SharingHub dynamically generates STAC collections from GitLab projects based on topics (e.g., `sharinghub:aimodel`, `sharinghub:dataset`). Each GitLab project becomes a STAC item with metadata extracted from its `README.md` file. MLflow-registered models are automatically linked to their corresponding STAC items, creating bidirectional traceability between the experiment tracking system and the discovery catalog.\n\n**Sources:** [docs/index.md:22-28](), [docs/design/scenarios/model-training.md:17-52]()\n\n---\n\n## Deployment Architecture on Kubernetes\n\nThe MLOps Building Block is deployed on Kubernetes using a namespaced architecture managed by ArgoCD:\n\n| Namespace | Components | Purpose |\n|-----------|-----------|---------|\n| `argocd` | ArgoCD Applications | GitOps control plane for declarative deployment |\n| `gitlab` | GitLab pods (webservice, sidekiq, kas), PostgreSQL, Redis | Code management and project hosting |\n| `sharinghub` | SharingHub pod | STAC catalog generation and API serving |\n| `mlflow` | MLflow SharingHub pod, PostgreSQL | Experiment tracking and model registry |\n| `cert-manager` | cert-manager controller | Automated TLS certificate management |\n\nAll components share:\n- **NGINX Ingress Controller**: Routes external traffic to services\n- **S3 Object Storage**: Stores artifacts, datasets, and backups\n- **Keycloak Identity Provider**: Provides OIDC authentication for GitLab\n\nFor detailed deployment instructions, see [Deployment Guide](#5).\n\n**Sources:** [mkdocs.yml:18-23]()\n\n---\n\n## Data Flow and Integration Points\n\nThe following diagram shows the key integration points and data flows between components, with specific configuration references:\n\n```mermaid\ngraph LR\n    subgraph \"MLflow Client\"\n        MLflowPython[\"mlflow.set_tracking_uri()\"]\n        MLflowLog[\"mlflow.log_metric()\"]\n        MLflowRegister[\"mlflow.register_model()\"]\n    end\n    \n    subgraph \"SharingHub Configuration\"\n        SHGitLab[\"gitlab.url\u003cbr/\u003egitlab.oauth_client_id\"]\n        SHCategories[\"categories[]\u003cbr/\u003egitlab_topic\u003cbr/\u003estac_id\"]\n        SHS3[\"s3_store.endpoint\u003cbr/\u003es3_store.bucket\"]\n    end\n    \n    subgraph \"MLflow SharingHub Configuration\"\n        MLFBackend[\"backend_store_uri\u003cbr/\u003ePostgreSQL connection\"]\n        MLFArtifacts[\"default_artifact_root\u003cbr/\u003es3://bucket/path\"]\n        MLFSHIntegration[\"sharinghub.url\u003cbr/\u003esharinghub.secret_key\"]\n    end\n    \n    subgraph \"GitLab Configuration\"\n        GLTopics[\"Project Topics\u003cbr/\u003esharinghub:aimodel\u003cbr/\u003esharinghub:dataset\u003cbr/\u003esharinghub:processor\"]\n        GLOIDC[\"OIDC Integration\u003cbr/\u003eKeycloak realm\"]\n        GLS3[\"Object Storage\u003cbr/\u003eLFS, Backups, Artifacts\"]\n    end\n    \n    MLflowPython --\u003e MLFSHIntegration\n    MLflowLog --\u003e MLFBackend\n    MLflowRegister --\u003e MLFArtifacts\n    \n    MLFSHIntegration --\u003e SHGitLab\n    MLFArtifacts --\u003e SHS3\n    \n    SHGitLab --\u003e GLTopics\n    SHGitLab --\u003e GLOIDC\n    SHCategories --\u003e GLTopics\n    SHS3 --\u003e GLS3\n```\n\n**Configuration and Integration Flow**\n\nThis diagram shows the specific configuration keys and integration points that connect the three components. SharingHub reads GitLab project topics via `categories[].gitlab_topic` to generate STAC collections. MLflow SharingHub delegates permission checks to SharingHub via `sharinghub.url` and stores artifacts in S3 via `default_artifact_root`. All components share S3 storage configured through their respective S3 configuration sections.\n\n**Sources:** [docs/index.md:22-28](), [mkdocs.yml:24-25]()\n\n---\n\n## User Personas and Workflows\n\nThe MLOps Building Block supports three primary user personas:\n\n### ML Developer\n- **Primary Activities**: Model development, training, experiment tracking, model registration\n- **Key Interactions**: GitLab (code), MLflow UI (metrics), SharingHub (dataset discovery)\n- **Workflow**: Browse datasets  Clone project  Configure MLflow client  Train model  Log experiments  Register model  Auto-publish to STAC catalog\n\n### Data Scientist\n- **Primary Activities**: Dataset creation, data versioning, metadata management\n- **Key Interactions**: GitLab (projects), DVC (data versioning), SharingHub (publication)\n- **Workflow**: Create project  Add `sharinghub:dataset` topic  Version data with DVC  Store in S3  Commit metadata  Appears in catalog\n\n### ML User/Operator\n- **Primary Activities**: Model discovery, model download, inference execution\n- **Key Interactions**: SharingHub (browse), STAC API (download), CWL (inference)\n- **Workflow**: Browse models  Filter by tags  View details  Download via STAC API  Get ONNX model  Run inference\n\nFor detailed workflows, see [Model Training Workflow](#4.1) and [Flood Detection Example](#4.3).\n\n**Sources:** [docs/design/scenarios/model-training.md:1-53](), [docs/design/scenarios/flood-example.md:1-72]()\n\n---\n\n## Standards and Technologies\n\nThe MLOps Building Block is built on industry-standard technologies and protocols:\n\n| Standard/Technology | Purpose | Implementation |\n|---------------------|---------|----------------|\n| **STAC** | Geospatial asset catalog standard | Root catalog, collections, items with ml-model extension |\n| **MLflow** | ML lifecycle management | Tracking server, model registry, artifact storage |\n| **DVC** | Data version control | Git-based data versioning with S3 remote storage |\n| **ONNX** | Interoperable model format | Model export and inference standardization |\n| **CWL** | Workflow description | Inference workflow automation |\n| **OAuth/OIDC** | Authentication | Keycloak integration for GitLab and SharingHub |\n| **S3 API** | Object storage | Artifact and dataset storage |\n| **Kubernetes** | Container orchestration | Deployment platform with Helm charts |\n| **ArgoCD** | GitOps | Declarative deployment management |\n\n**Sources:** [docs/index.md:22-29](), [mkdocs.yml:1-125]()\n\n---\n\n## Project Templates and Examples\n\nThe platform provides ready-to-use templates and demonstration projects:\n\n- **MLOps Templates Repository**: [`EOEPCA/mlops-templates`](https://github.com/EOEPCA/mlops-templates/) - Project templates for ML models and datasets\n- **Flood Model**: [`EOEPCA/flood-model`](https://github.com/EOEPCA/flood-model) - Demonstration image segmentation model for flood detection\n- **Sen1Floods11 Dataset**: [`EOEPCA/Sen1Floods11-Dataset`](https://github.com/EOEPCA/Sen1Floods11-Dataset/) - Demonstration dataset for flood detection\n\nThese resources provide starting points for creating new ML projects compatible with the platform's workflows and conventions.\n\n**Sources:** [docs/index.md:39-44](), [docs/design/scenarios/flood-example.md:9-13]()\n\n---\n\n## Documentation Structure\n\nThis documentation is organized into the following sections:\n\n1. **Overview** (current page) - System introduction and capabilities\n2. **[Architecture](#2)** - Design principles, requirements, and use cases\n3. **[Core Components](#3)** - Detailed documentation of GitLab, SharingHub, and MLflow SharingHub\n4. **[Workflows and Scenarios](#4)** - Practical guides for model training, dataset management, and examples\n5. **[Deployment Guide](#5)** - Kubernetes deployment with prerequisites, component deployment steps\n6. **[Configuration Reference](#6)** - Comprehensive configuration documentation\n7. **[API Reference](#7)** - STAC API specification and usage examples\n8. **[Operations and Maintenance](#8)** - Maintenance guidelines and best practices\n\n**Sources:** [mkdocs.yml:6-33](), [docs/index.md:1-15]()\n\n---\n\n## Next Steps\n\nTo get started with the EOEPCA MLOps Building Block:\n\n1. **Understand the Architecture**: Read [Architecture](#2) to understand system design and component relationships\n2. **Deploy the Platform**: Follow [Deployment Guide](#5) for Kubernetes installation\n3. **Explore Workflows**: Review [Model Training Workflow](#4.1) to understand the end-to-end process\n4. **Try an Example**: Work through the [Flood Detection Example](#4.3) for hands-on experience\n5. **Configure Your Deployment**: Consult [Configuration Reference](#6) for customization options\n6. **Use the API**: Learn to interact programmatically via [API Reference](#7)\n\n**Sources:** [docs/index.md:1-15](), [mkdocs.yml:6-33]()"])</script><script>self.__next_f.push([1,"18:T4a9f,"])</script><script>self.__next_f.push([1,"# Architecture\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/design/architecture.md](docs/design/architecture.md)\n- [docs/design/diagrams/mlops-archi.drawio.png](docs/design/diagrams/mlops-archi.drawio.png)\n- [docs/design/diagrams/mlops-overview.drawio.png](docs/design/diagrams/mlops-overview.drawio.png)\n- [docs/index.md](docs/index.md)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis document describes the overall system architecture of the EOEPCA MLOps Building Block, including its core components, their relationships, and deployment patterns. It covers the high-level design principles, component integration patterns, data flow, and security architecture.\n\nFor specific deployment instructions, see [Deployment Guide](#5). For detailed configuration options, see [Configuration Reference](#6). For API usage details, see [API Reference](#7).\n\nSources: [docs/design/architecture.md:1-76](), [docs/index.md:1-45]()\n\n## System Overview\n\nThe MLOps Building Block provides a complete platform for training, managing, and discovering machine learning models within the EOEPCA ecosystem. The architecture is built on three core components that work together to provide an integrated MLOps solution:\n\n1. **GitLab** - Provides version control, project management, and CI/CD capabilities\n2. **SharingHub** - Enables discovery and collaboration through a STAC API catalog\n3. **MLflow SharingHub** - Manages experiment tracking and model registry\n\nThese components are deployed on Kubernetes and share common infrastructure services including S3 object storage, PostgreSQL databases, and centralized authentication through Keycloak.\n\n```mermaid\ngraph TB\n    subgraph \"User Personas\"\n        MLDev[\"ML Developer\"]\n        DataSci[\"Data Scientist\"]\n        MLUser[\"ML User / Operator\"]\n    end\n    \n    subgraph \"Core Components\"\n        GL[\"GitLab\u003cbr/\u003eCode \u0026 CI/CD\"]\n        SH[\"SharingHub\u003cbr/\u003eDiscovery Platform\"]\n        MLF[\"MLflow SharingHub\u003cbr/\u003eExperiment Tracking\"]\n    end\n    \n    subgraph \"Infrastructure Services\"\n        S3[\"S3 Object Storage\u003cbr/\u003eArtifacts \u0026 Data\"]\n        PG[\"PostgreSQL\u003cbr/\u003eMetadata Store\"]\n        KC[\"Keycloak\u003cbr/\u003eIdentity Provider\"]\n    end\n    \n    subgraph \"APIs \u0026 Interfaces\"\n        STACAPI[\"STAC API\"]\n        MLFAPI[\"MLflow Tracking API\"]\n        WebUI[\"Web Interface\"]\n    end\n    \n    MLDev --\u003e|\"1. Browse \u0026 Train\"| WebUI\n    DataSci --\u003e|\"2. Publish Datasets\"| WebUI\n    MLUser --\u003e|\"3. Download Models\"| STACAPI\n    \n    WebUI --\u003e SH\n    WebUI --\u003e MLF\n    WebUI --\u003e GL\n    \n    SH --\u003e|\"Exposes\"| STACAPI\n    SH --\u003e|\"Extracts metadata from\"| GL\n    \n    MLF --\u003e|\"Provides\"| MLFAPI\n    MLF --\u003e|\"Checks permissions via\"| SH\n    MLF --\u003e|\"Stores metadata\"| PG\n    MLF --\u003e|\"Stores artifacts\"| S3\n    \n    GL --\u003e|\"Authenticates via OIDC\"| KC\n    GL --\u003e|\"Stores backups\"| S3\n    \n    SH --\u003e|\"Authenticates via OAuth\"| GL\n```\n\n**Diagram: High-Level System Architecture**\n\nSources: [docs/design/architecture.md:6-29](), [docs/index.md:16-38]()\n\n## Core Components\n\n### GitLab\n\nGitLab serves as the foundation of the MLOps platform, providing version control, project organization, and CI/CD capabilities. Projects in GitLab are tagged with specific topics (e.g., `sharinghub:aimodel`, `sharinghub:dataset`) to categorize them for discovery through SharingHub.\n\n**Key Responsibilities:**\n- Source code version control using Git\n- Project metadata storage (topics, tags, descriptions)\n- CI/CD pipeline execution\n- Large File Storage (LFS) for model artifacts\n- Authentication gateway via OIDC integration with Keycloak\n\n**Integration Points:**\n- SharingHub extracts project metadata via GitLab API\n- MLflow can be integrated directly into GitLab projects\n- Backup storage in S3\n- User authentication delegated to Keycloak\n\n```mermaid\ngraph LR\n    subgraph \"GitLab Components\"\n        GWS[\"gitlab-webservice\u003cbr/\u003epods\"]\n        GSK[\"gitlab-sidekiq\u003cbr/\u003ebackground jobs\"]\n        GKAS[\"gitlab-kas\u003cbr/\u003eagent server\"]\n        GPG[\"gitlab-postgresql\u003cbr/\u003edatabase\"]\n        GRED[\"gitlab-redis\u003cbr/\u003ecache\"]\n    end\n    \n    subgraph \"External Storage\"\n        S3[\"S3 Buckets\u003cbr/\u003egitlab-backups\u003cbr/\u003egitlab-lfs\"]\n    end\n    \n    subgraph \"Authentication\"\n        KC[\"Keycloak\u003cbr/\u003eOIDC Provider\"]\n    end\n    \n    USER[\"Users\"] --\u003e|\"HTTPS\"| GWS\n    GWS --\u003e GPG\n    GWS --\u003e GRED\n    GWS --\u003e|\"OAuth/OIDC\"| KC\n    GSK --\u003e GPG\n    GSK --\u003e S3\n    GWS --\u003e|\"LFS Objects\"| S3\n    GKAS --\u003e|\"Agent connections\"| GWS\n```\n\n**Diagram: GitLab Component Architecture**\n\nSources: [docs/design/architecture.md:52-76]()\n\n### SharingHub\n\nSharingHub is a lightweight discovery and collaboration platform deployed on top of GitLab. It dynamically extracts metadata from GitLab projects and exposes them through a standardized STAC API, making AI models and datasets discoverable.\n\n**Key Responsibilities:**\n- Dynamic STAC catalog generation from GitLab projects\n- STAC API implementation for standardized discovery\n- OAuth-based authentication against GitLab\n- Permission checking for private resources\n- Metadata extraction and STAC item creation\n- Integration with S3 for asset storage\n\n**STAC Catalog Structure:**\n\nThe SharingHub generates a STAC catalog with the following structure:\n- **Root Catalog**: Single root with ID `gitlab-cs`\n- **Collections**: Mapped from GitLab topics (e.g., `sharinghub:aimodel`  AI Model Collection)\n- **Items**: One STAC item per GitLab project, with appropriate STAC extensions\n\n```mermaid\ngraph TB\n    subgraph \"STAC Catalog Hierarchy\"\n        ROOT[\"STAC Root Catalog\u003cbr/\u003eid: gitlab-cs\"]\n        \n        subgraph \"Collections (mapped from GitLab topics)\"\n            COLL_AI[\"AI Model Collection\u003cbr/\u003egitlab_topic: sharinghub:aimodel\"]\n            COLL_DS[\"Dataset Collection\u003cbr/\u003egitlab_topic: sharinghub:dataset\"]\n            COLL_PROC[\"Processor Collection\u003cbr/\u003egitlab_topic: sharinghub:processor\"]\n        end\n        \n        subgraph \"STAC Items (one per project)\"\n            ITEM1[\"flood-model\u003cbr/\u003eml-model extension\u003cbr/\u003eONNX assets\"]\n            ITEM2[\"sen1floods11-dataset\u003cbr/\u003eeo extension\u003cbr/\u003eGeoTIFF assets\"]\n            ITEM3[\"wine-quality-model\u003cbr/\u003eml-model extension\u003cbr/\u003eCSV + ONNX\"]\n        end\n        \n        ROOT --\u003e COLL_AI\n        ROOT --\u003e COLL_DS\n        ROOT --\u003e COLL_PROC\n        \n        COLL_AI --\u003e|\"topic filter\"| ITEM1\n        COLL_AI --\u003e|\"topic filter\"| ITEM3\n        COLL_DS --\u003e|\"topic filter\"| ITEM2\n    end\n    \n    subgraph \"GitLab Projects\"\n        GP1[\"Project: flood-model\u003cbr/\u003eTopic: sharinghub:aimodel\"]\n        GP2[\"Project: sen1floods11\u003cbr/\u003eTopic: sharinghub:dataset\"]\n        GP3[\"Project: wine-quality\u003cbr/\u003eTopic: sharinghub:aimodel\"]\n    end\n    \n    GP1 -.metadata extraction.-\u003e ITEM1\n    GP2 -.metadata extraction.-\u003e ITEM2\n    GP3 -.metadata extraction.-\u003e ITEM3\n```\n\n**Diagram: STAC Catalog Structure and GitLab Mapping**\n\nSources: [docs/design/architecture.md:52-76](), [docs/index.md:22-28]()\n\n### MLflow SharingHub\n\nMLflow SharingHub is a customized MLflow deployment that integrates with SharingHub for permission management and with S3 for artifact storage. It provides experiment tracking and a model registry.\n\n**Key Responsibilities:**\n- Experiment tracking API for logging metrics, parameters, and artifacts\n- Model registry for versioning and staging models\n- Permission checking delegated to SharingHub\n- PostgreSQL backend for metadata storage\n- S3 artifact store for model files and training artifacts\n- Integration with SharingHub for automatic STAC item creation\n\n**Architecture:**\n\n```mermaid\ngraph TB\n    subgraph \"MLflow SharingHub Components\"\n        MLFSERVER[\"mlflow-sharinghub\u003cbr/\u003etracking server\"]\n        MLFPG[\"mlflow-postgresql\u003cbr/\u003ebackend store\"]\n    end\n    \n    subgraph \"Storage\"\n        S3[\"S3 Bucket\u003cbr/\u003emlflow-artifacts\u003cbr/\u003emodels, metrics, logs\"]\n    end\n    \n    subgraph \"Integration\"\n        SH[\"SharingHub\u003cbr/\u003epermission checking\"]\n    end\n    \n    CLIENT[\"MLflow Client\u003cbr/\u003ePython SDK\"] --\u003e|\"MLflow Tracking API\"| MLFSERVER\n    \n    MLFSERVER --\u003e|\"Check permissions\"| SH\n    MLFSERVER --\u003e|\"Store metadata\u003cbr/\u003eexperiments, runs, metrics\"| MLFPG\n    MLFSERVER --\u003e|\"Store artifacts\u003cbr/\u003emodels, plots, logs\"| S3\n    \n    MLFSERVER --\u003e|\"Auto-link registered models\"| SH\n    SH -.-\u003e|\"Creates STAC items\"| STACITEM[\"STAC Item with\u003cbr/\u003eml-model extension\"]\n```\n\n**Diagram: MLflow SharingHub Integration**\n\nSources: [docs/design/architecture.md:52-76]()\n\n## Data Flow and Integration Patterns\n\n### End-to-End Model Training Workflow\n\nThe following diagram illustrates the complete lifecycle of training and publishing a machine learning model:\n\n```mermaid\nsequenceDiagram\n    participant Dev as ML Developer\n    participant GL as GitLab\n    participant SH as SharingHub\n    participant MLF as MLflow SharingHub\n    participant S3 as S3 Storage\n    \n    Note over Dev,S3: 1. Project Setup\n    Dev-\u003e\u003eGL: Create project with topic sharinghub:aimodel\n    GL--\u003e\u003eSH: Webhook notification (project created)\n    SH-\u003e\u003eGL: Extract metadata via API\n    SH--\u003e\u003eDev: Project appears in STAC catalog\n    \n    Note over Dev,S3: 2. Model Training\n    Dev-\u003e\u003eSH: Browse datasets via STAC API\n    Dev-\u003e\u003eMLF: Initialize MLflow tracking (mlflow.set_tracking_uri)\n    Dev-\u003e\u003eMLF: Log parameters (mlflow.log_param)\n    Dev-\u003e\u003eMLF: Log metrics (mlflow.log_metric)\n    MLF-\u003e\u003eS3: Store training artifacts\n    MLF-\u003e\u003eSH: Check project permissions\n    \n    Note over Dev,S3: 3. Model Registration\n    Dev-\u003e\u003eMLF: Register model (mlflow.register_model)\n    MLF-\u003e\u003eS3: Store model artifacts (ONNX file)\n    MLF-\u003e\u003eSH: Create/update STAC item with ml-model extension\n    SH--\u003e\u003eDev: Model discoverable in catalog\n```\n\n**Diagram: Model Training and Registration Flow**\n\nSources: [docs/design/architecture.md:10-28]()\n\n### STAC Item Creation and Metadata Extraction\n\nSharingHub dynamically generates STAC items from GitLab projects using the following process:\n\n```mermaid\nflowchart TD\n    START[\"GitLab Project\u003cbr/\u003ewith sharinghub topic\"] --\u003e WEBHOOK[\"GitLab Webhook\u003cbr/\u003eproject update event\"]\n    \n    WEBHOOK --\u003e EXTRACT[\"SharingHub extracts metadata\u003cbr/\u003e- Project name/description\u003cbr/\u003e- Topics and tags\u003cbr/\u003e- README content\u003cbr/\u003e- LFS objects\"]\n    \n    EXTRACT --\u003e MAP[\"Map to STAC Item\u003cbr/\u003e- id: project path\u003cbr/\u003e- title: project name\u003cbr/\u003e- description: README\u003cbr/\u003e- assets: LFS files\"]\n    \n    MAP --\u003e EXT{\"Determine STAC Extensions\"}\n    \n    EXT --\u003e|\"Topic: aimodel\"| MLEXT[\"Add ml-model extension\u003cbr/\u003e- ml-model:architecture\u003cbr/\u003e- ml-model:training-processor-type\u003cbr/\u003e- ml-model:training-os\u003cbr/\u003e- ml-model:memory_size\"]\n    \n    EXT --\u003e|\"Topic: dataset\"| EOEXT[\"Add eo extension\u003cbr/\u003e- eo:bands\u003cbr/\u003e- eo:gsd\"]\n    \n    MLEXT --\u003e ASSETS[\"Generate asset links\u003cbr/\u003e- model files (ONNX)\u003cbr/\u003e- metadata files\u003cbr/\u003e- documentation\"]\n    \n    EOEXT --\u003e ASSETS\n    \n    ASSETS --\u003e PUBLISH[\"Publish STAC Item\u003cbr/\u003eAvailable via STAC API\"]\n    \n    PUBLISH --\u003e MLF_CHECK{\"MLflow model\u003cbr/\u003eregistered?\"}\n    \n    MLF_CHECK --\u003e|\"Yes\"| LINK[\"Auto-link MLflow model\u003cbr/\u003eAdd mlflow:run_id property\"]\n    MLF_CHECK --\u003e|\"No\"| END[\"STAC Item available\"]\n    LINK --\u003e END\n```\n\n**Diagram: STAC Item Creation Process**\n\nSources: [docs/design/architecture.md:52-76]()\n\n## Deployment Architecture\n\nThe MLOps Building Block is deployed on Kubernetes using ArgoCD for GitOps-style continuous deployment. All components are namespaced for isolation and share common infrastructure services.\n\n### Kubernetes Architecture\n\n```mermaid\ngraph TB\n    subgraph \"Kubernetes Cluster\"\n        subgraph \"argocd namespace\"\n            ARGO[\"ArgoCD Applications\u003cbr/\u003e- gitlab-app.yaml\u003cbr/\u003e- sharinghub-app.yaml\u003cbr/\u003e- mlflow-sharinghub-app.yaml\"]\n        end\n        \n        subgraph \"gitlab namespace\"\n            GLPODS[\"GitLab Pods\u003cbr/\u003e- webservice\u003cbr/\u003e- sidekiq\u003cbr/\u003e- kas\"]\n            GLPG[\"gitlab-postgresql\u003cbr/\u003eStatefulSet\"]\n            GLREDIS[\"gitlab-redis\u003cbr/\u003eStatefulSet\"]\n            GLINGRESS[\"Ingress\u003cbr/\u003egitlab.domain\"]\n        end\n        \n        subgraph \"sharinghub namespace\"\n            SHPOD[\"sharinghub\u003cbr/\u003eDeployment\"]\n            SHINGRESS[\"Ingress\u003cbr/\u003esharinghub.domain\"]\n        end\n        \n        subgraph \"mlflow namespace\"\n            MLFPOD[\"mlflow-sharinghub\u003cbr/\u003eDeployment\"]\n            MLFPG[\"mlflow-postgresql\u003cbr/\u003eStatefulSet\"]\n            MLFINGRESS[\"Ingress\u003cbr/\u003esharinghub.domain/mlflow\"]\n        end\n        \n        subgraph \"cert-manager namespace\"\n            CERT[\"cert-manager\u003cbr/\u003eTLS automation\"]\n        end\n        \n        subgraph \"Shared Infrastructure\"\n            NGINX[\"NGINX Ingress Controller\"]\n        end\n    end\n    \n    subgraph \"External Services\"\n        S3EXT[\"S3 Storage Provider\u003cbr/\u003e- gitlab-lfs\u003cbr/\u003e- gitlab-backups\u003cbr/\u003e- mlflow-artifacts\"]\n        KCEXT[\"Keycloak\u003cbr/\u003eOIDC Provider\"]\n        HELM[\"Helm Repositories\u003cbr/\u003e- charts.gitlab.io\u003cbr/\u003e- csgroup-oss\"]\n    end\n    \n    ARGO --\u003e|\"Syncs from Git\"| GLPODS\n    ARGO --\u003e|\"Syncs from Git\"| SHPOD\n    ARGO --\u003e|\"Syncs from Git\"| MLFPOD\n    ARGO -.-\u003e|\"Pulls charts\"| HELM\n    \n    GLINGRESS --\u003e NGINX\n    SHINGRESS --\u003e NGINX\n    MLFINGRESS --\u003e NGINX\n    \n    NGINX --\u003e|\"Requests certs\"| CERT\n    \n    GLPODS --\u003e GLPG\n    GLPODS --\u003e GLREDIS\n    GLPODS --\u003e S3EXT\n    GLPODS --\u003e|\"OIDC auth\"| KCEXT\n    \n    SHPOD --\u003e GLPODS\n    SHPOD --\u003e S3EXT\n    \n    MLFPOD --\u003e MLFPG\n    MLFPOD --\u003e S3EXT\n    MLFPOD --\u003e|\"Permission check\"| SHPOD\n```\n\n**Diagram: Kubernetes Deployment Architecture**\n\nSources: [docs/design/architecture.md:52-76]()\n\n### Namespace and Resource Organization\n\nEach component is deployed in its own Kubernetes namespace to provide isolation:\n\n| Namespace | Components | Purpose |\n|-----------|-----------|---------|\n| `argocd` | ArgoCD Applications | GitOps deployment management |\n| `gitlab` | GitLab webservice, sidekiq, kas, postgresql, redis | Version control and CI/CD |\n| `sharinghub` | SharingHub application | Discovery and STAC API |\n| `mlflow` | MLflow server, postgresql | Experiment tracking |\n| `cert-manager` | cert-manager controllers | TLS certificate automation |\n| Shared | NGINX Ingress Controller | Traffic routing |\n\n**Persistent Storage:**\n- PostgreSQL databases use persistent volumes for data durability\n- GitLab and MLflow artifacts stored in external S3 buckets\n- Configuration managed via Kubernetes Secrets and ConfigMaps\n\nSources: [docs/design/architecture.md:52-76]()\n\n## Security and Authentication Architecture\n\nThe security architecture is built on centralized authentication through Keycloak with OAuth/OIDC flows, and permission delegation between components.\n\n### Authentication Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Browser\n    participant NGINX as NGINX Ingress\n    participant GL as GitLab\n    participant SH as SharingHub\n    participant MLF as MLflow SharingHub\n    participant KC as Keycloak\n    \n    Note over User,KC: 1. User Access to GitLab\n    User-\u003e\u003eBrowser: Access gitlab.domain\n    Browser-\u003e\u003eNGINX: HTTPS Request\n    NGINX-\u003e\u003eGL: Forward request\n    GL--\u003e\u003eBrowser: Redirect to Keycloak\n    Browser-\u003e\u003eKC: OAuth/OIDC login\n    KC--\u003e\u003eBrowser: Return token\n    Browser-\u003e\u003eGL: Request with token\n    GL-\u003e\u003eKC: Validate token\n    KC--\u003e\u003eGL: Token valid\n    GL--\u003e\u003eBrowser: Grant access\n    \n    Note over User,KC: 2. SharingHub API Access\n    User-\u003e\u003eSH: Access STAC API\n    SH-\u003e\u003eGL: OAuth token exchange\n    GL-\u003e\u003eKC: Validate via OIDC\n    KC--\u003e\u003eGL: User identity\n    GL--\u003e\u003eSH: User info + permissions\n    SH--\u003e\u003eUser: Filtered catalog (based on permissions)\n    \n    Note over User,KC: 3. MLflow Tracking\n    User-\u003e\u003eMLF: Log experiment via MLflow API\n    MLF-\u003e\u003eSH: Check project permissions\n    SH-\u003e\u003eGL: Verify project access\n    GL--\u003e\u003eSH: Access granted/denied\n    SH--\u003e\u003eMLF: Permission result\n    MLF--\u003e\u003eUser: Allow/deny operation\n```\n\n**Diagram: Authentication and Authorization Flow**\n\n### Secrets Management\n\nAll sensitive credentials are stored in Kubernetes Secrets:\n\n| Secret Name | Namespace | Purpose |\n|-------------|-----------|---------|\n| `gitlab-oidc` | `gitlab` | Keycloak client credentials for GitLab |\n| `sharinghub-oidc` | `sharinghub` | OAuth credentials for SharingHub |\n| `sharinghub-oidc-default-token` | `sharinghub` | Optional token for public read access |\n| `mlflow-sharinghub` | `mlflow` | Secret key for MLflow server |\n| `*-tls` | Various | TLS certificates from cert-manager |\n\n**TLS Security:**\n- All external traffic encrypted via HTTPS\n- Certificates automatically provisioned by cert-manager\n- Let's Encrypt used as Certificate Authority\n- Certificates stored as Kubernetes TLS Secrets\n\nSources: [docs/design/architecture.md:52-76]()\n\n### Permission Model\n\nThe permission model is hierarchical and delegated:\n\n```mermaid\nflowchart TD\n    KC[\"Keycloak\u003cbr/\u003eIdentity Provider\"] --\u003e|\"OIDC authentication\"| GL[\"GitLab\u003cbr/\u003eSource of Truth for Permissions\"]\n    \n    GL --\u003e|\"Project membership\u003cbr/\u003epublic/private visibility\"| PERMS[\"GitLab Project Permissions\u003cbr/\u003e- Owner\u003cbr/\u003e- Maintainer\u003cbr/\u003e- Developer\u003cbr/\u003e- Reporter\u003cbr/\u003e- Guest\"]\n    \n    PERMS --\u003e|\"OAuth token exchange\"| SH[\"SharingHub\u003cbr/\u003eEnforces permissions on STAC API\"]\n    \n    SH --\u003e|\"Filtered catalog\u003cbr/\u003ebased on user access\"| STACAPI[\"STAC API Response\u003cbr/\u003eOnly accessible projects\"]\n    \n    MLF[\"MLflow SharingHub\"] --\u003e|\"Permission check API\"| SH\n    \n    SH --\u003e|\"Validates against GitLab\"| GL\n    \n    USER[\"User\"] -.-\u003e|\"1. Authenticates\"| KC\n    USER -.-\u003e|\"2. Accesses\"| STACAPI\n    USER -.-\u003e|\"3. Logs experiments\"| MLF\n```\n\n**Diagram: Permission Delegation Model**\n\n**Permission Rules:**\n- GitLab project permissions define who can access models and datasets\n- SharingHub filters STAC catalog based on user's GitLab project access\n- MLflow delegates all permission checks to SharingHub\n- Public projects visible to anonymous users (if `sharinghub-oidc-default-token` configured)\n- Private projects only visible to authenticated users with access\n\nSources: [docs/design/architecture.md:52-76]()\n\n## Design Principles\n\nThe MLOps Building Block architecture follows these key design principles:\n\n1. **Separation of Concerns**: Each component has a well-defined responsibility\n   - GitLab: Version control and project management\n   - SharingHub: Discovery and metadata management\n   - MLflow: Experiment tracking and model registry\n\n2. **Standards-Based Integration**: Uses established standards for interoperability\n   - STAC for spatial data discovery\n   - ONNX for framework-agnostic model representation\n   - OAuth/OIDC for authentication\n\n3. **GitOps Deployment**: Infrastructure as code with ArgoCD\n   - Declarative configuration in Git repositories\n   - Automated synchronization and drift detection\n   - Version-controlled deployment history\n\n4. **Cloud-Native Architecture**: Designed for Kubernetes environments\n   - Containerized components\n   - Horizontal scalability\n   - Health checks and self-healing\n\n5. **Security by Default**: Centralized authentication and fine-grained permissions\n   - OIDC integration with Keycloak\n   - Project-level access control via GitLab\n   - TLS encryption for all external traffic\n\nSources: [docs/design/architecture.md:1-76](), [docs/index.md:16-45]()"])</script><script>self.__next_f.push([1,"19:T4150,"])</script><script>self.__next_f.push([1,"# Requirements\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/design/diagrams/mlops-requirements.drawio.png](docs/design/diagrams/mlops-requirements.drawio.png)\n- [docs/design/requirements.md](docs/design/requirements.md)\n\n\u003c/details\u003e\n\n\n\nThis page documents the functional requirements for the EOEPCA MLOps Building Block. These requirements define the capabilities that must be provided by the Model Trainer, Training Data Manager, and MLOps UI components. The requirements establish the behavioral specifications that the system architecture and implementation must satisfy.\n\nFor information about how these requirements translate into practical user workflows and scenarios, see [Use Cases](#2.2). For details on the specific components that implement these requirements, see [GitLab](#3.1), [SharingHub](#3.2), and [MLflow SharingHub](#3.3).\n\n**Sources:** [docs/design/requirements.md:1-35]()\n\n---\n\n## Requirements Overview\n\nThe MLOps Building Block requirements are organized into three functional categories, each addressing a distinct aspect of the machine learning operations lifecycle:\n\n| Category | Code Range | Component Mapping | Primary Responsibility |\n|----------|------------|-------------------|------------------------|\n| **Model Trainer** | BR086-BR094 | MLflow SharingHub | Experiment tracking, model registry, version management |\n| **Training Data Manager** | BR095-BR096 | GitLab + DVC + SharingHub | Dataset versioning, metadata management, discovery |\n| **MLOps UI** | BR097 | GitLab UI + SharingHub UI + MLflow UI | Web-based access to all platform capabilities |\n\nThe requirements are designed to support a complete MLOps workflow from dataset preparation through model training, versioning, and publication for reuse.\n\n**Sources:** [docs/design/requirements.md:13-35]()\n\n---\n\n## Requirements to Component Mapping\n\nThe following diagram illustrates how the functional requirements map to the three core components of the MLOps Building Block:\n\n```mermaid\ngraph TB\n    subgraph \"Functional Requirements\"\n        MT[\"Model Trainer Requirements\u003cbr/\u003eBR086-BR094\"]\n        TDM[\"Training Data Manager Requirements\u003cbr/\u003eBR095-BR096\"]\n        UI[\"MLOps UI Requirements\u003cbr/\u003eBR097\"]\n    end\n    \n    subgraph \"Implementation Components\"\n        MLF[\"MLflow SharingHub\u003cbr/\u003edocker.io/eoepca/mlflow-sharinghub\"]\n        GL[\"GitLab\u003cbr/\u003egitlab.com/gitlab-org/gitlab\"]\n        DVC[\"DVC\u003cbr/\u003eData Version Control\"]\n        SH[\"SharingHub\u003cbr/\u003egitlab.com/eoepca/sharinghub\"]\n    end\n    \n    subgraph \"Storage Backend\"\n        PG[\"PostgreSQL\u003cbr/\u003emlflow_backend_store\"]\n        S3[\"S3 Object Storage\u003cbr/\u003emlflow_artifacts\"]\n        GLPG[\"GitLab PostgreSQL\u003cbr/\u003egitlab_database\"]\n    end\n    \n    subgraph \"API Layer\"\n        MLFAPI[\"MLflow Tracking API\u003cbr/\u003e/api/2.0/mlflow/*\"]\n        STACAPI[\"STAC API\u003cbr/\u003e/api/stac/v1/*\"]\n        GLAPI[\"GitLab REST API\u003cbr/\u003e/api/v4/*\"]\n    end\n    \n    MT --\u003e|\"BR086-BR092\"| MLF\n    MT --\u003e|\"BR093\"| MLF\n    MT --\u003e|\"BR094\"| SH\n    \n    TDM --\u003e|\"BR095\"| DVC\n    TDM --\u003e|\"BR095\"| GL\n    TDM --\u003e|\"BR096\"| SH\n    \n    UI --\u003e|\"BR097-1\"| MLF\n    UI --\u003e|\"BR097-2\"| GL\n    UI --\u003e|\"BR097-2\"| SH\n    \n    MLF --\u003e MLFAPI\n    MLF --\u003e PG\n    MLF --\u003e S3\n    \n    GL --\u003e GLAPI\n    GL --\u003e GLPG\n    \n    DVC --\u003e GL\n    DVC --\u003e S3\n    \n    SH --\u003e STACAPI\n    SH --\u003e GLAPI\n```\n\n**Sources:** [docs/design/requirements.md:1-35]()\n\n---\n\n## Model Trainer Requirements (BR086-BR094)\n\nThe Model Trainer requirements define capabilities for managing the complete machine learning training lifecycle, including experiment tracking, model versioning, and model registry functionality. These requirements are primarily satisfied by **MLflow SharingHub**.\n\n### Detailed Requirements\n\n| Requirement ID | Description | Implementation Component |\n|----------------|-------------|--------------------------|\n| **BR086** | Support management of ML training for popular frameworks (TensorFlow, PyTorch, Keras, etc.) | MLflow autologging, MLflow tracking API |\n| **BR087** | Support interoperable model representations (ONNX) | MLflow model registry with ONNX format support |\n| **BR088** | Support initiation of training runs and capture resultant metrics | MLflow tracking API, `mlflow.log_metric()`, `mlflow.log_param()` |\n| **BR089** | Maintain history of runs with parameterization, datasets, and metrics | PostgreSQL backend store, MLflow experiments and runs database |\n| **BR090** | Persist model assets in platform storage with workspace integration | S3 artifacts store, MLflow artifact logging |\n| **BR091** | Support applying versions to generated models | MLflow model registry, `mlflow.register_model()` |\n| **BR092** | Register versioned models in Resource Discovery for sharing | SharingHub STAC API integration, automatic STAC item generation |\n| **BR093** | Provide Web UI for training run history management | MLflow UI at `/mlflow` endpoint |\n| **BR094** | Support integration as service within Workspace BB | RESTful API, authentication via SharingHub |\n\n**Sources:** [docs/design/requirements.md:13-24]()\n\n---\n\n### Model Trainer Implementation Architecture\n\nThe following diagram shows how MLflow SharingHub implements the Model Trainer requirements:\n\n```mermaid\ngraph TB\n    subgraph \"User Code\"\n        TRAIN[\"Training Script\u003cbr/\u003etrain.py\"]\n        CLIENT[\"MLflow Client\u003cbr/\u003emlflow.start_run()\"]\n    end\n    \n    subgraph \"MLflow SharingHub Container\"\n        FLASK[\"Flask Application\u003cbr/\u003eapp.py\"]\n        TRACKING[\"Tracking Service\u003cbr/\u003e/api/2.0/mlflow/runs/*\"]\n        REGISTRY[\"Model Registry\u003cbr/\u003e/api/2.0/mlflow/registered-models/*\"]\n        AUTOLOG[\"Auto-logging\u003cbr/\u003emlflow.autolog()\"]\n    end\n    \n    subgraph \"Storage Layer\"\n        PGDB[\"PostgreSQL\u003cbr/\u003eexperiments, runs, metrics\u003cbr/\u003eregistered_models, model_versions\"]\n        S3STORE[\"S3 Bucket\u003cbr/\u003emodel artifacts\u003cbr/\u003eONNX files, pkl files\"]\n    end\n    \n    subgraph \"Integration Layer\"\n        SHINT[\"SharingHub Integration\u003cbr/\u003epermission_check()\"]\n        STACGEN[\"STAC Item Generator\u003cbr/\u003eml-model extension\"]\n    end\n    \n    TRAIN --\u003e|\"BR086: Log experiments\"| CLIENT\n    CLIENT --\u003e|\"BR088: POST /runs/create\"| TRACKING\n    AUTOLOG --\u003e|\"BR086: Framework metrics\"| TRACKING\n    \n    TRACKING --\u003e|\"BR089: Store run history\"| PGDB\n    TRACKING --\u003e|\"BR090: Store artifacts\"| S3STORE\n    \n    CLIENT --\u003e|\"BR091: POST /registered-models/create\"| REGISTRY\n    REGISTRY --\u003e|\"BR091: Version management\"| PGDB\n    REGISTRY --\u003e|\"BR087: Store ONNX models\"| S3STORE\n    \n    REGISTRY --\u003e|\"BR092: Auto-publish\"| STACGEN\n    STACGEN --\u003e|\"BR092: Generate STAC item\"| SHINT\n    \n    FLASK --\u003e|\"BR093: Serve UI\"| MLUI[\"MLflow Web UI\u003cbr/\u003e/mlflow\"]\n    FLASK --\u003e|\"BR094: Check permissions\"| SHINT\n```\n\n**Sources:** [docs/design/requirements.md:13-24]()\n\n---\n\n## Training Data Manager Requirements (BR095-BR096)\n\nThe Training Data Manager requirements define capabilities for version-controlled dataset management with metadata standards compliance. These requirements are satisfied through the combination of **GitLab**, **DVC**, and **SharingHub**.\n\n### Detailed Requirements\n\n| Requirement ID | Description | Implementation Component |\n|----------------|-------------|--------------------------|\n| **BR095** | Support version-controlled management of training datasets with STAC metadata | GitLab repository versioning, DVC data versioning, SharingHub STAC catalog generation |\n| **BR096** | Register versioned ML training data in Resource Discovery for sharing | SharingHub STAC API, GitLab topics filtering (`sharinghub:dataset`) |\n\n**Sources:** [docs/design/requirements.md:25-29]()\n\n---\n\n### Training Data Manager Implementation Architecture\n\nThe following diagram illustrates how GitLab, DVC, and SharingHub work together to satisfy Training Data Manager requirements:\n\n```mermaid\ngraph TB\n    subgraph \"Dataset Project\"\n        REPO[\"GitLab Repository\u003cbr/\u003esen1floods11-dataset\"]\n        DVCFILE[\".dvc Files\u003cbr/\u003edata.dvc, train.csv.dvc\"]\n        METADATA[\"Metadata Files\u003cbr/\u003eREADME.md, stac_item.json\"]\n        TOPIC[\"GitLab Topic\u003cbr/\u003esharinghub:dataset\"]\n    end\n    \n    subgraph \"Version Control\"\n        GITLOG[\"Git Commit History\u003cbr/\u003egit log, git tag\"]\n        DVCTRACK[\"DVC Tracking\u003cbr/\u003edvc add, dvc push\"]\n    end\n    \n    subgraph \"Data Storage\"\n        S3DATA[\"S3 Bucket\u003cbr/\u003etraining-data/\u003cbr/\u003e*.tif, *.csv, *.npy\"]\n        DVCCACHE[\"DVC Cache\u003cbr/\u003e.dvc/cache/\"]\n    end\n    \n    subgraph \"SharingHub Discovery\"\n        CRAWLER[\"GitLab Metadata Extractor\u003cbr/\u003eget_gitlab_projects()\"]\n        STACCAT[\"STAC Catalog\u003cbr/\u003e/collections/dataset\"]\n        STACITEM[\"STAC Item\u003cbr/\u003eeo extension, assets\"]\n    end\n    \n    REPO --\u003e|\"BR095: Version control\"| GITLOG\n    REPO --\u003e|\"BR095: Add topic\"| TOPIC\n    REPO --\u003e|\"BR095: Commit metadata\"| METADATA\n    \n    DVCFILE --\u003e|\"BR095: Track data files\"| DVCTRACK\n    DVCTRACK --\u003e|\"BR095: Push data\"| S3DATA\n    DVCTRACK --\u003e|\"BR095: Local cache\"| DVCCACHE\n    \n    CRAWLER --\u003e|\"BR096: Filter by topic\"| TOPIC\n    CRAWLER --\u003e|\"BR096: Extract metadata\"| METADATA\n    CRAWLER --\u003e|\"BR096: Generate catalog\"| STACCAT\n    \n    STACCAT --\u003e|\"BR096: Create items\"| STACITEM\n    STACITEM --\u003e|\"BR096: Link to\"| S3DATA\n    \n    GITLOG -.-\u003e|\"BR095: Version tags\"| STACITEM\n```\n\n**Sources:** [docs/design/requirements.md:25-29]()\n\n---\n\n## MLOps UI Requirements (BR097)\n\nThe MLOps UI requirements define the web-based user interface capabilities for accessing training run history and training data management. These requirements are satisfied through the combination of **MLflow UI**, **GitLab UI**, and **SharingHub Web UI**.\n\n### Detailed Requirements\n\n| Requirement ID | Description | Implementation Component |\n|----------------|-------------|--------------------------|\n| **BR097-1** | Access training run history for model run management and performance assessment | MLflow UI at `/mlflow` endpoint, experiments dashboard, run comparison views |\n| **BR097-2** | Access training data for management, versioning, and metadata editing | GitLab project UI, DVC file browser, SharingHub catalog browser |\n\n**Sources:** [docs/design/requirements.md:30-35]()\n\n---\n\n### MLOps UI Implementation Architecture\n\nThe following diagram shows the three user interfaces and their responsibilities:\n\n```mermaid\ngraph TB\n    subgraph \"User Access\"\n        USER[\"Data Scientist / ML Developer\"]\n        BROWSER[\"Web Browser\u003cbr/\u003eHTTPS\"]\n    end\n    \n    subgraph \"MLflow UI\"\n        MLFUI[\"MLflow Web Interface\u003cbr/\u003esharinghub.domain/mlflow\"]\n        EXPVIEW[\"Experiments View\u003cbr/\u003e/experiments/\u003cexp_id\u003e\"]\n        RUNVIEW[\"Run Details View\u003cbr/\u003e/runs/\u003crun_id\u003e\"]\n        REGVIEW[\"Model Registry View\u003cbr/\u003e/models/\u003cmodel_name\u003e\"]\n        COMPARE[\"Run Comparison\u003cbr/\u003e/compare-runs\"]\n    end\n    \n    subgraph \"GitLab UI\"\n        GLUI[\"GitLab Web Interface\u003cbr/\u003egitlab.domain\"]\n        PROJVIEW[\"Project View\u003cbr/\u003e/\u003cnamespace\u003e/\u003cproject\u003e\"]\n        FILEVIEW[\"File Browser\u003cbr/\u003e/-/tree/main\"]\n        COMMIT[\"Commit History\u003cbr/\u003e/-/commits/main\"]\n        TAGS[\"Tags / Releases\u003cbr/\u003e/-/tags\"]\n    end\n    \n    subgraph \"SharingHub UI\"\n        SHUI[\"SharingHub Web Interface\u003cbr/\u003esharinghub.domain\"]\n        CATVIEW[\"Catalog Browser\u003cbr/\u003e/browse\"]\n        ITEMVIEW[\"Item Detail View\u003cbr/\u003e/item/\u003citem_id\u003e\"]\n        SEARCH[\"Search \u0026 Filter\u003cbr/\u003e/search\"]\n        DOWNLOAD[\"Download Assets\u003cbr/\u003e/download\"]\n    end\n    \n    USER --\u003e BROWSER\n    \n    BROWSER --\u003e|\"BR097-1: View experiments\"| MLFUI\n    MLFUI --\u003e EXPVIEW\n    MLFUI --\u003e RUNVIEW\n    MLFUI --\u003e REGVIEW\n    MLFUI --\u003e COMPARE\n    \n    BROWSER --\u003e|\"BR097-2: Manage datasets\"| GLUI\n    GLUI --\u003e PROJVIEW\n    GLUI --\u003e FILEVIEW\n    GLUI --\u003e COMMIT\n    GLUI --\u003e TAGS\n    \n    BROWSER --\u003e|\"BR097-1 \u0026 BR097-2: Discover resources\"| SHUI\n    SHUI --\u003e CATVIEW\n    SHUI --\u003e ITEMVIEW\n    SHUI --\u003e SEARCH\n    SHUI --\u003e DOWNLOAD\n    \n    EXPVIEW -.-\u003e|\"Links to GitLab project\"| PROJVIEW\n    REGVIEW -.-\u003e|\"Links to STAC item\"| ITEMVIEW\n    ITEMVIEW -.-\u003e|\"Links to GitLab project\"| PROJVIEW\n```\n\n**Sources:** [docs/design/requirements.md:30-35]()\n\n---\n\n## Requirements Traceability Matrix\n\nThe following table provides a complete traceability matrix showing which components and code entities satisfy each requirement:\n\n| Requirement | Component | Key Implementation Details | Configuration Files |\n|-------------|-----------|----------------------------|---------------------|\n| BR086 | MLflow SharingHub | MLflow autologging, framework integrations (TensorFlow, PyTorch, Keras) | N/A (framework-agnostic) |\n| BR087 | MLflow SharingHub | MLflow ONNX model flavor, model serialization | N/A (MLflow built-in) |\n| BR088 | MLflow SharingHub | MLflow Tracking API: `/api/2.0/mlflow/runs/create`, `/api/2.0/mlflow/runs/log-metric` | N/A (MLflow API) |\n| BR089 | MLflow SharingHub + PostgreSQL | Experiments, runs, metrics, params tables in PostgreSQL backend | `postgresql://mlflow_user:password@postgres:5432/mlflow` |\n| BR090 | MLflow SharingHub + S3 | S3 artifacts store, MLflow artifact logging API | `s3://mlflow-artifacts/` |\n| BR091 | MLflow SharingHub | MLflow Model Registry: `/api/2.0/mlflow/registered-models/create`, model versioning | N/A (MLflow API) |\n| BR092 | MLflow SharingHub + SharingHub | Auto-publish to STAC catalog on model registration, ml-model extension | SharingHub STAC catalog generation |\n| BR093 | MLflow SharingHub | Flask application serving MLflow UI at `/mlflow` endpoint | MLflow UI templates |\n| BR094 | MLflow SharingHub + SharingHub | RESTful API, permission checking via SharingHub integration | Authentication headers, OIDC integration |\n| BR095 | GitLab + DVC + SharingHub | Git version control, DVC data tracking, STAC metadata generation | `.dvc` files, `dvc.yaml`, GitLab topics |\n| BR096 | SharingHub | STAC catalog with dataset collection, GitLab topic filtering (`sharinghub:dataset`) | `categories.yaml`, `tags.yaml` |\n| BR097-1 | MLflow UI | Web interface for experiments, runs, models at `/mlflow` | MLflow UI Flask routes |\n| BR097-2 | GitLab UI + SharingHub UI | GitLab project UI, file browser, SharingHub catalog browser | GitLab Rails UI, SharingHub Flask templates |\n\n**Sources:** [docs/design/requirements.md:1-35]()\n\n---\n\n## Integration Requirements\n\nThe requirements are designed to work together as an integrated system. The following diagram illustrates the critical integration points between components:\n\n```mermaid\ngraph LR\n    subgraph \"BR086-BR091: Model Training\"\n        TRAIN[\"Model Training\u003cbr/\u003ePython Script\"]\n        MLFTRACK[\"MLflow Tracking\u003cbr/\u003eLog Metrics\"]\n        MLFREG[\"MLflow Registry\u003cbr/\u003eRegister Model\"]\n    end\n    \n    subgraph \"BR092: Discovery Integration\"\n        AUTOPUB[\"Auto-publish\u003cbr/\u003eon Registration\"]\n        STACGEN[\"STAC Item\u003cbr/\u003eml-model Extension\"]\n    end\n    \n    subgraph \"BR095-BR096: Data Management\"\n        DVCADD[\"DVC Add\u003cbr/\u003eTrack Dataset\"]\n        GITCOMMIT[\"Git Commit\u003cbr/\u003eMetadata\"]\n        STACCAT[\"STAC Catalog\u003cbr/\u003eDataset Collection\"]\n    end\n    \n    subgraph \"BR093-BR097: UI Access\"\n        MLFUI[\"MLflow UI\u003cbr/\u003eView Runs\"]\n        GLUI[\"GitLab UI\u003cbr/\u003eManage Data\"]\n        SHUI[\"SharingHub UI\u003cbr/\u003eBrowse Catalog\"]\n    end\n    \n    TRAIN --\u003e|\"Experiment tracking\"| MLFTRACK\n    MLFTRACK --\u003e|\"Model versioning\"| MLFREG\n    MLFREG --\u003e|\"BR092: Trigger\"| AUTOPUB\n    AUTOPUB --\u003e|\"Generate\"| STACGEN\n    \n    DVCADD --\u003e|\"Version data\"| GITCOMMIT\n    GITCOMMIT --\u003e|\"BR096: Extract metadata\"| STACCAT\n    \n    STACGEN --\u003e|\"Appears in\"| SHUI\n    STACCAT --\u003e|\"Appears in\"| SHUI\n    \n    MLFTRACK -.-\u003e|\"BR093: View in\"| MLFUI\n    GITCOMMIT -.-\u003e|\"BR097-2: View in\"| GLUI\n    STACGEN -.-\u003e|\"Links to\"| GLUI\n    STACCAT -.-\u003e|\"Links to\"| GLUI\n```\n\n**Sources:** [docs/design/requirements.md:1-35]()\n\n---\n\n## Summary\n\nThe MLOps Building Block requirements establish a comprehensive framework for machine learning operations covering:\n\n- **Model training lifecycle management** (BR086-BR094) through MLflow SharingHub\n- **Dataset version control and discovery** (BR095-BR096) through GitLab, DVC, and SharingHub integration\n- **Web-based user interfaces** (BR097) providing unified access to all platform capabilities\n\nThese requirements are satisfied through the coordinated interaction of three core components: **GitLab** for code and data version control, **SharingHub** for discovery and metadata management via STAC API, and **MLflow SharingHub** for experiment tracking and model registry. The architecture ensures that models and datasets are consistently versioned, properly metadata-tagged, and discoverable through standardized APIs.\n\nFor practical examples of these requirements in action, see [Use Cases](#2.2). For deployment instructions, see [Deployment Guide](#5).\n\n**Sources:** [docs/design/requirements.md:1-35]()"])</script><script>self.__next_f.push([1,"1a:T49e0,"])</script><script>self.__next_f.push([1,"# Use Cases\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/design/diagrams/use-cases.drawio.png](docs/design/diagrams/use-cases.drawio.png)\n- [docs/design/use-cases.md](docs/design/use-cases.md)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis document describes the user stories and use cases supported by the EOEPCA MLOps Building Block. It presents the functional capabilities from the perspective of different user personas, detailing how they interact with the system to train models, manage datasets, track experiments, and share resources.\n\nThe use cases are organized into two primary categories: **AI Model Evaluation and Release Management** and **Dataset Management**. These use cases inform the functional requirements documented in [Requirements](#2.1) and are implemented through the workflows described in [Workflows and Scenarios](#4).\n\n**Sources:** [docs/design/use-cases.md:1-96]()\n\n## User Personas and System Components\n\nThe MLOps Building Block supports multiple user personas, each interacting with specific system components. The following table maps user roles to their primary activities and the components they interact with:\n\n| Persona | Primary Activities | Components Used |\n|---------|-------------------|-----------------|\n| **ML Developer** | Train models, log experiments, register models, view metrics, share models | MLflow SharingHub, SharingHub, GitLab |\n| **Data Scientist** | Create datasets, version data, publish datasets, share datasets | GitLab, DVC, S3 Storage, SharingHub |\n| **ML User** | Browse models, download models, browse datasets, run inference | SharingHub, STAC API, MLflow Registry |\n\nThe system components referenced in the use cases map to the following concrete implementations:\n\n| Component Name (Use Cases) | Actual Implementation | Description |\n|---------------------------|----------------------|-------------|\n| **Model Trainer** | MLflow SharingHub | Experiment tracking server for logging runs and registering models |\n| **MLOps UI** | SharingHub Web UI | Discovery platform with STAC catalog for browsing models and datasets |\n| **Training Data Manager** | GitLab + DVC + S3 | Version control system combined with data versioning for managing datasets |\n| **Resource Discovery BB** | SharingHub STAC API | Standardized catalog API for discovering and accessing resources |\n\n**Sources:** [docs/design/use-cases.md:15-96]()\n\n## Use Case Overview\n\nThe following diagram illustrates all use cases supported by the MLOps Building Block and the actors involved in each:\n\n```mermaid\ngraph TB\n    subgraph \"Actors\"\n        MLDev[\"ML Developer\"]\n        DataSci[\"Data Scientist\"]\n        MLUser[\"ML User\"]\n    end\n    \n    subgraph \"AI Model Evaluation and Release Management\"\n        UC1[\"Create model\"]\n        UC2[\"Use popular ML frameworks\"]\n        UC3[\"Use ONNX format\"]\n        UC4[\"Evaluate AI model training\"]\n        UC5[\"Display runs metrics\"]\n        UC6[\"View Model training history\"]\n        UC7[\"Share Model\"]\n        UC8[\"Model Release\"]\n        UC9[\"Register Models\"]\n    end\n    \n    subgraph \"Dataset Management\"\n        UC10[\"Publish Assets\"]\n        UC11[\"Dataset iteration\"]\n        UC12[\"Share Dataset\"]\n        UC13[\"Browse Dataset\"]\n    end\n    \n    subgraph \"System Components\"\n        MLflow[\"MLflow SharingHub\u003cbr/\u003eModel Trainer\"]\n        SH[\"SharingHub\u003cbr/\u003eMLOps UI\"]\n        GL[\"GitLab + DVC\u003cbr/\u003eTraining Data Manager\"]\n    end\n    \n    MLDev --\u003e UC1\n    MLDev --\u003e UC2\n    MLDev --\u003e UC3\n    MLDev --\u003e UC4\n    MLDev --\u003e UC5\n    MLDev --\u003e UC6\n    MLDev --\u003e UC7\n    MLDev --\u003e UC8\n    MLDev --\u003e UC9\n    \n    DataSci --\u003e UC10\n    DataSci --\u003e UC11\n    DataSci --\u003e UC12\n    DataSci --\u003e UC13\n    \n    MLUser --\u003e UC13\n    MLUser --\u003e UC8\n    \n    UC1 --\u003e GL\n    UC2 --\u003e MLflow\n    UC3 --\u003e MLflow\n    UC4 --\u003e MLflow\n    UC5 --\u003e SH\n    UC6 --\u003e SH\n    UC7 --\u003e SH\n    UC8 --\u003e MLflow\n    UC9 --\u003e SH\n    \n    UC10 --\u003e GL\n    UC11 --\u003e GL\n    UC12 --\u003e SH\n    UC13 --\u003e SH\n```\n\n**Sources:** [docs/design/use-cases.md:8-13]()\n\n## AI Model Evaluation and Release Management\n\nThis use case category covers the complete lifecycle of training, evaluating, versioning, and releasing AI models. It enables ML developers to work with popular frameworks, track experiments, compare model performance, and publish models for discovery and reuse.\n\n### Create Model\n\n- **Actors:** ML Developer\n- **Components:** GitLab (`gitlab` namespace pods)\n- **Description:** Create a new GitLab project to organize model training code, scripts, and configuration files. The project serves as the foundation for all model development activities.\n- **Preconditions:** User has access to GitLab instance\n- **Postconditions:** GitLab project created with appropriate topic tags for SharingHub discovery\n\n**Sources:** [docs/design/use-cases.md:21-24]()\n\n### Use Popular ML Frameworks\n\n- **Actors:** ML Developer\n- **Components:** MLflow SharingHub (`mlflow` namespace, `MLflow` class in tracking server)\n- **Description:** Train models using popular frameworks (TensorFlow, PyTorch, scikit-learn, etc.) while logging experiments to MLflow. The `mlflow.log_param()`, `mlflow.log_metric()`, and `mlflow.log_model()` APIs provide framework-agnostic tracking.\n- **Preconditions:** MLflow tracking server accessible, project configured with `MLFLOW_TRACKING_URI`\n- **Postconditions:** Training runs logged with framework-specific metadata\n\n**Sources:** [docs/design/use-cases.md:26-29]()\n\n### Use ONNX Model Representation Format\n\n- **Actors:** ML Developer\n- **Components:** MLflow SharingHub (model registry), S3 artifact storage\n- **Description:** Export trained models to ONNX format for interoperability and deployment. MLflow stores ONNX models as artifacts in S3, making them accessible via the STAC API.\n- **Preconditions:** Model trained in supported framework\n- **Postconditions:** ONNX model stored in S3 with path `s3://\u003cbucket\u003e/mlflow/\u003cexperiment_id\u003e/\u003crun_id\u003e/artifacts/model/model.onnx`\n\n**Sources:** [docs/design/use-cases.md:31-34]()\n\n### Evaluate AI Model Training\n\n- **Actors:** ML Developer\n- **Components:** MLflow SharingHub (`mlflow.log_metric()` API, PostgreSQL backend for metrics storage)\n- **Description:** Log accuracy metrics, loss values, and performance indicators during training. Metrics are stored in the MLflow PostgreSQL database (`mlflow` namespace, `mlflow-postgresql` StatefulSet) and associated with specific runs.\n- **Preconditions:** Active MLflow run context\n- **Postconditions:** Metrics stored in PostgreSQL, queryable via MLflow API\n\n**Sources:** [docs/design/use-cases.md:36-39]()\n\n### Display Runs Metrics\n\n- **Actors:** ML Developer\n- **Components:** SharingHub Web UI, MLflow UI (accessible at `/mlflow` path)\n- **Description:** View performance metrics collected during experiments in the MLflow UI. The interface displays metric plots, parameter comparisons, and run metadata.\n- **Preconditions:** Runs exist in MLflow tracking server\n- **Postconditions:** User can compare runs and identify best-performing models\n\n**Sources:** [docs/design/use-cases.md:41-44]()\n\n### View Model Training History\n\n- **Actors:** ML Developer\n- **Components:** SharingHub (`SharingHubClient` class), MLflow (`get_run()`, `search_runs()` APIs)\n- **Description:** Access historical training metrics and dataset versions used for model training. The SharingHub UI integrates with MLflow to display training history and links to the GitLab project containing training code.\n- **Preconditions:** User has permissions to view project in GitLab\n- **Postconditions:** Historical metrics and dataset versions displayed with temporal trends\n\n**Sources:** [docs/design/use-cases.md:47-58]()\n\n### Share Model\n\n- **Actors:** ML Developer\n- **Components:** SharingHub (GitLab project with `sharinghub:aimodel` topic), GitLab OAuth for access control\n- **Description:** Share model with collaborators by adding them to the GitLab project. Access control is inherited from GitLab's permission system. Models appear in the SharingHub catalog based on project visibility.\n- **Preconditions:** Model registered in MLflow, GitLab project configured\n- **Postconditions:** Authorized users can discover and access model through SharingHub\n\n**Sources:** [docs/design/use-cases.md:52-58]()\n\n### Model Release\n\n- **Actors:** ML Developer, ML User\n- **Components:** MLflow Model Registry (`mlflow.register_model()` API), S3 artifact storage\n- **Description:** Download ONNX models from the MLflow registry via STAC API. Registered models are automatically linked to STAC items in SharingHub, enabling standardized access.\n- **Preconditions:** Model registered with `mlflow.register_model(model_uri, name)`\n- **Postconditions:** ONNX model downloadable via STAC API asset links\n\n**Sources:** [docs/design/use-cases.md:60-63]()\n\n### Register Models in Resource Discovery\n\n- **Actors:** ML Developer\n- **Components:** MLflow SharingHub (`register_model()` API), SharingHub STAC catalog (`/stac` API endpoints)\n- **Description:** Register models with MLflow to make them discoverable through the SharingHub STAC catalog. The registration process creates a STAC item with the `ml-model` extension in the `ai-model` collection.\n- **Preconditions:** Model artifacts available in S3, GitLab project has `sharinghub:aimodel` topic\n- **Postconditions:** Model appears in STAC catalog with download links, metadata, and ML model properties\n\n**Sources:** [docs/design/use-cases.md:65-68]()\n\n### Model Training Workflow Diagram\n\nThe following diagram shows the complete workflow from model creation to registration:\n\n```mermaid\nsequenceDiagram\n    actor MLDev as \"ML Developer\"\n    participant GL as \"GitLab Project\"\n    participant Local as \"Local Environment\"\n    participant MLflow as \"MLflow SharingHub\"\n    participant PG as \"PostgreSQL\"\n    participant S3 as \"S3 Storage\"\n    participant SH as \"SharingHub STAC API\"\n    \n    MLDev-\u003e\u003eGL: 1. Create project with sharinghub:aimodel topic\n    MLDev-\u003e\u003eLocal: 2. Clone project, set MLFLOW_TRACKING_URI\n    MLDev-\u003e\u003eLocal: 3. Write training script with mlflow.start_run()\n    \n    Local-\u003e\u003eMLflow: 4. mlflow.log_param(\"learning_rate\", 0.01)\n    MLflow-\u003e\u003ePG: Store parameter\n    \n    Local-\u003e\u003eMLflow: 5. mlflow.log_metric(\"accuracy\", 0.95)\n    MLflow-\u003e\u003ePG: Store metric\n    \n    Local-\u003e\u003eMLflow: 6. mlflow.log_model(model, \"model\")\n    MLflow-\u003e\u003eS3: Store model artifacts\n    \n    MLDev-\u003e\u003eMLflow: 7. View runs in MLflow UI at /mlflow\n    \n    MLDev-\u003e\u003eMLflow: 8. mlflow.register_model(model_uri, \"flood-detection\")\n    MLflow-\u003e\u003ePG: Create model version in registry\n    \n    MLflow-\u003e\u003eSH: 9. Auto-link to STAC item\n    SH-\u003e\u003eGL: 10. Extract project metadata\n    \n    MLDev-\u003e\u003eSH: 11. Browse model in SharingHub catalog\n    SH--\u003e\u003eMLDev: Display STAC item with ml-model extension\n```\n\n**Sources:** [docs/design/use-cases.md:17-68]()\n\n## Dataset Management\n\nThis use case category focuses on storing, versioning, and sharing datasets used for model training. It enables data scientists to manage large volumes of data in various formats while maintaining version control and enabling collaboration.\n\n### Publish Assets\n\n- **Actors:** Data Scientist\n- **Components:** GitLab (repository storage), S3 (object storage for large files), DVC (data version control)\n- **Description:** Store large datasets (multiple GB) in various formats (images, sounds, text, videos) for model training. DVC tracks data files in GitLab while storing actual data in S3.\n- **Preconditions:** GitLab project created, S3 bucket configured, DVC initialized with `dvc init`\n- **Postconditions:** Data stored in S3 at `s3://\u003cbucket\u003e/\u003cproject\u003e/\u003cdataset\u003e/`, metadata files committed to GitLab\n\n**Sources:** [docs/design/use-cases.md:74-77]()\n\n### Dataset Iteration\n\n- **Actors:** Data Scientist\n- **Components:** GitLab (version control for `.dvc` files), DVC (data versioning commands)\n- **Description:** Maintain multiple versions of datasets to support iterative improvements. Each dataset version is tracked via `.dvc` files in GitLab, which reference specific data versions in S3.\n- **Preconditions:** Dataset published with `dvc add data/`\n- **Postconditions:** Multiple dataset versions accessible via `dvc checkout \u003cversion\u003e`, each version has unique Git commit\n\n**Sources:** [docs/design/use-cases.md:79-82]()\n\n### Share Dataset\n\n- **Actors:** Data Scientist\n- **Components:** SharingHub STAC catalog, GitLab (project with `sharinghub:dataset` topic)\n- **Description:** Share datasets with collaborators by adding the `sharinghub:dataset` topic to the GitLab project. The dataset appears in the SharingHub catalog as a STAC item with the `eo` or `datacube` extension.\n- **Preconditions:** GitLab project contains dataset with `.dvc` files\n- **Postconditions:** Dataset discoverable in SharingHub `/stac` API, accessible to authorized users\n\n**Sources:** [docs/design/use-cases.md:84-87]()\n\n### Browse Dataset\n\n- **Actors:** Data Scientist, ML Developer, ML User\n- **Components:** SharingHub Web UI, STAC API (`/stac/collections/dataset`, `/stac/collections/dataset/items`)\n- **Description:** Browse available datasets through the SharingHub Web UI or STAC API. Users can filter datasets by tags, view metadata, and access datasets they have permissions for.\n- **Preconditions:** User authenticated via GitLab OAuth or using default token\n- **Postconditions:** User can view dataset details, download links, and associated GitLab project\n\n**Sources:** [docs/design/use-cases.md:89-95]()\n\n### Dataset Management Workflow Diagram\n\nThe following diagram shows the complete workflow for dataset management:\n\n```mermaid\nsequenceDiagram\n    actor DS as \"Data Scientist\"\n    participant GL as \"GitLab Project\"\n    participant Local as \"Local Environment\"\n    participant DVC as \"DVC CLI\"\n    participant S3 as \"S3 Storage\"\n    participant SH as \"SharingHub\"\n    participant STAC as \"STAC API\"\n    \n    DS-\u003e\u003eGL: 1. Create project, add sharinghub:dataset topic\n    DS-\u003e\u003eLocal: 2. Clone project\n    DS-\u003e\u003eLocal: 3. dvc init\n    DS-\u003e\u003eLocal: 4. Add data files to data/ directory\n    \n    DS-\u003e\u003eDVC: 5. dvc add data/\n    DVC-\u003e\u003eS3: Upload data files\n    DVC-\u003e\u003eLocal: Create data.dvc metadata file\n    \n    DS-\u003e\u003eGL: 6. git add data.dvc .gitignore\n    DS-\u003e\u003eGL: 7. git commit -m \"Add dataset v1\"\n    DS-\u003e\u003eGL: 8. git push\n    \n    GL-\u003e\u003eSH: 9. GitLab webhook notifies SharingHub\n    SH-\u003e\u003eGL: 10. Extract project metadata and topics\n    SH-\u003e\u003eSTAC: 11. Create STAC item in dataset collection\n    \n    DS-\u003e\u003eSH: 12. Verify dataset appears in catalog\n    SH--\u003e\u003eDS: Display STAC item with eo extension\n    \n    DS-\u003e\u003eLocal: 13. Update dataset, dvc add data/\n    DS-\u003e\u003eGL: 14. Commit new version\n    SH-\u003e\u003eSTAC: 15. Update STAC item with new version\n```\n\n**Sources:** [docs/design/use-cases.md:70-95]()\n\n## Component and Code Entity Mapping\n\nThe following diagram maps use case components to actual code entities in the system:\n\n```mermaid\ngraph TB\n    subgraph \"Use Case Components\"\n        UC_ModelTrainer[\"Model Trainer\"]\n        UC_MLOpsUI[\"MLOps UI\"]\n        UC_TrainingDataMgr[\"Training Data Manager\"]\n        UC_ResourceDiscovery[\"Resource Discovery BB\"]\n    end\n    \n    subgraph \"Kubernetes Deployments\"\n        K8s_MLflow[\"mlflow namespace\u003cbr/\u003emlflow-sharinghub Deployment\"]\n        K8s_SH[\"sharinghub namespace\u003cbr/\u003esharinghub Deployment\"]\n        K8s_GL[\"gitlab namespace\u003cbr/\u003egitlab-webservice Deployment\"]\n        K8s_PG[\"mlflow-postgresql StatefulSet\"]\n        K8s_S3[\"External S3 Service\"]\n    end\n    \n    subgraph \"Code Entities and APIs\"\n        Code_MLflowAPI[\"mlflow.log_param()\u003cbr/\u003emlflow.log_metric()\u003cbr/\u003emlflow.log_model()\u003cbr/\u003emlflow.register_model()\"]\n        Code_STACAPI[\"/stac endpoint\u003cbr/\u003e/stac/collections\u003cbr/\u003e/stac/collections/ai-model/items\"]\n        Code_GitLabAPI[\"GitLab REST API\u003cbr/\u003e/api/v4/projects\u003cbr/\u003e/api/v4/topics\"]\n        Code_DVCAPI[\"dvc add\u003cbr/\u003edvc push\u003cbr/\u003edvc pull\u003cbr/\u003edvc checkout\"]\n    end\n    \n    subgraph \"Configuration Files\"\n        Helm_MLflow[\"charts/mlflow-sharinghub/\u003cbr/\u003evalues.yaml\"]\n        Helm_SH[\"charts/sharinghub/\u003cbr/\u003evalues.yaml\"]\n        Helm_GL[\"charts/gitlab/\u003cbr/\u003evalues.yaml\"]\n        ArgoCD[\"deploy/argocd/\u003cbr/\u003eapplication-*.yaml\"]\n    end\n    \n    UC_ModelTrainer --\u003e K8s_MLflow\n    UC_MLOpsUI --\u003e K8s_SH\n    UC_TrainingDataMgr --\u003e K8s_GL\n    UC_TrainingDataMgr --\u003e K8s_S3\n    UC_ResourceDiscovery --\u003e K8s_SH\n    \n    K8s_MLflow --\u003e Code_MLflowAPI\n    K8s_MLflow --\u003e K8s_PG\n    K8s_MLflow --\u003e K8s_S3\n    \n    K8s_SH --\u003e Code_STACAPI\n    K8s_SH --\u003e Code_GitLabAPI\n    \n    K8s_GL --\u003e Code_GitLabAPI\n    K8s_GL --\u003e Code_DVCAPI\n    K8s_GL --\u003e K8s_S3\n    \n    K8s_MLflow -.configured by.-\u003e Helm_MLflow\n    K8s_SH -.configured by.-\u003e Helm_SH\n    K8s_GL -.configured by.-\u003e Helm_GL\n    \n    Helm_MLflow -.deployed by.-\u003e ArgoCD\n    Helm_SH -.deployed by.-\u003e ArgoCD\n    Helm_GL -.deployed by.-\u003e ArgoCD\n```\n\nThis mapping shows how abstract use case components correspond to concrete Kubernetes deployments, code APIs, and configuration files in the repository.\n\n**Sources:** [docs/design/use-cases.md:1-96]()\n\n## Use Case to Implementation Traceability\n\nThe following table provides traceability from use cases to their implementation components:\n\n| Use Case | MLflow SharingHub | SharingHub | GitLab | Key APIs/Commands |\n|----------|------------------|------------|---------|-------------------|\n| Create model | - | - |  | GitLab project creation, topic: `sharinghub:aimodel` |\n| Use ML frameworks |  | - | - | `mlflow.log_param()`, `mlflow.log_metric()` |\n| Use ONNX format |  | - | - | `mlflow.log_model()`, ONNX artifact storage in S3 |\n| Evaluate training |  | - | - | `mlflow.log_metric()`, PostgreSQL metrics storage |\n| Display runs metrics |  |  | - | MLflow UI at `/mlflow`, SharingHub integration |\n| View training history |  |  | - | `mlflow.search_runs()`, SharingHub project view |\n| Share model | - |  |  | GitLab permissions, OAuth integration |\n| Model release |  |  | - | `mlflow.register_model()`, STAC API download |\n| Register models |  |  | - | MLflow registry, `/stac/collections/ai-model/items` |\n| Publish assets | - | - |  | `dvc add`, `dvc push`, S3 storage |\n| Dataset iteration | - | - |  | `dvc checkout`, Git commits for `.dvc` files |\n| Share dataset | - |  |  | GitLab topic: `sharinghub:dataset`, STAC catalog |\n| Browse dataset | - |  | - | `/stac/collections/dataset/items`, Web UI |\n\n**Sources:** [docs/design/use-cases.md:1-96]()\n\n## Related Documentation\n\nFor detailed information on related topics:\n\n- **Functional requirements** that inform these use cases: See [Requirements](#2.1)\n- **Step-by-step implementation** of these use cases: See [Model Training Workflow](#4.1) and [Dataset Management](#4.2)\n- **API specifications** for programmatic access: See [API Reference](#7)\n- **Deployment instructions** for setting up components: See [Deployment Guide](#5)"])</script><script>self.__next_f.push([1,"1b:T408e,"])</script><script>self.__next_f.push([1,"# Core Components\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/design/architecture.md](docs/design/architecture.md)\n- [docs/design/diagrams/mlops-archi.drawio.png](docs/design/diagrams/mlops-archi.drawio.png)\n- [docs/design/diagrams/mlops-overview.drawio.png](docs/design/diagrams/mlops-overview.drawio.png)\n- [docs/index.md](docs/index.md)\n\n\u003c/details\u003e\n\n\n\nThis page provides an overview of the three main components that comprise the EOEPCA MLOps Building Block and how they work together to deliver a complete machine learning operations platform. For detailed configuration and deployment of each component, see [GitLab](#3.1), [SharingHub](#3.2), and [MLflow SharingHub](#3.3).\n\nThe MLOps Building Block is implemented through the integration of three core components:\n\n1. **GitLab** - Provides version control, project management, and serves as the source of truth for code and metadata\n2. **SharingHub** - Discovery and collaboration platform that dynamically generates STAC catalogs from GitLab projects\n3. **MLflow SharingHub** - Experiment tracking and model registry for managing ML training runs and model artifacts\n\n## Component Overview\n\nThe architecture follows a layered approach where GitLab forms the foundation, SharingHub provides discovery and access control, and MLflow SharingHub handles ML-specific lifecycle management.\n\n**Component Interaction Architecture**\n\n```mermaid\ngraph TB\n    subgraph \"User Interaction Layer\"\n        MLDev[\"ML Developer\"]\n        DataSci[\"Data Scientist\"]\n        MLUser[\"ML User\"]\n    end\n    \n    subgraph \"Core Components\"\n        GL[\"GitLab\u003cbr/\u003egitlab namespace\u003cbr/\u003ewebservice, sidekiq, kas\"]\n        SH[\"SharingHub\u003cbr/\u003esharinghub namespace\u003cbr/\u003eSTAC API Server\"]\n        MLF[\"MLflow SharingHub\u003cbr/\u003emlflow namespace\u003cbr/\u003eMLflow Server\"]\n    end\n    \n    subgraph \"APIs\"\n        STACAPI[\"STAC API\u003cbr/\u003e/api/v1/stac\"]\n        MLAPI[\"MLflow Tracking API\u003cbr/\u003e/api/2.0/mlflow\"]\n        GLAPI[\"GitLab API\u003cbr/\u003e/api/v4\"]\n    end\n    \n    subgraph \"Storage\"\n        S3[\"S3 Object Storage\u003cbr/\u003eArtifacts \u0026 Models\"]\n        GLPG[\"GitLab PostgreSQL\u003cbr/\u003egitlab-postgresql\"]\n        MLFPG[\"MLflow PostgreSQL\u003cbr/\u003emlflow-postgresql\"]\n        GLREDIS[\"GitLab Redis\u003cbr/\u003egitlab-redis\"]\n    end\n    \n    MLDev --\u003e|Browse \u0026 Train| SH\n    MLDev --\u003e|Track Experiments| MLF\n    MLDev --\u003e|Manage Code| GL\n    DataSci --\u003e|Publish Data| GL\n    MLUser --\u003e|Download Models| SH\n    \n    SH --\u003e|Exposes| STACAPI\n    SH --\u003e|Extracts Metadata| GLAPI\n    SH --\u003e|OAuth Authentication| GL\n    \n    MLF --\u003e|Exposes| MLAPI\n    MLF --\u003e|Permission Check| SH\n    MLF --\u003e|Stores Metadata| MLFPG\n    MLF --\u003e|Stores Artifacts| S3\n    \n    GL --\u003e|Exposes| GLAPI\n    GL --\u003e|Stores Data| GLPG\n    GL --\u003e|Caches| GLREDIS\n    GL --\u003e|Backups| S3\n    \n    STACAPI -.-\u003e|Returns STAC Items| MLUser\n    MLAPI -.-\u003e|Logs Metrics| MLDev\n```\n\nSources: [docs/design/architecture.md:52-76](), [docs/index.md:16-29]()\n\n## GitLab: Foundation Layer\n\nGitLab serves as the foundational component, providing:\n\n- **Version Control**: Git repositories for code, models, and documentation\n- **Project Management**: Issues, merge requests, CI/CD pipelines\n- **Topic-Based Organization**: Projects are tagged with topics like `sharinghub:aimodel`, `sharinghub:dataset`, `sharinghub:processor` to enable automatic discovery\n- **User Authentication**: OIDC integration with Keycloak for centralized identity management\n- **Object Storage**: Integration with S3 for Git LFS and backup storage\n\nGitLab runs in the `gitlab` namespace with multiple pod types including `webservice`, `sidekiq` (background jobs), and `kas` (Kubernetes agent server). It maintains its own PostgreSQL database and Redis cache.\n\nFor detailed GitLab deployment and configuration, see [GitLab](#3.1).\n\nSources: [docs/design/architecture.md:30-51](), [docs/index.md:16-29]()\n\n## SharingHub: Discovery Layer\n\nSharingHub is deployed on top of GitLab and dynamically extracts metadata from GitLab projects to provide discovery services.\n\n**SharingHub STAC Catalog Generation**\n\n```mermaid\ngraph LR\n    subgraph \"GitLab Projects\"\n        GP1[\"Project: flood-model\u003cbr/\u003eTopic: sharinghub:aimodel\u003cbr/\u003eTags: Image Segmentation\"]\n        GP2[\"Project: sen1floods11-dataset\u003cbr/\u003eTopic: sharinghub:dataset\u003cbr/\u003eTags: Flood Detection\"]\n        GP3[\"Project: wine-quality\u003cbr/\u003eTopic: sharinghub:aimodel\u003cbr/\u003eTags: Tabular Classification\"]\n    end\n    \n    subgraph \"SharingHub Processing\"\n        EXT[\"Metadata Extractor\u003cbr/\u003eGitLab API Integration\"]\n        CAT[\"STAC Catalog Generator\"]\n    end\n    \n    subgraph \"STAC Catalog Structure\"\n        ROOT[\"STAC Root Catalog\u003cbr/\u003eid: gitlab-cs\"]\n        COL1[\"Collection: AI Models\u003cbr/\u003egitlab_topic: sharinghub:aimodel\"]\n        COL2[\"Collection: Datasets\u003cbr/\u003egitlab_topic: sharinghub:dataset\"]\n        COL3[\"Collection: Processors\u003cbr/\u003egitlab_topic: sharinghub:processor\"]\n        ITEM1[\"STAC Item: flood-model\u003cbr/\u003eml-model extension\u003cbr/\u003eONNX assets\"]\n        ITEM2[\"STAC Item: sen1floods11\u003cbr/\u003eeo extension\u003cbr/\u003eGeoTIFF assets\"]\n    end\n    \n    GP1 --\u003e|Extract Metadata| EXT\n    GP2 --\u003e|Extract Metadata| EXT\n    GP3 --\u003e|Extract Metadata| EXT\n    \n    EXT --\u003e|Generate| CAT\n    CAT --\u003e|Creates| ROOT\n    ROOT --\u003e|Contains| COL1\n    ROOT --\u003e|Contains| COL2\n    ROOT --\u003e|Contains| COL3\n    \n    COL1 --\u003e|Contains| ITEM1\n    COL2 --\u003e|Contains| ITEM2\n```\n\n**Key Features:**\n\n- **Dynamic Catalog**: STAC catalog is generated on-the-fly based on GitLab project metadata and user permissions\n- **STAC API**: Implements STAC API specification at `/api/v1/stac` endpoint for standardized access\n- **Topic Filtering**: Collections are automatically created based on GitLab topics (`sharinghub:aimodel`, `sharinghub:dataset`, `sharinghub:processor`)\n- **Permission Integration**: User access is validated against GitLab project permissions via OAuth\n- **STAC Extensions**: Supports `ml-model` extension for AI models and `eo` extension for Earth Observation datasets\n\nSharingHub runs in the `sharinghub` namespace as a single pod deployment.\n\nFor detailed SharingHub configuration including categories, tags, and STAC settings, see [SharingHub](#3.2).\n\nSources: [docs/design/architecture.md:52-76](), [docs/index.md:22-28]()\n\n## MLflow SharingHub: ML Lifecycle Layer\n\nMLflow SharingHub manages the complete machine learning lifecycle including experiment tracking, model training, and model registry.\n\n**MLflow Integration Architecture**\n\n```mermaid\ngraph TB\n    subgraph \"ML Developer Environment\"\n        CODE[\"Training Script\u003cbr/\u003emodel.py\"]\n        MLFCLIENT[\"MLflow Client\u003cbr/\u003emlflow.log_metric\u003cbr/\u003emlflow.log_param\"]\n    end\n    \n    subgraph \"MLflow SharingHub\"\n        MLFSERVER[\"MLflow Server\u003cbr/\u003emlflow namespace\"]\n        TRACKING[\"Tracking API\u003cbr/\u003e/api/2.0/mlflow/runs\"]\n        REGISTRY[\"Model Registry API\u003cbr/\u003e/api/2.0/mlflow/registered-models\"]\n    end\n    \n    subgraph \"Storage Layer\"\n        MLFPG[\"MLflow PostgreSQL\u003cbr/\u003eExperiments, Runs, Metrics\"]\n        S3MLF[\"S3 Bucket\u003cbr/\u003eModel Artifacts\u003cbr/\u003eONNX files\"]\n    end\n    \n    subgraph \"Integration Points\"\n        SHPERM[\"SharingHub\u003cbr/\u003ePermission Validation\"]\n        GLPROJ[\"GitLab Project\u003cbr/\u003eLinks to Runs\"]\n    end\n    \n    CODE --\u003e|Uses| MLFCLIENT\n    MLFCLIENT --\u003e|HTTP POST| TRACKING\n    TRACKING --\u003e|Validates| MLFSERVER\n    \n    MLFSERVER --\u003e|Check Access| SHPERM\n    MLFSERVER --\u003e|Store Metadata| MLFPG\n    MLFSERVER --\u003e|Store Artifacts| S3MLF\n    \n    MLFSERVER --\u003e|Expose| REGISTRY\n    REGISTRY --\u003e|Auto-link| GLPROJ\n    GLPROJ -.-\u003e|Appears in| SHPERM\n```\n\n**Key Features:**\n\n- **Experiment Tracking**: Logs parameters, metrics, and artifacts for each training run using MLflow Tracking API\n- **Model Registry**: Maintains versioned models with lifecycle stages (staging, production, archived)\n- **Artifact Storage**: Model files (including ONNX format) stored in S3 object storage\n- **Metadata Storage**: Training run metadata stored in dedicated PostgreSQL database (`mlflow-postgresql`)\n- **Permission Delegation**: Validates user access by checking permissions through SharingHub, which in turn validates against GitLab\n- **Auto-linking**: Registered models automatically linked to STAC items in SharingHub catalog\n\nMLflow SharingHub runs in the `mlflow` namespace as a single pod deployment with environment variables configured for backend store and artifact store.\n\nFor detailed MLflow SharingHub configuration including backend store, artifact store, and SharingHub integration, see [MLflow SharingHub](#3.3).\n\nSources: [docs/design/architecture.md:52-76](), [docs/index.md:22-28]()\n\n## Component Interaction Patterns\n\nThe three components interact through well-defined interfaces to provide a cohesive MLOps experience.\n\n**Authentication and Permission Flow**\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant SH as SharingHub\n    participant GL as GitLab\n    participant MLF as MLflow\n    participant KC as Keycloak\n    \n    User-\u003e\u003eSH: Request STAC catalog\n    SH-\u003e\u003eKC: Validate OAuth token\n    KC--\u003e\u003eSH: Token valid\n    SH-\u003e\u003eGL: GET /api/v4/projects\u003cbr/\u003e(with user token)\n    GL--\u003e\u003eSH: Projects list (filtered by access)\n    SH--\u003e\u003eUser: STAC catalog (user-specific)\n    \n    User-\u003e\u003eMLF: Log training metrics\n    MLF-\u003e\u003eSH: Check project permissions\n    SH-\u003e\u003eGL: Validate user access to project\n    GL--\u003e\u003eSH: Access granted\n    SH--\u003e\u003eMLF: Permission confirmed\n    MLF--\u003e\u003eUser: Metrics logged\n```\n\n**Data and Metadata Flow**\n\n| Component | Data Type | Storage Location | Access Method |\n|-----------|-----------|------------------|---------------|\n| GitLab | Git repositories, CI/CD data | `gitlab-postgresql`, `gitlab-redis` | GitLab API `/api/v4` |\n| GitLab | LFS objects, backups | S3 object storage | S3 API |\n| SharingHub | STAC catalog (dynamic) | None (generated on-the-fly) | STAC API `/api/v1/stac` |\n| MLflow | Experiment metadata, metrics | `mlflow-postgresql` | MLflow Tracking API |\n| MLflow | Model artifacts, ONNX files | S3 object storage | S3 API, MLflow Artifacts API |\n\n**Topic-Based Discovery**\n\nGitLab projects use topics to indicate their type, which SharingHub uses to automatically generate STAC collections:\n\n- `sharinghub:aimodel`  AI Models collection\n- `sharinghub:dataset`  Datasets collection  \n- `sharinghub:processor`  Processors collection\n\nAdditional tags on GitLab projects (e.g., \"Image Segmentation\", \"Flood Detection\") become searchable metadata in the STAC catalog.\n\nSources: [docs/design/architecture.md:52-76](), [docs/index.md:16-29]()\n\n## Deployment Architecture\n\nAll three components are deployed on Kubernetes using ArgoCD for GitOps-style deployment management.\n\n**Kubernetes Namespace Layout**\n\n```mermaid\ngraph TB\n    subgraph \"Kubernetes Cluster\"\n        subgraph \"argocd namespace\"\n            ARGOCD[\"ArgoCD Applications\u003cbr/\u003emanages deployments\"]\n        end\n        \n        subgraph \"gitlab namespace\"\n            GLPODS[\"GitLab Pods\u003cbr/\u003ewebservice\u003cbr/\u003esidekiq\u003cbr/\u003ekas\"]\n            GLPG[\"StatefulSet\u003cbr/\u003egitlab-postgresql\"]\n            GLREDIS[\"StatefulSet\u003cbr/\u003egitlab-redis\"]\n        end\n        \n        subgraph \"sharinghub namespace\"\n            SHPOD[\"SharingHub Pod\u003cbr/\u003edeployment\"]\n        end\n        \n        subgraph \"mlflow namespace\"\n            MLFPOD[\"MLflow Pod\u003cbr/\u003edeployment\"]\n            MLFPG[\"StatefulSet\u003cbr/\u003emlflow-postgresql\"]\n        end\n        \n        subgraph \"cert-manager namespace\"\n            CERTMGR[\"cert-manager\u003cbr/\u003eTLS automation\"]\n        end\n        \n        subgraph \"ingress-nginx namespace\"\n            NGINX[\"NGINX Ingress\u003cbr/\u003etraffic routing\"]\n        end\n    end\n    \n    subgraph \"External Services\"\n        S3EXT[\"S3 Provider\u003cbr/\u003eartifacts storage\"]\n        KC[\"Keycloak\u003cbr/\u003eOIDC IdP\"]\n    end\n    \n    ARGOCD --\u003e|Deploys| GLPODS\n    ARGOCD --\u003e|Deploys| SHPOD\n    ARGOCD --\u003e|Deploys| MLFPOD\n    \n    NGINX --\u003e|Routes to| GLPODS\n    NGINX --\u003e|Routes to| SHPOD\n    NGINX --\u003e|Routes to| MLFPOD\n    \n    GLPODS --\u003e|Uses| GLPG\n    GLPODS --\u003e|Uses| GLREDIS\n    GLPODS --\u003e|Stores| S3EXT\n    GLPODS --\u003e|Auth via| KC\n    \n    SHPOD --\u003e|Queries| GLPODS\n    SHPOD --\u003e|Reads| S3EXT\n    \n    MLFPOD --\u003e|Uses| MLFPG\n    MLFPOD --\u003e|Stores| S3EXT\n    MLFPOD --\u003e|Validates| SHPOD\n    \n    CERTMGR -.-\u003e|Provisions TLS| NGINX\n```\n\n**Component Dependencies:**\n\n- **GitLab**: Requires PostgreSQL, Redis, S3, and Keycloak for OIDC\n- **SharingHub**: Requires GitLab to be running and accessible\n- **MLflow SharingHub**: Requires PostgreSQL, S3, and SharingHub for permission checks\n\nFor complete deployment instructions including prerequisites and step-by-step guides, see [Deployment Guide](#5).\n\nSources: [docs/design/architecture.md:52-76]()\n\n## Storage and Persistence\n\nThe components use different storage backends for different data types:\n\n**Storage Backend Summary**\n\n```mermaid\ngraph LR\n    subgraph \"Persistent Data\"\n        GLPG[\"gitlab-postgresql\u003cbr/\u003eGit metadata\u003cbr/\u003eUsers, Projects\"]\n        MLFPG[\"mlflow-postgresql\u003cbr/\u003eExperiments\u003cbr/\u003eMetrics, Params\"]\n        GLREDIS[\"gitlab-redis\u003cbr/\u003eCache\u003cbr/\u003eBackground jobs\"]\n        S3[\"S3 Object Storage\u003cbr/\u003eGit LFS\u003cbr/\u003eModel artifacts\u003cbr/\u003eBackups\"]\n    end\n    \n    subgraph \"Components\"\n        GL[\"GitLab\"]\n        SH[\"SharingHub\"]\n        MLF[\"MLflow\"]\n    end\n    \n    GL --\u003e|Reads/Writes| GLPG\n    GL --\u003e|Reads/Writes| GLREDIS\n    GL --\u003e|Writes| S3\n    \n    SH --\u003e|Reads| GLPG\n    SH --\u003e|Reads| S3\n    \n    MLF --\u003e|Reads/Writes| MLFPG\n    MLF --\u003e|Writes| S3\n```\n\n**PostgreSQL Databases:**\n\n- `gitlab-postgresql`: Stores GitLab's core data (users, projects, merge requests, CI/CD pipelines)\n- `mlflow-postgresql`: Stores MLflow's tracking data (experiments, runs, metrics, parameters, model registry)\n\n**Redis:**\n\n- `gitlab-redis`: Caching layer and message queue for GitLab background jobs (Sidekiq)\n\n**S3 Object Storage:**\n\n- Git LFS objects\n- GitLab backup archives\n- MLflow model artifacts (ONNX files, training data)\n- General file attachments\n\nSources: [docs/design/architecture.md:52-76]()\n\n## Authentication and Security\n\nThe components share a common authentication architecture based on OAuth 2.0 and OIDC.\n\n**Authentication Chain**\n\n```mermaid\ngraph LR\n    USER[\"User\"]\n    KC[\"Keycloak\u003cbr/\u003eOIDC Provider\u003cbr/\u003eeoepca realm\"]\n    GL[\"GitLab\u003cbr/\u003eOAuth Client\"]\n    SH[\"SharingHub\u003cbr/\u003eOAuth Client\"]\n    MLF[\"MLflow\u003cbr/\u003eDelegates to SH\"]\n    \n    USER --\u003e|1. Login| KC\n    KC --\u003e|2. OAuth Token| GL\n    GL --\u003e|3. API Call with Token| SH\n    SH --\u003e|4. Validate Token| KC\n    MLF --\u003e|5. Check Permissions| SH\n    SH --\u003e|6. Validate against| GL\n```\n\n**Kubernetes Secrets:**\n\n- `gitlab-oidc`: Contains `client-id` and `client-secret` for GitLab's OIDC integration with Keycloak\n- `sharinghub-oidc`: Contains `client-id` and `client-secret` for SharingHub's OAuth with GitLab\n- `sharinghub-oidc` (optional): Contains `default-token` for public unauthenticated read access\n- `mlflow-sharinghub`: Contains `secret-key` for MLflow's integration with SharingHub\n- TLS secrets: `gitlab.domain-tls`, `sharinghub.domain-tls` provisioned by cert-manager\n\n**Permission Model:**\n\n1. User authenticates with Keycloak\n2. GitLab validates OIDC token and establishes session\n3. SharingHub uses GitLab OAuth to validate user identity\n4. SharingHub queries GitLab API to determine which projects user can access\n5. MLflow delegates all permission checks to SharingHub\n6. STAC catalog and MLflow responses are filtered based on user permissions\n\nFor detailed security configuration including TLS and secret management, see [Deployment Guide](#5).\n\nSources: [docs/design/architecture.md:52-76]()\n\n## Summary\n\nThe MLOps Building Block achieves its functionality through tight integration of three components:\n\n- **GitLab** provides the foundational layer for version control and project management\n- **SharingHub** builds on GitLab to provide standardized discovery through dynamic STAC catalog generation  \n- **MLflow SharingHub** adds ML-specific capabilities while leveraging SharingHub for access control\n\nThis modular architecture enables:\n\n- Standard-compliant APIs (STAC API, MLflow API, GitLab API)\n- Unified authentication and authorization\n- Flexible deployment on Kubernetes\n- Integration with external services (S3, Keycloak)\n\nFor implementation details of each component, see their respective pages: [GitLab](#3.1), [SharingHub](#3.2), and [MLflow SharingHub](#3.3). For operational workflows using these components, see [Workflows and Scenarios](#4).\n\nSources: [docs/design/architecture.md:1-76](), [docs/index.md:1-45]()"])</script><script>self.__next_f.push([1,"1c:T5fa8,"])</script><script>self.__next_f.push([1,"# GitLab\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/deployment-guide/components/gitlab.md](docs/admin/deployment-guide/components/gitlab.md)\n- [docs/admin/deployment-guide/intro.md](docs/admin/deployment-guide/intro.md)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis document describes GitLab's role as the foundational code management and version control system within the EOEPCA MLOps Building Block. GitLab serves as the primary repository for all projects, including AI models, datasets, and processors, and provides the organizational structure through topics that drives automatic discovery in SharingHub.\n\nFor deployment instructions, see [GitLab Deployment](#5.2). For information about how SharingHub extracts metadata from GitLab projects, see [SharingHub](#3.2).\n\n**Sources:** [docs/admin/deployment-guide/intro.md:10-11]()\n\n---\n\n## Role in the MLOps Building Block\n\nGitLab functions as the central repository and project management platform for the entire MLOps ecosystem. Its primary responsibilities include:\n\n- **Version Control**: Hosts all code repositories for AI models, training scripts, datasets, and processors\n- **Project Organization**: Uses GitLab topics (e.g., `sharinghub:aimodel`, `sharinghub:dataset`) to categorize projects for automatic discovery\n- **CI/CD Pipeline**: Provides continuous integration and deployment capabilities for model training and deployment workflows\n- **Metadata Source**: Serves as the authoritative source of project metadata that SharingHub extracts to generate STAC catalog items\n- **Authentication Provider**: Acts as an OAuth provider for SharingHub, enabling unified access control across components\n- **Integration Point**: Provides API endpoints for DVC (Data Version Control) and other tools to interact with the platform\n\n**Sources:** [docs/admin/deployment-guide/intro.md:10-11]()\n\n---\n\n## Architecture and Component Integration\n\n### GitLab in the MLOps Ecosystem\n\n```mermaid\ngraph TB\n    subgraph \"External Services\"\n        Keycloak[\"Keycloak\u003cbr/\u003eOIDC Identity Provider\"]\n        S3Provider[\"S3 Object Storage\u003cbr/\u003eExternal Provider\"]\n    end\n    \n    subgraph \"gitlab Namespace\"\n        GitLabWebservice[\"gitlab-webservice Pod\u003cbr/\u003eMain Application Server\"]\n        GitLabSidekiq[\"gitlab-sidekiq Pod\u003cbr/\u003eBackground Job Processor\"]\n        GitLabKAS[\"gitlab-kas Pod\u003cbr/\u003eKubernetes Agent Server\"]\n        GitLabPostgreSQL[\"PostgreSQL\u003cbr/\u003egitlab-postgresql\"]\n        GitLabRedis[\"Redis\u003cbr/\u003egitlab-redis\"]\n    end\n    \n    subgraph \"S3 Buckets\"\n        BackupBucket[\"gitlab-backup-storage\"]\n        TmpBucket[\"gitlab-tmp-storage\"]\n        LFSBucket[\"gitlab-lfs-storage\"]\n    end\n    \n    subgraph \"Kubernetes Secrets\"\n        StorageConfig[\"storage-config Secret\u003cbr/\u003eS3 connection config\"]\n        ObjectStorage[\"object-storage Secret\u003cbr/\u003eLFS S3 config\"]\n        OIDCSecret[\"openid-connect Secret\u003cbr/\u003eprovider.yaml\"]\n    end\n    \n    subgraph \"SharingHub Integration\"\n        SharingHub[\"SharingHub\"]\n        STACCatalog[\"STAC Catalog Generator\"]\n    end\n    \n    Keycloak --\u003e|\"OIDC Authentication\"| GitLabWebservice\n    GitLabWebservice --\u003e|\"Queries\"| GitLabPostgreSQL\n    GitLabWebservice --\u003e|\"Cache\"| GitLabRedis\n    GitLabSidekiq --\u003e|\"Background Jobs\"| GitLabPostgreSQL\n    GitLabWebservice --\u003e|\"Backups\"| BackupBucket\n    GitLabWebservice --\u003e|\"Temp Storage\"| TmpBucket\n    GitLabWebservice --\u003e|\"LFS Objects\"| LFSBucket\n    \n    StorageConfig -.-\u003e|\"Mounted by\"| GitLabWebservice\n    ObjectStorage -.-\u003e|\"Mounted by\"| GitLabWebservice\n    OIDCSecret -.-\u003e|\"Mounted by\"| GitLabWebservice\n    \n    SharingHub --\u003e|\"OAuth Authentication\"| GitLabWebservice\n    SharingHub --\u003e|\"Extract Project Metadata\"| GitLabWebservice\n    STACCatalog --\u003e|\"Filter by Topics\"| GitLabWebservice\n```\n\nGitLab is deployed in the `gitlab` namespace and consists of multiple interconnected pods. The `gitlab-webservice` pod handles user requests and API calls, `gitlab-sidekiq` processes background jobs (such as repository maintenance and CI/CD pipeline execution), and `gitlab-kas` provides the Kubernetes Agent Server for GitOps workflows. PostgreSQL stores all GitLab data including repositories, issues, and user information, while Redis provides caching and job queue management.\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:1-14](), [docs/admin/deployment-guide/components/gitlab.md:169-188]()\n\n---\n\n### Storage Architecture\n\n```mermaid\ngraph LR\n    subgraph \"GitLab Application\"\n        Webservice[\"gitlab-webservice\"]\n        Toolbox[\"gitlab-toolbox\"]\n    end\n    \n    subgraph \"S3 Storage Buckets\"\n        BackupBucket[\"gitlab-backup-storage\u003cbr/\u003eScheduled backups\"]\n        TmpBucket[\"gitlab-tmp-storage\u003cbr/\u003eTemporary files\"]\n        LFSBucket[\"gitlab-lfs-storage\u003cbr/\u003eLarge File Storage\"]\n    end\n    \n    subgraph \"Secret Configuration\"\n        StorageConfigSecret[\"storage-config Secret\u003cbr/\u003econfig key\"]\n        ObjectStorageSecret[\"object-storage Secret\u003cbr/\u003econnection key\"]\n    end\n    \n    Webservice --\u003e|\"appConfig.lfs\"| LFSBucket\n    Toolbox --\u003e|\"backups.objectStorage\"| BackupBucket\n    Toolbox --\u003e|\"backups.objectStorage\"| TmpBucket\n    \n    StorageConfigSecret -.-\u003e|\"toolbox.backups.objectStorage.config\"| Toolbox\n    ObjectStorageSecret -.-\u003e|\"appConfig.lfs.connection\"| Webservice\n```\n\nGitLab requires three S3 buckets for external object storage:\n- `gitlab-backup-storage`: Stores automated GitLab backups created by the `gitlab-toolbox` pod\n- `gitlab-tmp-storage`: Holds temporary files during backup operations\n- `gitlab-lfs-storage`: Stores Git Large File Storage (LFS) objects for repositories containing large files such as datasets and model weights\n\nThe `storage-config` secret contains S3 credentials in s3cmd configuration format, while the `object-storage` secret provides LFS-specific connection parameters including endpoint, region, and AWS signature version.\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:16-66](), [docs/admin/deployment-guide/components/gitlab.md:162-184]()\n\n---\n\n## Deployment Configuration\n\n### ArgoCD Application Structure\n\nThe GitLab deployment is managed through an ArgoCD Application manifest that references the official GitLab Helm chart. The deployment structure follows this pattern:\n\n```mermaid\ngraph TB\n    subgraph \"argocd Namespace\"\n        ArgoCDApp[\"ArgoCD Application\u003cbr/\u003ename: gitlab\"]\n    end\n    \n    subgraph \"Helm Chart Source\"\n        GitLabChart[\"charts.gitlab.io/gitlab\u003cbr/\u003eversion: 8.1.0\"]\n    end\n    \n    subgraph \"gitlab Namespace\"\n        HelmRelease[\"Helm Release\"]\n        Webservice[\"gitlab-webservice Deployment\"]\n        Sidekiq[\"gitlab-sidekiq Deployment\"]\n        KAS[\"gitlab-kas Deployment\"]\n        PostgreSQL[\"gitlab-postgresql StatefulSet\"]\n        Redis[\"gitlab-redis StatefulSet\"]\n    end\n    \n    subgraph \"Ingress Resources\"\n        WebserviceIngress[\"gitlab.domain Ingress\u003cbr/\u003esecretName: gitlab.domain-tls\"]\n        KASIngress[\"kas.domain Ingress\u003cbr/\u003esecretName: kas.domain-tls\"]\n    end\n    \n    ArgoCDApp --\u003e|\"source.repoURL\u003cbr/\u003esource.chart\"| GitLabChart\n    ArgoCDApp --\u003e|\"spec.destination\"| HelmRelease\n    HelmRelease --\u003e|\"Deploys\"| Webservice\n    HelmRelease --\u003e|\"Deploys\"| Sidekiq\n    HelmRelease --\u003e|\"Deploys\"| KAS\n    HelmRelease --\u003e|\"Deploys\"| PostgreSQL\n    HelmRelease --\u003e|\"Deploys\"| Redis\n    \n    Webservice -.-\u003e|\"gitlab.webservice.ingress\"| WebserviceIngress\n    KAS -.-\u003e|\"gitlab.kas.ingress\"| KASIngress\n```\n\nThe ArgoCD Application manifest defines the deployment source (`repoURL: https://charts.gitlab.io`), chart version (`targetRevision: 8.1.0`), and destination namespace (`gitlab`). The `helm.valuesObject` section contains all GitLab configuration parameters.\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:107-230]()\n\n---\n\n### Key Configuration Parameters\n\nThe GitLab Helm chart configuration is structured hierarchically under the `global` and component-specific sections:\n\n| Configuration Path | Purpose | Example Value |\n|-------------------|---------|---------------|\n| `global.hosts.domain` | Base domain for all GitLab services | `example.com` |\n| `global.ingress.class` | Ingress controller class | `nginx` |\n| `global.ingress.annotations` | Ingress annotations for cert-manager | `cert-manager.io/cluster-issuer: letsencrypt-prod` |\n| `global.edition` | GitLab edition (ce/ee) | `ce` |\n| `global.appConfig.omniauth.enabled` | Enable OIDC authentication | `true` |\n| `global.appConfig.lfs.enabled` | Enable Git LFS | `true` |\n| `global.appConfig.lfs.bucket` | S3 bucket for LFS objects | `gitlab-lfs-storage` |\n| `global.appConfig.backups.bucket` | S3 bucket for backups | `gitlab-backup-storage` |\n| `gitlab.webservice.ingress.tls.secretName` | TLS certificate secret | `gitlab.example.com-tls` |\n| `gitlab.toolbox.backups.objectStorage.config.secret` | S3 credentials secret | `storage-config` |\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:125-184]()\n\n---\n\n### Minimal Deployment Mode\n\nThe provided GitLab deployment configuration disables several optional components to reduce resource consumption and complexity:\n\n```yaml\n# Disabled Components\nglobal.registry.enabled: false           # Container registry\nglobal.minio.enabled: false              # Internal object storage\nupgradeCheck.enabled: false              # Version upgrade checker\ncertmanager.install: false               # Use external cert-manager\nnginx-ingress.enabled: false             # Use external NGINX\nprometheus.install: false                # Monitoring stack\ngitlab-runner.install: false             # CI/CD runners\n```\n\nThis minimal configuration assumes external infrastructure components (cert-manager, NGINX Ingress Controller, S3 storage) are already available in the cluster.\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:13-14](), [docs/admin/deployment-guide/components/gitlab.md:137-216]()\n\n---\n\n## Authentication and Authorization\n\n### OIDC Integration with Keycloak\n\nGitLab integrates with Keycloak as an OpenID Connect (OIDC) provider to enable single sign-on (SSO) authentication. The integration flow is as follows:\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Browser\n    participant GitLabWebservice as gitlab-webservice\n    participant OIDCSecret as openid-connect Secret\n    participant Keycloak as Keycloak IdP\n    \n    User-\u003e\u003eBrowser: Navigate to GitLab\n    Browser-\u003e\u003eGitLabWebservice: GET /users/sign_in\n    GitLabWebservice-\u003e\u003eBrowser: Show login page with OIDC button\n    User-\u003e\u003eBrowser: Click \"Sign in with EOEPCA\"\n    Browser-\u003e\u003eGitLabWebservice: Initiate OIDC flow\n    GitLabWebservice-\u003e\u003eOIDCSecret: Read client_id and secret\n    GitLabWebservice-\u003e\u003eKeycloak: Authorization request\u003cbr/\u003e(client_id, redirect_uri, scope, PKCE)\n    Keycloak-\u003e\u003eBrowser: Redirect to Keycloak login\n    User-\u003e\u003eKeycloak: Enter credentials\n    Keycloak-\u003e\u003eBrowser: Redirect to callback with auth code\n    Browser-\u003e\u003eGitLabWebservice: GET /users/auth/openid_connect/callback?code=...\n    GitLabWebservice-\u003e\u003eKeycloak: Exchange auth code for tokens\n    Keycloak-\u003e\u003eGitLabWebservice: Access token + ID token\n    GitLabWebservice-\u003e\u003eGitLabWebservice: Create/update user from ID token claims\n    GitLabWebservice-\u003e\u003eBrowser: Set session cookie, redirect to dashboard\n```\n\nThe OIDC configuration is stored in the `openid-connect` secret with the following structure in `provider.yaml`:\n\n```yaml\nname: openid_connect\nlabel: EOEPCA                                    # Button label on login page\nargs:\n  scope: [\"openid\", \"profile\", \"email\"]\n  response_type: \"code\"                          # Authorization code flow\n  issuer: \"https://keycloak.domain/realms/realm\" # OIDC issuer URL\n  discovery: true                                 # Auto-discover endpoints\n  uid_field: \"preferred_username\"                 # Map username from token\n  pkce: true                                      # Enable PKCE for security\n  client_options:\n    identifier: \"gitlab\"                          # Client ID in Keycloak\n    redirect_uri: \"https://gitlab.domain/users/auth/openid_connect/callback\"\n```\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:68-103](), [docs/admin/deployment-guide/components/gitlab.md:143-148]()\n\n---\n\n### OAuth Provider for SharingHub\n\nGitLab also functions as an OAuth 2.0 provider for SharingHub. When SharingHub needs to access GitLab projects on behalf of a user, it initiates an OAuth flow where GitLab authenticates the user and issues an access token. SharingHub uses this token to query the GitLab API for project metadata, repository contents, and topic information.\n\nThe OAuth application must be configured in GitLab with the SharingHub callback URL (typically `https://sharinghub.domain/oauth/callback`). The application ID and secret are then stored in Kubernetes secrets for SharingHub to use.\n\n**Sources:** [docs/admin/deployment-guide/intro.md:5-6]()\n\n---\n\n## Project Organization and Topics\n\n### GitLab Topics for Categorization\n\nGitLab topics serve as the primary mechanism for categorizing projects and enabling automatic discovery in SharingHub. Projects are tagged with specific topics that correspond to STAC collection types:\n\n| GitLab Topic | STAC Collection | Purpose |\n|-------------|-----------------|---------|\n| `sharinghub:aimodel` | AI Model Collection | Machine learning models (trained weights, ONNX files) |\n| `sharinghub:dataset` | Dataset Collection | Training and evaluation datasets |\n| `sharinghub:processor` | Processor Collection | Data processing and inference workflows |\n\n```mermaid\ngraph LR\n    subgraph \"GitLab Projects\"\n        Project1[\"flood-detection-model\u003cbr/\u003eTopics: sharinghub:aimodel\u003cbr/\u003eTags: image-segmentation, flood\"]\n        Project2[\"sen1floods11-dataset\u003cbr/\u003eTopics: sharinghub:dataset\u003cbr/\u003eTags: flood-detection, sentinel-1\"]\n        Project3[\"inference-processor\u003cbr/\u003eTopics: sharinghub:processor\u003cbr/\u003eTags: cwl, onnx-runtime\"]\n    end\n    \n    subgraph \"SharingHub Catalog\"\n        AICollection[\"AI Model Collection\u003cbr/\u003eFilter: topic=sharinghub:aimodel\"]\n        DSCollection[\"Dataset Collection\u003cbr/\u003eFilter: topic=sharinghub:dataset\"]\n        ProcCollection[\"Processor Collection\u003cbr/\u003eFilter: topic=sharinghub:processor\"]\n    end\n    \n    subgraph \"STAC Items\"\n        STACItem1[\"STAC Item: flood-detection-model\u003cbr/\u003eml-model extension\"]\n        STACItem2[\"STAC Item: sen1floods11-dataset\u003cbr/\u003eeo extension\"]\n        STACItem3[\"STAC Item: inference-processor\u003cbr/\u003eprocessing extension\"]\n    end\n    \n    Project1 -.-\u003e|\"Filtered by topic\"| AICollection\n    Project2 -.-\u003e|\"Filtered by topic\"| DSCollection\n    Project3 -.-\u003e|\"Filtered by topic\"| ProcCollection\n    \n    AICollection --\u003e|\"Generates\"| STACItem1\n    DSCollection --\u003e|\"Generates\"| STACItem2\n    ProcCollection --\u003e|\"Generates\"| STACItem3\n```\n\nSharingHub periodically queries the GitLab API to discover projects with these topics and generates corresponding STAC catalog entries. Additional GitLab tags provide finer-grained classification within each collection.\n\n**Sources:** Based on high-level architecture diagrams\n\n---\n\n## S3 Storage Configuration\n\n### Storage Configuration Secret\n\nThe `storage-config` secret contains s3cmd-compatible configuration for GitLab's backup functionality. This configuration is mounted by the `gitlab-toolbox` pod and referenced via the `gitlab.toolbox.backups.objectStorage.config` Helm values:\n\n```conf\n[default]\naccess_key = \u003caccess_key\u003e\nbucket_location = \u003cbucket_region\u003e\nhost_base = \u003cs3_endpoint\u003e\nsecret_key = \u003csecret_key\u003e\nuse_https = True\n```\n\nThe secret is created with:\n```bash\nkubectl create secret generic storage-config --from-file=config=storage.config -n gitlab\n```\n\nAnd referenced in the Helm values at [docs/admin/deployment-guide/components/gitlab.md:179-184]():\n```yaml\ngitlab.toolbox.backups.objectStorage.config.secret: storage-config\ngitlab.toolbox.backups.objectStorage.config.key: config\n```\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:16-39](), [docs/admin/deployment-guide/components/gitlab.md:179-184]()\n\n---\n\n### LFS Object Storage Secret\n\nThe `object-storage` secret contains AWS SDK-compatible configuration for Git LFS. This configuration is mounted by the `gitlab-webservice` pod and referenced via the `global.appConfig.lfs.connection` Helm values:\n\n```yaml\nprovider: AWS\nregion: eu\naws_access_key_id: \u003caccess_key\u003e\naws_secret_access_key: \u003csecret_key\u003e\naws_signature_version: 4                    # Required for non-AWS S3\nhost: \u003cs3_endpoint\u003e\nendpoint: \"https://\u003cs3_endpoint\u003e\"\npath_style: true                             # Use path-style URLs\n```\n\nThe secret is created with:\n```bash\nkubectl create secret generic object-storage --from-file=connection=lfs-s3.yaml -n gitlab\n```\n\nAnd referenced in the Helm values at [docs/admin/deployment-guide/components/gitlab.md:150-155]():\n```yaml\nglobal.appConfig.lfs.enabled: true\nglobal.appConfig.lfs.bucket: gitlab-lfs-storage\nglobal.appConfig.lfs.connection.secret: object-storage\nglobal.appConfig.lfs.connection.key: connection\n```\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:41-66](), [docs/admin/deployment-guide/components/gitlab.md:150-155]()\n\n---\n\n## Integration with MLOps Components\n\n### SharingHub Metadata Extraction\n\nSharingHub connects to GitLab via its API to extract project metadata for STAC catalog generation. The integration involves:\n\n1. **Authentication**: SharingHub uses OAuth 2.0 to authenticate users and obtain access tokens\n2. **Project Discovery**: Queries GitLab API for projects with specific topics (e.g., `/api/v4/projects?topic=sharinghub:aimodel`)\n3. **Metadata Extraction**: Retrieves project details including name, description, repository URL, tags, and file listings\n4. **STAC Generation**: Transforms GitLab project metadata into STAC items with appropriate extensions\n\nThe SharingHub configuration includes GitLab connection parameters:\n```yaml\nserver:\n  gitlab_url: \"https://gitlab.example.com\"\n  gitlab_oauth_client_id: \"\u003coauth_app_id\u003e\"\n  gitlab_oauth_client_secret: \"\u003coauth_app_secret\u003e\"\n```\n\n**Sources:** [docs/admin/deployment-guide/intro.md:5-7]()\n\n---\n\n### DVC Integration\n\nData Version Control (DVC) uses GitLab repositories to track dataset versions while storing actual data in S3. The workflow is:\n\n1. Data scientist creates a GitLab project with the `sharinghub:dataset` topic\n2. DVC is initialized in the local repository (`dvc init`)\n3. Large dataset files are tracked with DVC (`dvc add data/`)\n4. DVC generates `.dvc` metadata files committed to GitLab\n5. Actual data is pushed to S3 (`dvc push`)\n6. Other users clone the GitLab repository and fetch data from S3 (`dvc pull`)\n\nThis separation allows GitLab to remain performant while supporting large-scale datasets. The DVC-tracked project automatically appears in the SharingHub catalog as a dataset entry.\n\n**Sources:** Based on high-level architecture diagrams\n\n---\n\n## GitLab Components and Services\n\n### Core Pods and Services\n\nThe GitLab deployment creates several interconnected Kubernetes resources:\n\n```mermaid\ngraph TB\n    subgraph \"User Traffic\"\n        NginxIngress[\"NGINX Ingress Controller\"]\n    end\n    \n    subgraph \"gitlab Namespace\"\n        WebserviceIngress[\"gitlab.domain Ingress\"]\n        WebserviceService[\"gitlab-webservice Service\"]\n        WebserviceDeployment[\"gitlab-webservice Deployment\u003cbr/\u003eReplicas: configurable\"]\n        \n        KASIngress[\"kas.domain Ingress\"]\n        KASService[\"gitlab-kas Service\"]\n        KASDeployment[\"gitlab-kas Deployment\"]\n        \n        SidekiqDeployment[\"gitlab-sidekiq Deployment\u003cbr/\u003eBackground job processing\"]\n        \n        ToolboxDeployment[\"gitlab-toolbox Deployment\u003cbr/\u003eBackup and maintenance\"]\n        \n        PostgreSQLService[\"gitlab-postgresql Service\"]\n        PostgreSQLStatefulSet[\"gitlab-postgresql StatefulSet\u003cbr/\u003ePersistent storage\"]\n        \n        RedisService[\"gitlab-redis-master Service\"]\n        RedisStatefulSet[\"gitlab-redis StatefulSet\"]\n    end\n    \n    NginxIngress --\u003e WebserviceIngress\n    NginxIngress --\u003e KASIngress\n    \n    WebserviceIngress --\u003e WebserviceService\n    WebserviceService --\u003e WebserviceDeployment\n    \n    KASIngress --\u003e KASService\n    KASService --\u003e KASDeployment\n    \n    WebserviceDeployment --\u003e PostgreSQLService\n    WebserviceDeployment --\u003e RedisService\n    SidekiqDeployment --\u003e PostgreSQLService\n    SidekiqDeployment --\u003e RedisService\n    ToolboxDeployment --\u003e PostgreSQLService\n    \n    PostgreSQLService --\u003e PostgreSQLStatefulSet\n    RedisService --\u003e RedisStatefulSet\n```\n\n**Component Descriptions:**\n\n- **gitlab-webservice**: Handles HTTP requests, serves the web UI, and provides the REST API. This is the primary entry point for users and integrations.\n- **gitlab-sidekiq**: Processes asynchronous jobs including repository operations, CI/CD pipelines, and email notifications.\n- **gitlab-kas**: Provides the Kubernetes Agent Server for GitOps-based deployments to Kubernetes clusters.\n- **gitlab-toolbox**: Executes maintenance tasks including database backups to S3 and repository housekeeping.\n- **gitlab-postgresql**: Stores all GitLab data including repositories, issues, merge requests, and user accounts.\n- **gitlab-redis**: Provides caching and job queue management for Sidekiq.\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:169-188]()\n\n---\n\n## Minimal Configuration Rationale\n\nThe GitLab deployment is configured in \"minimal mode\" with several components disabled to reduce resource usage and deployment complexity:\n\n| Disabled Component | Rationale |\n|-------------------|-----------|\n| `global.registry.enabled: false` | Container images are stored in external registries; GitLab's built-in registry is unnecessary |\n| `global.minio.enabled: false` | External S3-compatible storage is used instead of bundled MinIO |\n| `certmanager.install: false` | Cluster-wide cert-manager installation is already present |\n| `nginx-ingress.enabled: false` | Cluster-wide NGINX Ingress Controller is already deployed |\n| `prometheus.install: false` | Monitoring is handled by external Prometheus instance or not required |\n| `gitlab-runner.install: false` | CI/CD runners can be registered separately if needed |\n\nThis configuration is suitable for environments where GitLab primarily serves as a code repository and OAuth provider, with MLflow handling experiment tracking and SharingHub providing model discovery. CI/CD capabilities can be enabled by setting `gitlab-runner.install: true` and configuring runners.\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:13-14](), [docs/admin/deployment-guide/components/gitlab.md:137-216]()\n\n---\n\n## TLS Certificate Management\n\nGitLab ingress resources request TLS certificates from cert-manager using annotations:\n\n```yaml\nglobal.ingress.annotations:\n  cert-manager.io/cluster-issuer: letsencrypt-prod\n```\n\nIndividual services specify their certificate secret names:\n\n| Service | Ingress Host | TLS Secret Name |\n|---------|--------------|-----------------|\n| GitLab Web UI | `gitlab.\u003cdomain\u003e` | `gitlab.\u003cdomain\u003e-tls` |\n| Kubernetes Agent Server | `kas.\u003cdomain\u003e` | `kas.\u003cdomain\u003e-tls` |\n\nThe cert-manager `ClusterIssuer` named `letsencrypt-prod` automatically provisions certificates from Let's Encrypt using the ACME protocol with HTTP-01 or DNS-01 challenges. Certificates are automatically renewed before expiration.\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:131-135](), [docs/admin/deployment-guide/components/gitlab.md:171-178]()\n\n---\n\n## Summary\n\nGitLab serves as the foundational component of the EOEPCA MLOps Building Block, providing:\n\n- **Version Control**: Git repository management for code, models, and datasets\n- **Project Organization**: Topic-based categorization that enables automatic discovery in SharingHub\n- **Authentication**: OIDC integration with Keycloak for user authentication and OAuth provider for SharingHub\n- **Storage Integration**: S3-backed LFS and backup storage for scalability\n- **API Access**: REST API for metadata extraction and programmatic access by other components\n\nThe deployment follows a minimal configuration approach, leveraging external infrastructure components (cert-manager, NGINX, S3) and disabling unused features to optimize resource usage. The Kubernetes-native deployment via ArgoCD and Helm enables declarative infrastructure management and easy upgrades.\n\n**Sources:** [docs/admin/deployment-guide/intro.md:10-14](), [docs/admin/deployment-guide/components/gitlab.md:1-243]()"])</script><script>self.__next_f.push([1,"1d:T55b7,"])</script><script>self.__next_f.push([1,"# SharingHub\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/configuration.md](docs/admin/configuration.md)\n- [docs/admin/deployment-guide/components/sharinghub.md](docs/admin/deployment-guide/components/sharinghub.md)\n- [docs/index.md](docs/index.md)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nSharingHub is the central discovery and collaboration platform within the EOEPCA MLOps Building Block. It dynamically generates a STAC (SpatioTemporal Asset Catalog) API from GitLab projects, enabling users to discover, browse, and access AI models, datasets, and processing workflows through a standardized interface. SharingHub acts as the bridge between GitLab's project management capabilities and standardized catalog discovery protocols.\n\nFor information about deploying SharingHub, see [SharingHub Deployment](#5.3). For detailed configuration options, see [SharingHub Configuration](#6.1). For using the STAC API programmatically, see [STAC API Specification](#7.1).\n\n**Sources:** [docs/index.md:16-29](), [docs/admin/deployment-guide/components/sharinghub.md:1-4]()\n\n## Architecture Overview\n\nSharingHub is a Python-based web service that integrates with GitLab to provide dynamic catalog generation. The service extracts metadata from GitLab projects and exposes them as STAC items through a standards-compliant API.\n\n### Core Components\n\n```mermaid\ngraph TB\n    subgraph \"SharingHub Service\"\n        WebUI[\"Web UI\u003cbr/\u003e(FastAPI + Jinja2 Templates)\"]\n        STACAPI[\"STAC API Router\u003cbr/\u003e(FastAPI endpoints)\"]\n        StoreAPI[\"Store API Router\u003cbr/\u003e(S3 proxy for DVC)\"]\n        AuthMiddleware[\"Authentication Middleware\u003cbr/\u003e(OAuth session management)\"]\n        CacheSystem[\"Cache System\u003cbr/\u003e(In-memory with timeout)\"]\n    end\n    \n    subgraph \"Data Providers\"\n        GitLabClient[\"GitLab API Client\u003cbr/\u003e(Projects, Topics, Metadata)\"]\n        S3Client[\"S3 Client\u003cbr/\u003e(Artifacts storage access)\"]\n        MLflowClient[\"MLflow Client\u003cbr/\u003e(Model registry queries)\"]\n    end\n    \n    subgraph \"STAC Generation\"\n        RootCatalog[\"Root STAC Catalog\u003cbr/\u003e(config: stac.root.id)\"]\n        Collections[\"STAC Collections\u003cbr/\u003e(config: stac.categories)\"]\n        ItemGenerator[\"STAC Item Generator\u003cbr/\u003e(GitLab project  STAC item)\"]\n        Extensions[\"STAC Extensions Handler\u003cbr/\u003e(ml-model, eo, label, sci)\"]\n    end\n    \n    subgraph \"External Systems\"\n        GitLab[\"GitLab Instance\u003cbr/\u003e(Projects, OAuth Provider)\"]\n        S3Storage[\"S3 Object Storage\u003cbr/\u003e(Artifacts, Datasets)\"]\n        MLflow[\"MLflow SharingHub\u003cbr/\u003e(Model Registry)\"]\n    end\n    \n    WebUI --\u003e AuthMiddleware\n    STACAPI --\u003e AuthMiddleware\n    StoreAPI --\u003e AuthMiddleware\n    \n    AuthMiddleware --\u003e GitLabClient\n    STACAPI --\u003e ItemGenerator\n    STACAPI --\u003e Collections\n    STACAPI --\u003e RootCatalog\n    ItemGenerator --\u003e Extensions\n    ItemGenerator --\u003e CacheSystem\n    \n    GitLabClient --\u003e GitLab\n    GitLabClient --\u003e CacheSystem\n    S3Client --\u003e S3Storage\n    MLflowClient --\u003e MLflow\n    \n    StoreAPI --\u003e S3Client\n    ItemGenerator --\u003e GitLabClient\n    ItemGenerator --\u003e MLflowClient\n    \n    Collections -.gitlab_topic mapping.-\u003e GitLabClient\n```\n\n**Diagram: SharingHub Internal Architecture**\n\nThe service is deployed as a single Kubernetes pod running a FastAPI application. It maintains in-memory caches with configurable timeouts to optimize performance when querying GitLab and S3 resources.\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:49-215](), [docs/admin/configuration.md:8-280]()\n\n## STAC Catalog Structure\n\nSharingHub generates a hierarchical STAC catalog structure that maps GitLab organizational concepts to STAC entities. The catalog is dynamically created based on configuration and current GitLab project state.\n\n### GitLab to STAC Mapping\n\n```mermaid\ngraph TB\n    subgraph \"Configuration Layer\"\n        Config[\"config: stac.categories\u003cbr/\u003e(YAML configuration)\"]\n        AIModelCat[\"ai-model category\u003cbr/\u003egitlab_topic: sharinghub:aimodel\"]\n        DatasetCat[\"dataset category\u003cbr/\u003egitlab_topic: sharinghub:dataset\"]\n        ProcessorCat[\"processor category\u003cbr/\u003egitlab_topic: sharinghub:processor\"]\n    end\n    \n    subgraph \"GitLab Projects\"\n        GP1[\"Project: flood-model\u003cbr/\u003eTopic: sharinghub:aimodel\u003cbr/\u003eTags: Image Segmentation\"]\n        GP2[\"Project: sen1floods11-dataset\u003cbr/\u003eTopic: sharinghub:dataset\u003cbr/\u003eTags: Flood Detection\"]\n        GP3[\"Project: wine-classifier\u003cbr/\u003eTopic: sharinghub:aimodel\u003cbr/\u003eTags: Tabular Classification\"]\n    end\n    \n    subgraph \"STAC Catalog Structure\"\n        Root[\"STAC Root Catalog\u003cbr/\u003eid: stac.root.id\u003cbr/\u003etype: Catalog\"]\n        CollAI[\"STAC Collection: ai-model\u003cbr/\u003etype: Collection\"]\n        CollDS[\"STAC Collection: dataset\u003cbr/\u003etype: Collection\"]\n        \n        Item1[\"STAC Item: flood-model\u003cbr/\u003estac_extensions: ml-model\u003cbr/\u003eassets: ONNX files\"]\n        Item2[\"STAC Item: sen1floods11\u003cbr/\u003estac_extensions: eo, label\u003cbr/\u003eassets: GeoTIFF files\"]\n        Item3[\"STAC Item: wine-classifier\u003cbr/\u003estac_extensions: ml-model\u003cbr/\u003eassets: ONNX, CSV\"]\n    end\n    \n    subgraph \"Metadata Extraction\"\n        Extractor[\"Item Generator\u003cbr/\u003e(Python logic)\"]\n        MetadataYAML[\"sharinghub.yaml\u003cbr/\u003e(Project metadata file)\"]\n        MLflowLink[\"MLflow Registry Lookup\u003cbr/\u003e(Auto-link models)\"]\n    end\n    \n    Config --\u003e AIModelCat\n    Config --\u003e DatasetCat\n    Config --\u003e ProcessorCat\n    \n    AIModelCat -.topic filter.-\u003e GP1\n    AIModelCat -.topic filter.-\u003e GP3\n    DatasetCat -.topic filter.-\u003e GP2\n    \n    Root --\u003e CollAI\n    Root --\u003e CollDS\n    \n    CollAI --\u003e Item1\n    CollAI --\u003e Item3\n    CollDS --\u003e Item2\n    \n    GP1 --\u003e Extractor\n    GP2 --\u003e Extractor\n    GP3 --\u003e Extractor\n    \n    Extractor --\u003e MetadataYAML\n    Extractor --\u003e MLflowLink\n    Extractor --\u003e Item1\n    Extractor --\u003e Item2\n    Extractor --\u003e Item3\n    \n    MLflowLink -.registered model link.-\u003e Item1\n```\n\n**Diagram: STAC Catalog Generation from GitLab Projects**\n\nThe mapping process works as follows:\n\n1. **Root Catalog**: Defined in configuration at `stac.root.id`, this is the entry point of the STAC catalog\n2. **Collections (Categories)**: Each entry in `stac.categories` becomes a STAC Collection, mapped to a specific `gitlab_topic`\n3. **Items**: GitLab projects with matching topics are converted to STAC Items with appropriate extensions\n4. **Metadata**: Projects can include a `sharinghub.yaml` file for additional STAC metadata\n5. **Auto-linking**: Registered MLflow models are automatically linked to their corresponding STAC items\n\n**Sources:** [docs/admin/configuration.md:119-179](), [docs/admin/deployment-guide/components/sharinghub.md:68-120]()\n\n### Category Configuration Structure\n\nCategories are defined in the configuration file with the following structure:\n\n| Configuration Field | Purpose | Example Value |\n|-------------------|---------|---------------|\n| `title` | Display name for the category | `\"AI Models\"` |\n| `description` | Category description | `\"AI models are the core...\"` |\n| `gitlab_topic` | GitLab topic for project filtering | `sharinghub:aimodel` |\n| `logo` | URL to category logo image | `https://data.web.example.com/ai-model.jpg` |\n| `icon` | URL to category icon | `https://img.icons8.com/material/24/ai.png` |\n| `locales` | Translations for multi-language support | `fr: {title: \"Modles IA\"}` |\n| `features.map-viewer` | Enable/disable map visualization | `enable` or `disable` |\n| `features.store-s3` | Enable/disable S3 store API | `enable` or `disable` |\n| `features.mlflow` | Enable/disable MLflow integration | `enable` or `disable` |\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:92-120](), [docs/admin/configuration.md:142-179]()\n\n## Authentication and Authorization\n\nSharingHub implements a multi-layered authentication and authorization system that integrates with GitLab's OAuth provider.\n\n### Authentication Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Browser\n    participant SharingHub as \"SharingHub\u003cbr/\u003e(FastAPI + Session)\"\n    participant GitLabOAuth as \"GitLab OAuth\u003cbr/\u003e(OIDC Provider)\"\n    participant GitLabAPI as \"GitLab API\u003cbr/\u003e(Project Access)\"\n    \n    User-\u003e\u003eBrowser: Access SharingHub\n    Browser-\u003e\u003eSharingHub: GET /api/stac\n    \n    alt Authenticated Session\n        SharingHub-\u003e\u003eSharingHub: Check session cookie\n        SharingHub-\u003e\u003eBrowser: Return catalog (user scope)\n    else No Session - Default Token\n        SharingHub-\u003e\u003eSharingHub: Use default token (if configured)\n        SharingHub-\u003e\u003eGitLabAPI: Query projects (default token)\n        GitLabAPI-\u003e\u003eSharingHub: Return public projects\n        SharingHub-\u003e\u003eBrowser: Return catalog (limited scope)\n    else No Session - No Default Token\n        SharingHub-\u003e\u003eBrowser: Return catalog (empty/public only)\n    end\n    \n    User-\u003e\u003eBrowser: Click login\n    Browser-\u003e\u003eSharingHub: GET /api/auth/login\n    SharingHub-\u003e\u003eGitLabOAuth: Redirect to OAuth authorize\n    GitLabOAuth-\u003e\u003eUser: Show login page\n    User-\u003e\u003eGitLabOAuth: Enter credentials\n    GitLabOAuth-\u003e\u003eBrowser: Redirect to callback URL\n    Browser-\u003e\u003eSharingHub: GET /api/auth/login/callback?code=...\n    SharingHub-\u003e\u003eGitLabOAuth: Exchange code for token\n    GitLabOAuth-\u003e\u003eSharingHub: Return access token\n    SharingHub-\u003e\u003eSharingHub: Create session with token\n    SharingHub-\u003e\u003eBrowser: Set session cookie\n    Browser-\u003e\u003eUser: Redirect to home\n```\n\n**Diagram: OAuth Authentication Flow**\n\n### Session Management\n\nSessions are managed using server-side storage with signed cookies. Key configuration parameters:\n\n- **Secret Key**: Stored in Kubernetes secret `sharinghub` with key `session-secret-key`\n- **Cookie Name**: Configurable via `server.session.cookie` (default: `sharinghub-session`)\n- **Domain**: Set via `server.session.domain` for cross-subdomain sessions\n- **Max Age**: Session timeout in seconds via `server.session.max-age` (default: 14400 = 4 hours)\n\n**Sources:** [docs/admin/configuration.md:49-61](), [docs/admin/deployment-guide/components/sharinghub.md:8-14]()\n\n### Default Token Mechanism\n\nSharingHub supports an optional default token mechanism for unauthenticated access:\n\n1. **Configuration**: Set via Kubernetes secret `sharinghub-oidc` with key `default-token`\n2. **Token Types**: Can be a GitLab Personal Access Token or Group Access Token\n3. **Required Scopes**: `read_api`, `read_repository` (Group tokens require Reporter role minimum)\n4. **Behavior**: When configured, unauthenticated users see projects accessible via the default token\n\nThis mechanism enables public read-only access to datasets and models while maintaining security for private resources.\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:39-45](), [docs/admin/configuration.md:111-116]()\n\n### Permission Checking\n\n```mermaid\ngraph LR\n    Request[\"API Request\u003cbr/\u003e(STAC or Store)\"]\n    AuthCheck[\"Authentication Check\u003cbr/\u003e(Session or Default Token)\"]\n    GitLabQuery[\"GitLab API Query\u003cbr/\u003e(Project metadata + access)\"]\n    CacheCheck[\"Permission Cache\u003cbr/\u003e(cache-timeout: 30s)\"]\n    Response[\"Filtered Response\u003cbr/\u003e(User-specific view)\"]\n    \n    Request --\u003e AuthCheck\n    AuthCheck --\u003e CacheCheck\n    CacheCheck -.cache miss.-\u003e GitLabQuery\n    GitLabQuery --\u003e CacheCheck\n    CacheCheck --\u003e Response\n    \n    GitLabQuery -.projects visible to token.-\u003e Response\n```\n\n**Diagram: Permission Checking Flow**\n\nEach API request performs permission checking by:\n1. Extracting the access token (from session or default token)\n2. Checking the cache for recent permission data\n3. Querying GitLab API for project visibility (on cache miss)\n4. Filtering results based on user's project access rights\n\n**Sources:** [docs/admin/configuration.md:63-86](), [docs/admin/configuration.md:88-116]()\n\n## Core Features\n\n### Categories and Collections\n\nCategories map GitLab topics to STAC collections, enabling organized discovery of projects. Each category configuration includes:\n\n- **Display metadata**: Title, description, logo, and icon\n- **GitLab mapping**: `gitlab_topic` specifies which GitLab topic to filter on\n- **Feature toggles**: Per-category enable/disable of map-viewer, S3 store, and MLflow\n- **Localization**: Multi-language support via `locales` field\n\nExample from configuration:\n\n```yaml\ncategories:\n  - ai-model:\n      title: \"AI Models\"\n      gitlab_topic: sharinghub:aimodel\n      features:\n        map-viewer: enable\n        store-s3: enable\n        mlflow: enable\n```\n\n**Sources:** [docs/admin/configuration.md:119-179]()\n\n### Tags System\n\nTags provide fine-grained classification within categories. The configuration defines tag sections that organize related keywords:\n\n| Configuration Path | Purpose |\n|-------------------|---------|\n| `tags.gitlab.minimum_count` | Minimum projects for a tag to appear |\n| `tags.sections[].name` | Section name (e.g., \"Computer Vision\") |\n| `tags.sections[].enabled_for` | Which categories show this section |\n| `tags.sections[].keywords` | List of tag keywords in this section |\n\nTags are mapped from GitLab project topics and displayed in the web UI's left panel for filtering.\n\n**Sources:** [docs/admin/configuration.md:235-264]()\n\n### S3 Store API\n\nWhen enabled, the Store API provides an S3-compatible interface that allows DVC (Data Version Control) to store and retrieve data artifacts. This feature:\n\n- **URL Configuration**: Set via `services.store.url` and `services.store.mode`\n- **Access Control**: Checks GitLab project permissions before granting S3 access\n- **S3 Backend**: Requires configuration of `s3.bucket`, `s3.region`, `s3.endpoint`\n- **Credentials**: Stored in Kubernetes secret `sharinghub-s3` with keys `access-key` and `secret-key`\n- **Per-Category**: Can be enabled/disabled via `features.store-s3` in category config\n\nThe Store API acts as a proxy, translating DVC's S3 requests to the configured S3 backend while enforcing GitLab-based access control.\n\n**Sources:** [docs/admin/configuration.md:208-233]()\n\n### MLflow Integration\n\nSharingHub integrates with MLflow SharingHub to provide experiment tracking and model registry features:\n\n| Integration Type | Configuration | Description |\n|-----------------|---------------|-------------|\n| `mlflow-sharinghub` | **Recommended** | Custom MLflow with SharingHub permission checking |\n| `mlflow` | Basic setup | Standard MLflow instance without authentication |\n| `gitlab` | GitLab ML Tracking | Uses GitLab's built-in ML tracking features |\n\nConfiguration example:\n\n```yaml\nmlflow:\n  type: mlflow-sharinghub\n  url: https://sharinghub.example.com/mlflow\n```\n\nWhen `mlflow-sharinghub` is configured:\n- Per-project tracking URIs are generated from GitLab project paths\n- Permission checks are delegated to SharingHub\n- Registered models are automatically linked to STAC items\n- Model artifacts are exposed as STAC assets\n\n**Sources:** [docs/admin/configuration.md:186-206]()\n\n## Integration Points\n\n### GitLab API Integration\n\n```mermaid\ngraph TB\n    subgraph \"SharingHub Queries\"\n        ProjectQuery[\"Project List Query\u003cbr/\u003e(Filtered by topic)\"]\n        ProjectDetail[\"Project Detail Query\u003cbr/\u003e(Metadata, files, tags)\"]\n        FileQuery[\"File Content Query\u003cbr/\u003e(sharinghub.yaml)\"]\n        UserQuery[\"User Info Query\u003cbr/\u003e(Profile, permissions)\"]\n    end\n    \n    subgraph \"GitLab API Endpoints\"\n        ProjectsAPI[\"/api/v4/projects\"]\n        ProjectAPI[\"/api/v4/projects/:id\"]\n        RepoAPI[\"/api/v4/projects/:id/repository\"]\n        UserAPI[\"/api/v4/user\"]\n    end\n    \n    subgraph \"Caching Layer\"\n        ProjectCache[\"Projects Cache\u003cbr/\u003e(cache-timeout: 30s)\"]\n        PermissionCache[\"Permission Cache\u003cbr/\u003e(cache-timeout: 30s)\"]\n    end\n    \n    ProjectQuery --\u003e ProjectCache\n    ProjectDetail --\u003e ProjectCache\n    ProjectCache -.cache miss.-\u003e ProjectsAPI\n    ProjectCache -.cache miss.-\u003e ProjectAPI\n    \n    FileQuery --\u003e RepoAPI\n    UserQuery --\u003e UserAPI\n    \n    ProjectQuery --\u003e PermissionCache\n    PermissionCache -.cache miss.-\u003e ProjectsAPI\n```\n\n**Diagram: GitLab API Integration Points**\n\nSharingHub queries GitLab through the following patterns:\n\n1. **Topic-based filtering**: Projects are discovered using the `topic` parameter matching `gitlab_topic` from category config\n2. **Metadata extraction**: Project descriptions, README files, and optional `sharinghub.yaml` files provide STAC metadata\n3. **Access control**: User permissions from GitLab determine project visibility in the catalog\n4. **Ignored topics**: Topics listed in `gitlab.ignore.topics` are filtered from tag lists\n\n**Sources:** [docs/admin/configuration.md:88-116]()\n\n### STAC Extensions Support\n\nSharingHub declares support for multiple STAC extensions in its configuration:\n\n| Extension | Schema URL | Use Case |\n|-----------|------------|----------|\n| `ml-model` | `https://stac-extensions.github.io/ml-model/v1.0.0/schema.json` | AI models with training details |\n| `eo` | `https://stac-extensions.github.io/eo/v1.1.0/schema.json` | Earth observation datasets |\n| `label` | `https://stac-extensions.github.io/label/v1.0.1/schema.json` | Labeled training data |\n| `sci` | `https://stac-extensions.github.io/scientific/v1.0.0/schema.json` | Scientific datasets |\n\nExtensions are declared in `stac.extensions` configuration and included in the root catalog's `stac_extensions` field.\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:79-83](), [docs/admin/configuration.md:129-133]()\n\n## API Endpoints\n\nSharingHub exposes several API endpoint groups:\n\n### STAC API Endpoints\n\n| Endpoint Pattern | Purpose | STAC Conformance |\n|-----------------|---------|------------------|\n| `/api/stac` | Root STAC catalog | Catalog |\n| `/api/stac/collections` | List all collections | OGC API - Features Part 1 |\n| `/api/stac/collections/{collection_id}` | Collection detail | Collection |\n| `/api/stac/collections/{collection_id}/items` | List items in collection | Items |\n| `/api/stac/collections/{collection_id}/items/{item_id}` | Item detail | Item |\n\n### Store API Endpoints\n\nWhen S3 store is enabled (`features.store-s3: enable`):\n\n| Endpoint Pattern | Purpose |\n|-----------------|---------|\n| `/api/store/{project_path}` | S3-compatible storage for DVC |\n\n### Authentication Endpoints\n\n| Endpoint | Purpose |\n|----------|---------|\n| `/api/auth/login` | Initiate OAuth flow with GitLab |\n| `/api/auth/login/callback` | OAuth callback handler |\n| `/api/auth/logout` | Clear session and logout |\n| `/api/auth/user` | Get current user info |\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:1-215](), [docs/admin/configuration.md:1-280]()\n\n## Deployment Architecture\n\nSharingHub is deployed as a Kubernetes pod with the following characteristics:\n\n### Container Image\n\n- **Repository**: `eoepca/sharinghub`\n- **Base**: Python FastAPI application\n- **Source**: [github.com/csgroup-oss/sharinghub](https://github.com/csgroup-oss/sharinghub)\n\n### Kubernetes Resources\n\n```mermaid\ngraph TB\n    subgraph \"sharinghub namespace\"\n        Pod[\"SharingHub Pod\u003cbr/\u003e(image: eoepca/sharinghub)\"]\n        SvcSecret[\"Secret: sharinghub\u003cbr/\u003e(session-secret-key)\"]\n        OIDCSecret[\"Secret: sharinghub-oidc\u003cbr/\u003e(client-id, client-secret, default-token)\"]\n        S3Secret[\"Secret: sharinghub-s3\u003cbr/\u003e(access-key, secret-key)\"]\n        ConfigMap[\"ConfigMap\u003cbr/\u003e(config.yaml)\"]\n        Service[\"Service: sharinghub\u003cbr/\u003e(ClusterIP)\"]\n        Ingress[\"Ingress: sharinghub\u003cbr/\u003e(nginx + TLS)\"]\n    end\n    \n    subgraph \"cert-manager namespace\"\n        CertManager[\"cert-manager\u003cbr/\u003e(TLS certificate provider)\"]\n    end\n    \n    subgraph \"External Dependencies\"\n        GitLabExt[\"GitLab Instance\u003cbr/\u003e(OAuth + API)\"]\n        S3Ext[\"S3 Storage\u003cbr/\u003e(Artifacts)\"]\n        MLflowExt[\"MLflow SharingHub\u003cbr/\u003e(Optional)\"]\n    end\n    \n    Pod --\u003e SvcSecret\n    Pod --\u003e OIDCSecret\n    Pod --\u003e S3Secret\n    Pod --\u003e ConfigMap\n    Service --\u003e Pod\n    Ingress --\u003e Service\n    Ingress --\u003e CertManager\n    \n    Pod --\u003e GitLabExt\n    Pod --\u003e S3Ext\n    Pod --\u003e MLflowExt\n```\n\n**Diagram: SharingHub Kubernetes Deployment**\n\n### Configuration Management\n\n- **Helm Chart**: Located in `deploy/helm/sharinghub` of the SharingHub repository\n- **Values**: Main configuration is in `config` field as YAML string\n- **Secrets**: Sensitive data managed via Kubernetes secrets\n- **ArgoCD**: GitOps-style deployment recommended\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:1-215]()\n\n### Ingress Configuration\n\nThe ingress configuration includes:\n\n- **TLS Termination**: Automated via cert-manager with Let's Encrypt\n- **Annotations**: \n  - `cert-manager.io/cluster-issuer: letsencrypt-prod` for certificate provisioning\n  - `nginx.ingress.kubernetes.io/ssl-redirect: \"true\"` to enforce HTTPS\n  - `nginx.ingress.kubernetes.io/proxy-body-size: 10g` to allow large artifact uploads\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:168-183]()\n\n## Performance Considerations\n\n### Caching Strategy\n\nSharingHub implements aggressive caching to minimize GitLab API calls:\n\n| Cache Type | Configuration Path | Default Timeout | Cached Data |\n|-----------|-------------------|----------------|-------------|\n| Project List | `stac.projects.cache-timeout` | 30s | Project discovery results |\n| Permission Check | `checker.cache-timeout` | 30s | User permission validation |\n| S3 Access | `s3.check-access.cache-timeout` | 30s | S3 bucket access rights |\n\nCache can be disabled for debugging via `server.cache: false`, though this significantly impacts performance.\n\n**Sources:** [docs/admin/configuration.md:63-86]()\n\n### Resource Requirements\n\nWhile not explicitly documented in the provided files, typical resource requirements include:\n\n- Memory for in-memory caching of GitLab responses\n- CPU for STAC item generation and JSON serialization\n- Network bandwidth for GitLab API communication\n\nThe stateless design allows horizontal scaling by deploying multiple pods behind a load balancer.\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:49-215]()"])</script><script>self.__next_f.push([1,"1e:T5818,"])</script><script>self.__next_f.push([1,"# MLflow SharingHub\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/configuration.md](docs/admin/configuration.md)\n- [docs/admin/deployment-guide/components/mlflow-sharinghub.md](docs/admin/deployment-guide/components/mlflow-sharinghub.md)\n- [docs/index.md](docs/index.md)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nMLflow SharingHub is a customized MLflow server that provides experiment tracking and model registry capabilities for the EOEPCA MLOps Building Block. This page describes its architecture, integration with SharingHub for permission management, storage backends, and its role in the model development lifecycle.\n\nFor deployment instructions, see [MLflow SharingHub Deployment](#5.4). For configuration details, see [MLflow SharingHub Configuration](#6.2).\n\n## Overview\n\nMLflow SharingHub extends the standard MLflow tracking server with GitLab project-based access control and automatic integration with the SharingHub STAC catalog. It serves as the central experiment tracking system where ML developers log training runs, metrics, parameters, and artifacts. When models are registered in the MLflow model registry, they are automatically linked to corresponding STAC items in SharingHub, enabling seamless discovery and consumption.\n\n**Key Capabilities:**\n\n- **Experiment Tracking:** Log metrics, parameters, artifacts, and model files from training runs\n- **Model Registry:** Version and manage production-ready models with lifecycle stages\n- **Permission Integration:** Delegate access control to SharingHub based on GitLab project permissions\n- **STAC Auto-linking:** Automatically associate registered models with STAC items for discovery\n- **Multi-project Support:** Project-specific tracking URIs mapped from GitLab project paths\n\nSources: [docs/index.md:16-28](), [docs/admin/configuration.md:282-297]()\n\n## Architecture\n\n### Component Structure\n\nMLflow SharingHub consists of several integrated components working together to provide experiment tracking and model registry functionality:\n\n```mermaid\ngraph TB\n    subgraph \"MLflow SharingHub Server\"\n        TRACKING[\"Tracking Server\u003cbr/\u003e(Flask Application)\"]\n        REGISTRY[\"Model Registry\u003cbr/\u003e(MLflow Component)\"]\n        PERMS[\"Permission Checker\u003cbr/\u003e(SharingHub Integration)\"]\n    end\n    \n    subgraph \"Storage Backends\"\n        POSTGRES[(\"PostgreSQL\u003cbr/\u003eBackend Store\u003cbr/\u003emlflow.db\")]\n        S3[\"S3 Bucket\u003cbr/\u003eArtifacts Store\u003cbr/\u003emlartifacts/\"]\n        LOCAL[\"Local Storage\u003cbr/\u003e(Alternative)\u003cbr/\u003e/home/mlflow/data/\"]\n    end\n    \n    subgraph \"External Systems\"\n        SHARINGHUB[\"SharingHub Server\u003cbr/\u003ePermission API\u003cbr/\u003eSTAC Catalog\"]\n        GITLAB[\"GitLab\u003cbr/\u003eProject Metadata\"]\n    end\n    \n    subgraph \"Client Interactions\"\n        MLCLIENT[\"MLflow Client\u003cbr/\u003e(Python SDK)\"]\n        WEBUI[\"MLflow Web UI\u003cbr/\u003e/mlflow/\"]\n    end\n    \n    MLCLIENT --\u003e|\"mlflow.log_metric()\u003cbr/\u003emlflow.log_artifact()\"| TRACKING\n    WEBUI --\u003e|\"View Experiments\u003cbr/\u003eCompare Runs\"| TRACKING\n    \n    TRACKING --\u003e|\"Store Metadata\"| POSTGRES\n    TRACKING --\u003e|\"Store Artifacts\"| S3\n    TRACKING --\u003e|\"Check Permissions\"| PERMS\n    \n    REGISTRY --\u003e|\"Register Model\"| POSTGRES\n    REGISTRY --\u003e|\"Store Model Files\"| S3\n    REGISTRY --\u003e|\"Auto-link to STAC\"| SHARINGHUB\n    \n    PERMS --\u003e|\"Validate Access\"| SHARINGHUB\n    SHARINGHUB --\u003e|\"Query Project Access\"| GITLAB\n    \n    POSTGRES -.-\u003e|\"Alternative\"| LOCAL\n    S3 -.-\u003e|\"Alternative\"| LOCAL\n    \n    style TRACKING fill:#ffe1e1\n    style REGISTRY fill:#ffe1e1\n    style PERMS fill:#ffe1e1\n```\n\n**MLflow SharingHub Server Components:**\n\n- **Tracking Server:** Core Flask application that implements the MLflow Tracking API, handling experiment logging and artifact storage\n- **Model Registry:** MLflow component managing model versions, stages (Staging, Production, Archived), and metadata\n- **Permission Checker:** Custom integration layer that validates user access against SharingHub's permission API before allowing operations\n\nSources: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:1-111](), [docs/admin/configuration.md:281-358]()\n\n### Storage Backends\n\nMLflow SharingHub uses a dual-storage architecture separating metadata from artifacts:\n\n| Storage Type | Purpose | Default | Production Recommendation |\n|--------------|---------|---------|---------------------------|\n| **Backend Store** | Experiment metadata, run parameters, metrics, tags | SQLite at `/home/mlflow/data/mlflow.db` | PostgreSQL with dedicated instance |\n| **Artifacts Store** | Model files, datasets, plots, logs, arbitrary files | Local directory at `/home/mlflow/data/mlartifacts` | S3-compatible object storage |\n\n#### Backend Store Configuration\n\n**SQLite (Default):**\n```yaml\n# No configuration needed - uses local file\n# Location: /home/mlflow/data/mlflow.db\n```\n\n**PostgreSQL (Recommended):**\n\nCreate secret with database credentials:\n```bash\nkubectl create secret generic mlflow-sharinghub-postgres \\\n  --from-literal password=\"\u003cmlflow-user-password\u003e\" \\\n  --from-literal postgres-password=\"\u003croot-user-password\u003e\" \\\n  --namespace sharinghub\n```\n\nConfigure deployment values [docs/admin/deployment-guide/components/mlflow-sharinghub.md:87-90]():\n```yaml\npostgresql:\n  enabled: true\n  auth:\n    existingSecret: mlflow-sharinghub-postgres\n```\n\nFor external PostgreSQL instance [docs/admin/configuration.md:325-333]():\n```yaml\nmlflowSharinghub:\n  backendStoreUriSecret: true\n  # Secret must contain key: backend-store-uri\n  # Format: postgresql://\u003cuser\u003e:\u003cpassword\u003e@\u003chost\u003e:5432/\u003cdatabase\u003e\n```\n\n#### Artifacts Store Configuration\n\n**Local Storage (Default):**\n```yaml\n# No configuration needed - uses local directory\n# Location: /home/mlflow/data/mlartifacts\n```\n\n**S3 (Recommended):**\n\nCreate S3 credentials secret [docs/admin/deployment-guide/components/mlflow-sharinghub.md:22-25]():\n```bash\nkubectl create secret generic mlflow-sharinghub-s3 \\\n  --from-literal access-key-id=\"\u003caccess-key\u003e\" \\\n  --from-literal secret-access-key=\"\u003csecret-key\u003e\" \\\n  --namespace sharinghub\n```\n\nConfigure deployment values [docs/admin/deployment-guide/components/mlflow-sharinghub.md:52-60]():\n```yaml\nmlflowSharinghub:\n  artifactsDestination: s3://\u003cbucket\u003e\n\ns3:\n  enabled: true\n  endpointUrl: https://\u003cs3-endpoint\u003e\n```\n\nSources: [docs/admin/configuration.md:299-358](), [docs/admin/deployment-guide/components/mlflow-sharinghub.md:19-25]()\n\n### Integration Points\n\n```mermaid\ngraph LR\n    subgraph \"MLflow SharingHub\"\n        MLFLOW[\"MLflow Server\u003cbr/\u003esharinghub.domain/mlflow\"]\n        PERMCHECK[\"Permission Validator\"]\n    end\n    \n    subgraph \"SharingHub\"\n        PERMAPI[\"Permission Check API\u003cbr/\u003e/api/mlflow/check-permission\"]\n        STACAPI[\"STAC API\u003cbr/\u003e/stac/collections/ai-model\"]\n        STACITEM[\"STAC Item\u003cbr/\u003eml-model extension\"]\n    end\n    \n    subgraph \"GitLab\"\n        PROJECT[\"GitLab Project\u003cbr/\u003enamespace/project-name\"]\n        PROJECTMETA[\"Project Metadata\u003cbr/\u003eTopics, Tags, Visibility\"]\n    end\n    \n    MLFLOW --\u003e|\"1. Validate User Access\u003cbr/\u003ePOST with project_uri\"| PERMCHECK\n    PERMCHECK --\u003e|\"2. Check Permission\"| PERMAPI\n    PERMAPI --\u003e|\"3. Query Project\"| PROJECT\n    PROJECT --\u003e|\"4. Return Access Level\"| PERMAPI\n    PERMAPI --\u003e|\"5. Allow/Deny\"| PERMCHECK\n    PERMCHECK --\u003e|\"6. Grant/Reject Operation\"| MLFLOW\n    \n    MLFLOW -.-\u003e|\"Auto-link on Registration\"| STACITEM\n    STACITEM --\u003e|\"References\"| PROJECT\n    STACAPI --\u003e|\"Exposes\"| STACITEM\n    PROJECT --\u003e|\"Has Topic\"| PROJECTMETA\n```\n\n**Integration Flow:**\n\n1. **Permission Validation:** Before any MLflow operation (logging experiments, viewing runs, registering models), MLflow SharingHub sends a permission check request to SharingHub\n2. **Project Access Query:** SharingHub validates the user's access level to the corresponding GitLab project based on the `project_uri`\n3. **GitLab Authorization:** SharingHub queries GitLab to determine if the authenticated user has sufficient permissions for the requested operation\n4. **Operation Authorization:** Based on GitLab's response, the operation is either allowed or denied\n5. **STAC Auto-linking:** When a model is registered, MLflow SharingHub notifies SharingHub to create or update the corresponding STAC item with model metadata\n\nSources: [docs/admin/configuration.md:283-297](), [docs/admin/deployment-guide/components/mlflow-sharinghub.md:52-56]()\n\n## Experiment Tracking\n\n### Project-based Tracking URIs\n\nMLflow SharingHub implements project-specific tracking URIs that map directly to GitLab project paths. This ensures experiments are organized by project and access control is enforced at the project level.\n\n**Tracking URI Format:**\n```\nhttps://sharinghub.\u003cdomain\u003e/mlflow/\u003cnamespace\u003e/\u003cproject-name\u003e\n```\n\n**Example:**\n```python\nimport mlflow\n\n# Set tracking URI for specific project\nmlflow.set_tracking_uri(\"https://sharinghub.example.com/mlflow/ml-team/flood-detection\")\n\n# Create or set experiment\nmlflow.set_experiment(\"flood-model-training\")\n\n# Log training run\nwith mlflow.start_run():\n    mlflow.log_param(\"learning_rate\", 0.001)\n    mlflow.log_metric(\"accuracy\", 0.95)\n    mlflow.log_artifact(\"model.onnx\")\n```\n\nThe `\u003cnamespace\u003e/\u003cproject-name\u003e` segment must correspond to an existing GitLab project with the topic `sharinghub:aimodel` to be eligible for MLflow tracking.\n\n### Experiment Lifecycle\n\n```mermaid\ngraph TB\n    START[/\"ML Developer\u003cbr/\u003eStarts Training\"/]\n    \n    SETEXP[\"Set Experiment\u003cbr/\u003emlflow.set_experiment()\"]\n    STARTRUN[\"Start Run\u003cbr/\u003emlflow.start_run()\"]\n    \n    subgraph \"During Training Run\"\n        LOGPARAM[\"Log Parameters\u003cbr/\u003emlflow.log_param()\"]\n        LOGMETRIC[\"Log Metrics\u003cbr/\u003emlflow.log_metric()\"]\n        LOGART[\"Log Artifacts\u003cbr/\u003emlflow.log_artifact()\"]\n        LOGMODEL[\"Log Model\u003cbr/\u003emlflow.sklearn.log_model()\"]\n    end\n    \n    ENDRUN[\"End Run\u003cbr/\u003eContext Exit\"]\n    \n    subgraph \"Storage Operations\"\n        SAVEMETA[(\"Save to PostgreSQL\u003cbr/\u003erun_id, params, metrics\")]\n        SAVEART[\"Upload to S3\u003cbr/\u003eartifacts, model files\"]\n    end\n    \n    VIEW[\"View in MLflow UI\u003cbr/\u003e/mlflow/#/experiments\"]\n    \n    START --\u003e SETEXP\n    SETEXP --\u003e STARTRUN\n    STARTRUN --\u003e LOGPARAM\n    LOGPARAM --\u003e LOGMETRIC\n    LOGMETRIC --\u003e LOGART\n    LOGART --\u003e LOGMODEL\n    LOGMODEL --\u003e ENDRUN\n    \n    LOGPARAM -.-\u003e SAVEMETA\n    LOGMETRIC -.-\u003e SAVEMETA\n    LOGART -.-\u003e SAVEART\n    LOGMODEL -.-\u003e SAVEART\n    \n    ENDRUN --\u003e VIEW\n```\n\n**Key Functions:**\n\n- `mlflow.set_experiment(name)`: Creates or retrieves an experiment within the project\n- `mlflow.start_run()`: Begins a new training run with unique `run_id`\n- `mlflow.log_param(key, value)`: Records hyperparameters (immutable)\n- `mlflow.log_metric(key, value, step)`: Records performance metrics (can be updated)\n- `mlflow.log_artifact(path)`: Uploads files (plots, datasets, etc.)\n- `mlflow.\u003cframework\u003e.log_model()`: Logs model with framework-specific metadata\n\nSources: [docs/admin/configuration.md:295-297]()\n\n## Model Registry\n\n### Registration and Versioning\n\nThe MLflow Model Registry provides centralized model versioning and lifecycle management:\n\n```mermaid\ngraph TB\n    TRAIN[\"Training Complete\u003cbr/\u003eModel Logged\"]\n    \n    REGISTER[\"Register Model\u003cbr/\u003emlflow.register_model()\"]\n    CREATEVER[\"Create Model Version\u003cbr/\u003eversion=1, 2, 3...\"]\n    \n    subgraph \"Model Stages\"\n        NONE[\"None\u003cbr/\u003e(Default)\"]\n        STAGING[\"Staging\u003cbr/\u003e(Testing)\"]\n        PRODUCTION[\"Production\u003cbr/\u003e(Deployed)\"]\n        ARCHIVED[\"Archived\u003cbr/\u003e(Deprecated)\"]\n    end\n    \n    subgraph \"Storage and Linking\"\n        REGSAVE[(\"Save to PostgreSQL\u003cbr/\u003emodel_name, version,\u003cbr/\u003estage, metadata\")]\n        STACLINK[\"Create STAC Item\u003cbr/\u003eml-model extension\u003cbr/\u003eAuto-linked\"]\n        STACCAT[\"Appears in\u003cbr/\u003eSharingHub Catalog\u003cbr/\u003eai-model collection\"]\n    end\n    \n    TRAIN --\u003e REGISTER\n    REGISTER --\u003e CREATEVER\n    CREATEVER --\u003e NONE\n    \n    NONE --\u003e|\"Promote\"| STAGING\n    STAGING --\u003e|\"Promote\"| PRODUCTION\n    PRODUCTION --\u003e|\"Demote\"| ARCHIVED\n    STAGING --\u003e|\"Reject\"| ARCHIVED\n    \n    CREATEVER --\u003e REGSAVE\n    REGSAVE --\u003e STACLINK\n    STACLINK --\u003e STACCAT\n```\n\n**Registration Example:**\n```python\n# Option 1: Register from run\nmlflow.register_model(\n    model_uri=\"runs:/\u003crun_id\u003e/model\",\n    name=\"flood-detection-model\"\n)\n\n# Option 2: Register from artifact path\nmlflow.register_model(\n    model_uri=\"s3://bucket/path/to/model\",\n    name=\"flood-detection-model\"\n)\n```\n\n**Model Versioning:**\n\nEach registration creates a new version (1, 2, 3...) under the model name. Versions are immutable but can transition through lifecycle stages.\n\n### STAC Integration and Discovery\n\nWhen a model is registered in MLflow SharingHub, it automatically creates or updates a STAC item in the SharingHub catalog:\n\n```mermaid\ngraph LR\n    subgraph \"MLflow Registry\"\n        MODEL[\"Model: flood-detection\u003cbr/\u003eVersion: 3\u003cbr/\u003eStage: Production\"]\n        METADATA[\"Model Metadata\u003cbr/\u003eframework, input_schema,\u003cbr/\u003eoutput_schema\"]\n    end\n    \n    subgraph \"STAC Catalog\"\n        COLLECTION[\"Collection: ai-model\u003cbr/\u003egitlab_topic:\u003cbr/\u003esharinghub:aimodel\"]\n        STACITEM[\"STAC Item\u003cbr/\u003eflood-detection\"]\n        MLEXT[\"ml-model Extension\u003cbr/\u003earchitecture, tasks,\u003cbr/\u003eframework, runtime\"]\n        ASSETS[\"Assets\u003cbr/\u003emodel.onnx\u003cbr/\u003erequirements.txt\u003cbr/\u003eREADME.md\"]\n    end\n    \n    subgraph \"GitLab Project\"\n        GITPROJECT[\"Project:\u003cbr/\u003eml-team/flood-detection\u003cbr/\u003eTopic: sharinghub:aimodel\"]\n    end\n    \n    MODEL --\u003e|\"Auto-link on Registration\"| STACITEM\n    METADATA --\u003e|\"Populate Extension\"| MLEXT\n    MODEL --\u003e|\"Reference Artifacts\"| ASSETS\n    \n    STACITEM --\u003e|\"Part of\"| COLLECTION\n    STACITEM --\u003e|\"Uses Extension\"| MLEXT\n    STACITEM --\u003e|\"Contains\"| ASSETS\n    STACITEM --\u003e|\"Linked to\"| GITPROJECT\n    \n    COLLECTION --\u003e|\"Filters by Topic\"| GITPROJECT\n```\n\n**STAC Item Structure for Registered Models:**\n\nThe STAC item includes the `ml-model` extension with metadata extracted from the MLflow model:\n\n- **Model artifacts:** ONNX files, serialized models, prediction scripts\n- **Framework metadata:** sklearn, pytorch, tensorflow version information  \n- **Input/output schemas:** Expected data types and shapes\n- **Model architecture:** Network structure for deep learning models\n- **Task type:** Classification, regression, segmentation, etc.\n\nThis auto-linking enables models registered in MLflow to be immediately discoverable through the SharingHub STAC API and web interface.\n\nSources: [docs/admin/configuration.md:295-297]()\n\n## Permission Model\n\n### SharingHub Permission Integration\n\nMLflow SharingHub delegates all permission checks to SharingHub, which in turn validates against GitLab project permissions. This creates a unified authorization model across the platform:\n\n```mermaid\ngraph TB\n    USER[\"Authenticated User\u003cbr/\u003eAccess Token\"]\n    \n    subgraph \"MLflow Operations\"\n        VIEWEXP[\"View Experiments\"]\n        LOGART[\"Log Artifacts\"]\n        REGMODEL[\"Register Model\"]\n        DELRUN[\"Delete Runs\"]\n    end\n    \n    subgraph \"MLflow SharingHub\"\n        INTERCEPTOR[\"Request Interceptor\"]\n        PROJURI[\"Extract project_uri\u003cbr/\u003enamespace/project\"]\n    end\n    \n    subgraph \"SharingHub Permission API\"\n        CHECKAPI[\"POST /api/mlflow/\u003cbr/\u003echeck-permission\"]\n        VALIDATETOKEN[\"Validate OAuth Token\"]\n        QUERYGITLAB[\"Query GitLab API\u003cbr/\u003eGET /projects/:id/\u003cbr/\u003emembers/:user_id\"]\n    end\n    \n    subgraph \"GitLab\"\n        PROJECTACL[\"Project Access Levels\u003cbr/\u003eGuest: 10\u003cbr/\u003eReporter: 20\u003cbr/\u003eDeveloper: 30\u003cbr/\u003eMaintainer: 40\u003cbr/\u003eOwner: 50\"]\n    end\n    \n    DECISION{\"Access\u003cbr/\u003eGranted?\"}\n    ALLOW[\"Allow Operation\"]\n    DENY[\"Return 403 Forbidden\"]\n    \n    USER --\u003e VIEWEXP\n    USER --\u003e LOGART\n    USER --\u003e REGMODEL\n    USER --\u003e DELRUN\n    \n    VIEWEXP --\u003e INTERCEPTOR\n    LOGART --\u003e INTERCEPTOR\n    REGMODEL --\u003e INTERCEPTOR\n    DELRUN --\u003e INTERCEPTOR\n    \n    INTERCEPTOR --\u003e PROJURI\n    PROJURI --\u003e CHECKAPI\n    CHECKAPI --\u003e VALIDATETOKEN\n    VALIDATETOKEN --\u003e QUERYGITLAB\n    QUERYGITLAB --\u003e PROJECTACL\n    PROJECTACL --\u003e DECISION\n    \n    DECISION --\u003e|\"Yes\"| ALLOW\n    DECISION --\u003e|\"No\"| DENY\n```\n\n**Permission Levels:**\n\n| GitLab Access Level | View Experiments | Log Runs | Register Models | Delete Runs |\n|---------------------|------------------|----------|-----------------|-------------|\n| **Guest (10)** |  |  |  |  |\n| **Reporter (20)** |  |  |  |  |\n| **Developer (30)** |  |  |  |  |\n| **Maintainer (40)** |  |  |  |  |\n| **Owner (50)** |  |  |  |  |\n\n### Configuration\n\nThe SharingHub integration is configured via deployment values [docs/admin/deployment-guide/components/mlflow-sharinghub.md:52-56]():\n\n```yaml\nmlflowSharinghub:\n  sharinghubUrl: https://sharinghub.\u003cdomain-name\u003e\n  sharinghubStacCollection: \"ai-model\"\n  sharinghubAuthDefaultToken: false\n```\n\n**Configuration Parameters:**\n\n- `sharinghubUrl`: Base URL of the SharingHub instance for permission API calls\n- `sharinghubStacCollection`: STAC collection ID where models must be registered (restricts MLflow usage to projects in this collection)\n- `sharinghubAuthDefaultToken`: Set to `false` if SharingHub has a default token configured, enabling read-only access to public projects without authentication\n\nSources: [docs/admin/configuration.md:283-297]()\n\n## Deployment Architecture\n\nMLflow SharingHub is deployed in the `sharinghub` namespace alongside SharingHub itself, sharing infrastructure and networking:\n\n```mermaid\ngraph TB\n    subgraph \"Kubernetes: sharinghub namespace\"\n        POD[\"mlflow-sharinghub Pod\u003cbr/\u003eContainer Image:\u003cbr/\u003eeoepca/mlflow-sharinghub:latest\"]\n        \n        subgraph \"Mounted Secrets\"\n            SECRET[\"mlflow-sharinghub\u003cbr/\u003esecret-key\"]\n            S3SECRET[\"mlflow-sharinghub-s3\u003cbr/\u003eaccess-key-id\u003cbr/\u003esecret-access-key\"]\n            PGSECRET[\"mlflow-sharinghub-postgres\u003cbr/\u003epassword\u003cbr/\u003epostgres-password\"]\n        end\n        \n        PGDB[(\"PostgreSQL\u003cbr/\u003emlflow database\u003cbr/\u003eHelm subchart\")]\n        \n        SHPOD[\"sharinghub Pod\u003cbr/\u003ePermission API\"]\n    end\n    \n    subgraph \"Ingress Layer\"\n        NGINX[\"NGINX Ingress Controller\"]\n        CERT[\"TLS Certificate\u003cbr/\u003esharinghub.domain-tls\"]\n    end\n    \n    subgraph \"External Services\"\n        S3EXT[\"S3 Bucket\u003cbr/\u003eArtifacts Storage\"]\n        GITLAB[\"GitLab\u003cbr/\u003eProject Metadata\"]\n    end\n    \n    CLIENT[\"MLflow Client\u003cbr/\u003ePython SDK\"]\n    BROWSER[\"Web Browser\u003cbr/\u003eMLflow UI\"]\n    \n    CLIENT --\u003e|\"HTTPS\"| NGINX\n    BROWSER --\u003e|\"HTTPS\"| NGINX\n    \n    NGINX --\u003e|\"TLS Termination\"| CERT\n    NGINX --\u003e|\"Path: /mlflow/\"| POD\n    \n    POD --\u003e|\"Mount\"| SECRET\n    POD --\u003e|\"Mount\"| S3SECRET\n    POD --\u003e|\"Mount\"| PGSECRET\n    \n    POD --\u003e|\"Store Metadata\"| PGDB\n    POD --\u003e|\"Store Artifacts\"| S3EXT\n    POD --\u003e|\"Check Permissions\"| SHPOD\n    \n    SHPOD --\u003e|\"Validate Access\"| GITLAB\n```\n\n**Deployment Configuration:**\n\nThe ArgoCD Application manifest deploys MLflow SharingHub from the Helm chart repository [docs/admin/deployment-guide/components/mlflow-sharinghub.md:29-96]():\n\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: mlflow-sharinghub\n  namespace: argocd\nspec:\n  destination:\n    namespace: sharinghub\n    server: https://kubernetes.default.svc\n  source:\n    repoURL: https://github.com/csgroup-oss/mlflow-sharinghub.git\n    path: deploy/helm/mlflow-sharinghub\n    targetRevision: \"0.2.0\"\n```\n\n**Key Deployment Values:**\n\n- **Image:** `eoepca/mlflow-sharinghub:latest` [docs/admin/deployment-guide/components/mlflow-sharinghub.md:48-50]()\n- **Ingress Path:** `/mlflow/` with URL rewrite to `/` [docs/admin/deployment-guide/components/mlflow-sharinghub.md:75-82]()\n- **Pod Security:** `fsGroup: 999` for PostgreSQL volume permissions [docs/admin/deployment-guide/components/mlflow-sharinghub.md:65-66]()\n- **Body Size:** 10GB limit for large artifact uploads [docs/admin/deployment-guide/components/mlflow-sharinghub.md:74]()\n\nSources: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:1-111]()\n\n## API and Interfaces\n\n### MLflow Tracking API\n\nMLflow SharingHub exposes the standard MLflow Tracking API at `https://sharinghub.\u003cdomain\u003e/mlflow/`:\n\n**Key Endpoints:**\n\n| Endpoint | Method | Purpose |\n|----------|--------|---------|\n| `/api/2.0/mlflow/experiments/create` | POST | Create new experiment |\n| `/api/2.0/mlflow/runs/create` | POST | Start new training run |\n| `/api/2.0/mlflow/runs/log-parameter` | POST | Log hyperparameter |\n| `/api/2.0/mlflow/runs/log-metric` | POST | Log performance metric |\n| `/api/2.0/mlflow/runs/log-artifact` | POST | Upload artifact file |\n| `/api/2.0/mlflow/model-versions/create` | POST | Register new model version |\n| `/api/2.0/mlflow/model-versions/update` | PATCH | Update model stage |\n\nAll endpoints require authentication via OAuth token and permission validation via SharingHub.\n\n### Web Interface\n\nThe MLflow UI is accessible at `https://sharinghub.\u003cdomain\u003e/mlflow/` and provides:\n\n- **Experiments View:** Browse and compare training runs, visualize metrics\n- **Run Details:** Inspect parameters, metrics, artifacts, and model outputs\n- **Model Registry:** View registered models, versions, and lifecycle stages\n- **Comparison Tools:** Compare multiple runs side-by-side with metric charts\n- **Artifact Browser:** Download logged files, models, and datasets\n\nThe UI respects the same permission model as the API, showing only experiments and models the authenticated user has access to.\n\n### Python Client Usage\n\n```python\nimport mlflow\n\n# Configure tracking URI\nmlflow.set_tracking_uri(\"https://sharinghub.example.com/mlflow/ml-team/my-project\")\n\n# Set experiment\nmlflow.set_experiment(\"model-training\")\n\n# Start run and log\nwith mlflow.start_run() as run:\n    # Log parameters\n    mlflow.log_param(\"epochs\", 10)\n    mlflow.log_param(\"batch_size\", 32)\n    \n    # Log metrics\n    for epoch in range(10):\n        mlflow.log_metric(\"loss\", loss_value, step=epoch)\n        mlflow.log_metric(\"accuracy\", acc_value, step=epoch)\n    \n    # Log model\n    mlflow.sklearn.log_model(model, \"model\")\n    \n    # Register model\n    mlflow.register_model(\n        model_uri=f\"runs:/{run.info.run_id}/model\",\n        name=\"my-model\"\n    )\n```\n\nSources: [docs/admin/configuration.md:286-297]()\n\n---\n\n**Related Pages:**\n\n- For SharingHub configuration and STAC catalog generation, see [SharingHub](#3.2)\n- For GitLab project setup and topics configuration, see [GitLab](#3.1)\n- For deployment instructions, see [MLflow SharingHub Deployment](#5.4)\n- For complete configuration reference, see [MLflow SharingHub Configuration](#6.2)\n- For model training workflow examples, see [Model Training Workflow](#4.1)"])</script><script>self.__next_f.push([1,"1f:T3fd7,"])</script><script>self.__next_f.push([1,"# Workflows and Scenarios\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/design/diagrams/use-cases.drawio.png](docs/design/diagrams/use-cases.drawio.png)\n- [docs/design/scenarios/flood-example.md](docs/design/scenarios/flood-example.md)\n- [docs/design/scenarios/model-training.md](docs/design/scenarios/model-training.md)\n- [docs/design/use-cases.md](docs/design/use-cases.md)\n- [mkdocs.yml](mkdocs.yml)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis section provides an overview of the practical workflows and scenarios supported by the EOEPCA MLOps Building Block. It describes how the three core componentsGitLab, SharingHub, and MLflow SharingHubwork together to support end-to-end machine learning operations, from dataset preparation through model training to model deployment and sharing.\n\nThe workflows are organized by activity type:\n- **Model Training Workflow**: Complete lifecycle from project creation to model registration (detailed in [Model Training Workflow](#4.1))\n- **Dataset Management**: Versioning and sharing datasets using DVC and GitLab (detailed in [Dataset Management](#4.2))\n- **End-to-End Examples**: Practical implementations like flood detection (detailed in [Flood Detection Example](#4.3))\n\nFor architectural details about the individual components, see [Core Components](#3). For API-level interactions, see [API Reference](#7).\n\nSources: [docs/design/scenarios/model-training.md:1-53](), [docs/design/use-cases.md:1-96](), [mkdocs.yml:14-16]()\n\n## User Personas\n\nThe MLOps Building Block supports three primary user personas, each with distinct workflows and interaction patterns:\n\n| Persona | Primary Activities | Main Components Used | Key Objectives |\n|---------|-------------------|---------------------|----------------|\n| **ML Developer** | Model development, training, experimentation | GitLab, MLflow client, SharingHub STAC API | Train and register production-ready models |\n| **Data Scientist** | Dataset creation, versioning, curation | GitLab, DVC, SharingHub | Publish and share versioned datasets |\n| **ML User/Operator** | Model discovery, deployment, inference | SharingHub Web UI, STAC API, CWL | Find and use models for operational tasks |\n\nEach persona interacts with the platform differently, but their workflows are interconnected through shared artifacts and metadata.\n\nSources: [docs/design/scenarios/model-training.md:7-8](), [docs/design/use-cases.md:16-96]()\n\n## Workflow Overview\n\nThe following diagram illustrates the high-level interactions across all three workflow types, showing how artifacts flow through the system from creation to consumption.\n\n```mermaid\ngraph TB\n    subgraph \"Dataset Management Workflow\"\n        DS[\"Data Scientist\"]\n        DS --\u003e GL1[\"GitLab Project\"]\n        GL1 --\u003e TOPIC1[\"Add topic:\u003cbr/\u003esharinghub:dataset\"]\n        TOPIC1 --\u003e DVC1[\"DVC version control\"]\n        DVC1 --\u003e S3DS[\"S3 Storage\"]\n        GL1 --\u003e SH1[\"SharingHub STAC Catalog\"]\n    end\n    \n    subgraph \"Model Training Workflow\"\n        MLD[\"ML Developer\"]\n        MLD --\u003e SH2[\"Browse datasets in\u003cbr/\u003eSharingHub\"]\n        SH2 --\u003e STAC[\"STAC API\u003cbr/\u003e/collections/datasets\"]\n        MLD --\u003e GL2[\"Clone GitLab Project\"]\n        GL2 --\u003e TOPIC2[\"Add topic:\u003cbr/\u003esharinghub:aimodel\"]\n        MLD --\u003e MLF1[\"MLflow Client\u003cbr/\u003emlflow.start_run()\"]\n        MLF1 --\u003e MLF2[\"MLflow Server\u003cbr/\u003eTracking URI\"]\n        MLF2 --\u003e PG[\"PostgreSQL\u003cbr/\u003eMetrics Storage\"]\n        MLF2 --\u003e S3ML[\"S3 Storage\u003cbr/\u003eArtifacts\"]\n        MLD --\u003e REG[\"Register Model\u003cbr/\u003eMLflow Registry\"]\n        REG --\u003e LINK[\"Auto-link to\u003cbr/\u003eSTAC Item\"]\n        LINK --\u003e SH3[\"SharingHub Catalog\"]\n    end\n    \n    subgraph \"Model Consumption Workflow\"\n        MLU[\"ML User/Operator\"]\n        MLU --\u003e SH4[\"Browse models in\u003cbr/\u003eSharingHub Web UI\"]\n        SH4 --\u003e FILTER[\"Filter by tags\u003cbr/\u003eand metadata\"]\n        FILTER --\u003e STAC2[\"STAC API\u003cbr/\u003e/collections/aimodels\"]\n        STAC2 --\u003e DL[\"Download ONNX\u003cbr/\u003efrom MLflow\"]\n        DL --\u003e CWL[\"Execute CWL\u003cbr/\u003eWorkflow\"]\n    end\n    \n    S3DS -.dataset artifacts.-\u003e STAC\n    STAC -.dataset discovery.-\u003e MLF1\n    SH3 -.model discovery.-\u003e SH4\n```\n\nThis diagram shows the complete data flow from dataset creation through model training to operational deployment. Each workflow produces artifacts that feed into subsequent workflows, creating a continuous MLOps pipeline.\n\nSources: [docs/design/scenarios/model-training.md:1-53](), [docs/design/use-cases.md:1-96]()\n\n## Model Training Workflow Overview\n\nThe model training workflow encompasses the complete lifecycle of developing and registering an AI model. This workflow is detailed in [Model Training Workflow](#4.1), but the key stages are:\n\n```mermaid\nsequenceDiagram\n    participant MLD as ML Developer\n    participant GL as GitLab\n    participant SH as SharingHub\n    participant MLF as MLflow Server\n    participant REG as MLflow Registry\n    \n    MLD-\u003e\u003eGL: Create new project\n    MLD-\u003e\u003eGL: Add topic: \"sharinghub:aimodel\"\n    MLD-\u003e\u003eGL: Commit code and README.md\n    GL-\u003e\u003eSH: Project appears in catalog\n    \n    MLD-\u003e\u003eSH: Browse datasets via STAC API\n    MLD-\u003e\u003eSH: Download dataset\n    \n    MLD-\u003e\u003eMLF: mlflow.set_tracking_uri()\n    MLD-\u003e\u003eMLF: mlflow.start_run()\n    loop Training Iterations\n        MLD-\u003e\u003eMLF: mlflow.log_metric()\n        MLD-\u003e\u003eMLF: mlflow.log_param()\n    end\n    MLD-\u003e\u003eMLF: mlflow.log_model()\n    \n    MLD-\u003e\u003eREG: Register model version\n    REG-\u003e\u003eSH: Auto-create STAC Item link\n    SH-\u003e\u003eMLD: Model discoverable in catalog\n```\n\n**Key Steps:**\n\n1. **Project Creation**: Create a GitLab project and tag it with the `sharinghub:aimodel` topic\n2. **Metadata Configuration**: Add STAC-compliant metadata to `README.md` including model description, input/output schemas\n3. **Dataset Discovery**: Use SharingHub's STAC API to find and retrieve training datasets\n4. **Training Setup**: Configure MLflow client with tracking URI from SharingHub\n5. **Experiment Tracking**: Log metrics, parameters, and artifacts using `mlflow.log_*()` functions\n6. **Model Evaluation**: Review performance metrics in MLflow UI\n7. **Model Registration**: Register the final model in MLflow Registry, which automatically creates STAC metadata links\n\nFor detailed step-by-step instructions, see [Model Training Workflow](#4.1).\n\nSources: [docs/design/scenarios/model-training.md:11-53](), [docs/design/use-cases.md:17-69]()\n\n## Dataset Management Workflow Overview\n\nThe dataset management workflow focuses on versioning, storing, and sharing large datasets efficiently. This workflow is detailed in [Dataset Management](#4.2), but the core pattern involves:\n\n```mermaid\ngraph LR\n    subgraph \"Dataset Creation\"\n        CREATE[\"Create GitLab Project\"]\n        TOPIC[\"Add topic:\u003cbr/\u003esharinghub:dataset\"]\n        README[\"Document in README.md\"]\n        CREATE --\u003e TOPIC\n        TOPIC --\u003e README\n    end\n    \n    subgraph \"Version Control with DVC\"\n        INIT[\"dvc init\"]\n        ADD[\"dvc add data/\"]\n        REMOTE[\"dvc remote add -d\u003cbr/\u003es3://bucket\"]\n        PUSH[\"dvc push\"]\n        INIT --\u003e ADD\n        ADD --\u003e REMOTE\n        REMOTE --\u003e PUSH\n    end\n    \n    subgraph \"Git Tracking\"\n        COMMIT[\"git add .dvc files\"]\n        GITPUSH[\"git push\"]\n        COMMIT --\u003e GITPUSH\n    end\n    \n    subgraph \"Discovery\"\n        CATALOG[\"SharingHub extracts metadata\"]\n        STACITEM[\"STAC Item created\"]\n        API[\"Available via STAC API\u003cbr/\u003e/collections/datasets\"]\n        CATALOG --\u003e STACITEM\n        STACITEM --\u003e API\n    end\n    \n    README --\u003e INIT\n    PUSH --\u003e COMMIT\n    GITPUSH --\u003e CATALOG\n```\n\n**Key Concepts:**\n\n| Component | Purpose | Commands/Files |\n|-----------|---------|----------------|\n| **DVC** | Data version control | `dvc init`, `dvc add`, `dvc push`, `dvc pull` |\n| **GitLab** | Metadata and pointer file storage | `.dvc` files, `dvc.yaml`, `dvc.lock` |\n| **S3** | Large data file storage | Configured via `dvc remote` |\n| **SharingHub** | Dataset discovery | Automatically indexes `sharinghub:dataset` projects |\n\nThe workflow ensures that large datasets (several GB) are stored efficiently in S3 while maintaining version history and metadata in GitLab. DVC tracks dataset versions through `.dvc` pointer files committed to Git, enabling reproducible model training.\n\nFor implementation details, see [Dataset Management](#4.2).\n\nSources: [docs/design/use-cases.md:70-96](), [docs/design/scenarios/flood-example.md:34-39]()\n\n## End-to-End Example: Flood Detection\n\nThe flood detection example demonstrates all workflows in a complete, real-world scenario. This example is fully detailed in [Flood Detection Example](#4.3), but here's the high-level flow:\n\n```mermaid\ngraph TB\n    subgraph \"Phase 1: Dataset Setup\"\n        CLONE_DS[\"Clone sen1floods11-dataset\u003cbr/\u003efrom GitLab\"]\n        DVC_CRED[\"Configure DVC\u003cbr/\u003eS3 credentials\"]\n        DVC_PULL[\"dvc pull\u003cbr/\u003eDownload ~4GB dataset\"]\n        CLONE_DS --\u003e DVC_CRED\n        DVC_CRED --\u003e DVC_PULL\n    end\n    \n    subgraph \"Phase 2: Model Training\"\n        CLONE_MODEL[\"Clone flood-model\u003cbr/\u003efrom GitLab\"]\n        ENV_SETUP[\"Setup .env file\u003cbr/\u003eMLflow credentials\"]\n        POETRY[\"poetry install\u003cbr/\u003eDependencies\"]\n        TRAIN[\"Run training session\u003cbr/\u003epython train.py\"]\n        METRICS[\"View metrics\u003cbr/\u003eMLflow UI\"]\n        CLONE_MODEL --\u003e ENV_SETUP\n        ENV_SETUP --\u003e POETRY\n        POETRY --\u003e TRAIN\n        TRAIN --\u003e METRICS\n    end\n    \n    subgraph \"Phase 3: Model Registration\"\n        REGISTER[\"Register model\u003cbr/\u003ein MLflow Registry\"]\n        VERSION[\"Model version 1.0.0\u003cbr/\u003eONNX format\"]\n        STAC_LINK[\"Auto-linked to\u003cbr/\u003eSTAC Item\"]\n        REGISTER --\u003e VERSION\n        VERSION --\u003e STAC_LINK\n    end\n    \n    subgraph \"Phase 4: Inference\"\n        DOWNLOAD[\"Download ONNX\u003cbr/\u003efrom SharingHub\"]\n        CWL_RUN[\"Execute CWL workflow\u003cbr/\u003ecwltool inference.cwl\"]\n        INPUT[\"Input: Pakistan_43105_S1Hand.tif\"]\n        OUTPUT[\"Output: predictions/prediction.tif\"]\n        DOWNLOAD --\u003e CWL_RUN\n        CWL_RUN --\u003e INPUT\n        INPUT --\u003e OUTPUT\n    end\n    \n    DVC_PULL --\u003e TRAIN\n    METRICS --\u003e REGISTER\n    STAC_LINK --\u003e DOWNLOAD\n```\n\n**Example Repositories:**\n\nThe flood detection example uses two GitLab projects:\n\n- **flood-model**: `https://gitlab.develop.eoepca.org/sharinghub-test/flood-model` (mirrored at `https://github.com/EOEPCA/flood-model`)\n- **sen1floods11-dataset**: `https://gitlab.develop.eoepca.org/sharinghub-test/sen1floods11-dataset` (mirrored at `https://github.com/EOEPCA/Sen1Floods11-Dataset`)\n\nBoth projects are tagged with appropriate SharingHub topics (`sharinghub:aimodel` and `sharinghub:dataset`) and appear automatically in the SharingHub catalog at `https://sharinghub.develop.eoepca.org`.\n\nFor complete step-by-step instructions, see [Flood Detection Example](#4.3).\n\nSources: [docs/design/scenarios/flood-example.md:1-72]()\n\n## Component Integration Patterns\n\nThe workflows rely on specific integration patterns between components. Understanding these patterns is essential for using the platform effectively.\n\n### GitLab Topic-Based Discovery\n\nSharingHub automatically discovers GitLab projects based on topic tags:\n\n| GitLab Topic | STAC Collection | Purpose |\n|--------------|----------------|---------|\n| `sharinghub:aimodel` | `/collections/aimodels` | ML models and training code |\n| `sharinghub:dataset` | `/collections/datasets` | Training and validation datasets |\n| `sharinghub:processor` | `/collections/processors` | Processing workflows and scripts |\n\nWhen a project is tagged with one of these topics, it appears in the corresponding STAC collection within minutes.\n\n### MLflow-SharingHub Linking\n\nThe MLflow SharingHub component maintains bidirectional links between MLflow models and SharingHub STAC items:\n\n```mermaid\ngraph LR\n    subgraph \"MLflow Registry\"\n        MODEL[\"Registered Model\u003cbr/\u003eflood-detection\"]\n        VERSION[\"Model Version 1.0.0\u003cbr/\u003eONNX artifact\"]\n        MODEL --\u003e VERSION\n    end\n    \n    subgraph \"SharingHub STAC Catalog\"\n        ITEM[\"STAC Item\u003cbr/\u003eflood-model\"]\n        ASSET[\"STAC Asset\u003cbr/\u003emodel.onnx\"]\n        ITEM --\u003e ASSET\n    end\n    \n    subgraph \"GitLab Project\"\n        PROJECT[\"flood-model project\u003cbr/\u003etopic: sharinghub:aimodel\"]\n        README[\"README.md\u003cbr/\u003eSTAC metadata\"]\n        PROJECT --\u003e README\n    end\n    \n    VERSION -.mlflow_model_uri.-\u003e ASSET\n    ASSET -.stac_item_id.-\u003e ITEM\n    ITEM -.gitlab_project_id.-\u003e PROJECT\n    README -.extracted metadata.-\u003e ITEM\n```\n\nThis linking happens automatically when a model is registered in MLflow Registry. The MLflow SharingHub plugin checks if the associated GitLab project exists in SharingHub and creates the appropriate STAC asset links.\n\n### DVC Remote Storage Configuration\n\nDVC manages large datasets by storing them in S3 while tracking metadata in Git:\n\n```mermaid\ngraph TB\n    subgraph \"Local Development Environment\"\n        DVC_INIT[\"dvc init\"]\n        DATA[\"data/\u003cbr/\u003elarge files\"]\n        DVC_ADD[\"dvc add data/\"]\n        DVC_FILE[\"data.dvc\u003cbr/\u003epointer file\"]\n        DVC_INIT --\u003e DVC_ADD\n        DATA --\u003e DVC_ADD\n        DVC_ADD --\u003e DVC_FILE\n    end\n    \n    subgraph \"Git Repository (GitLab)\"\n        COMMIT[\"git commit data.dvc\"]\n        PUSH[\"git push\"]\n        DVC_FILE --\u003e COMMIT\n        COMMIT --\u003e PUSH\n    end\n    \n    subgraph \"S3 Object Storage\"\n        S3_BUCKET[\"s3://bucket/datasets/\"]\n        DVC_PUSH[\"dvc push\"]\n        DVC_FILE -.references.-\u003e DVC_PUSH\n        DVC_PUSH --\u003e S3_BUCKET\n    end\n    \n    subgraph \"Remote Development Environment\"\n        CLONE[\"git clone\"]\n        DVC_PULL[\"dvc pull\"]\n        DATA_RESTORE[\"data/\u003cbr/\u003erestored\"]\n        PUSH --\u003e CLONE\n        CLONE --\u003e DVC_PULL\n        S3_BUCKET --\u003e DVC_PULL\n        DVC_PULL --\u003e DATA_RESTORE\n    end\n```\n\nThe `.dvc` files contain hashes and metadata that reference the actual data in S3, enabling efficient collaboration without storing large files in Git.\n\nSources: [docs/design/scenarios/model-training.md:17-53](), [docs/design/scenarios/flood-example.md:34-39]()\n\n## Workflow Prerequisites\n\nBefore executing any of the workflows, users must have:\n\n1. **Access Credentials**:\n   - GitLab account with project creation permissions\n   - MLflow tracking URI and credentials (obtained from SharingHub admin)\n   - S3 bucket credentials for DVC (for dataset management)\n\n2. **Development Environment**:\n   - Python 3.8+ with `mlflow` client library installed\n   - DVC installed (`pip install dvc[s3]`) for dataset workflows\n   - Git configured for GitLab authentication\n\n3. **Project Configuration**:\n   - `.env` file with MLflow tracking URI and credentials\n   - `dvc.yaml` configuration for dataset projects\n   - README.md with STAC-compliant metadata fields\n\n4. **Network Access**:\n   - Connectivity to GitLab instance (e.g., `https://gitlab.develop.eoepca.org`)\n   - Access to SharingHub STAC API (e.g., `https://sharinghub.develop.eoepca.org`)\n   - S3 endpoint accessibility for artifact storage\n\nFor deployment-specific prerequisites, see [Deployment Guide](#5).\n\nSources: [docs/design/scenarios/model-training.md:23-39](), [docs/design/scenarios/flood-example.md:31-39]()\n\n## Workflow Outputs and Artifacts\n\nEach workflow produces specific artifacts that are consumed by other workflows or external systems:\n\n| Workflow | Primary Outputs | Storage Location | Access Method |\n|----------|----------------|------------------|---------------|\n| **Dataset Management** | Versioned datasets, `.dvc` files | S3 (data), GitLab (metadata) | `dvc pull`, STAC API |\n| **Model Training** | Trained models, metrics, parameters | S3 (artifacts), PostgreSQL (metadata) | MLflow API, STAC API |\n| **Model Consumption** | Inference results, predictions | Local or application-specific | Direct file access |\n\n### STAC Metadata Structure\n\nAll outputs are described using STAC metadata, which includes:\n\n- **Item ID**: Unique identifier (typically GitLab project ID)\n- **Properties**: Model/dataset metadata, dates, versions\n- **Assets**: Downloadable files (ONNX models, datasets, documentation)\n- **Extensions**: STAC extensions like `ml-model` for ML-specific metadata\n- **Links**: Relationships to other items (model-to-dataset, model-to-experiments)\n\nFor detailed STAC API usage, see [STAC API Specification](#7.1) and [Using the STAC API](#7.2).\n\nSources: [docs/design/scenarios/model-training.md:47-53](), [docs/design/use-cases.md:52-69]()"])</script><script>self.__next_f.push([1,"20:T4967,"])</script><script>self.__next_f.push([1,"# Model Training Workflow\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/design/diagrams/use-cases.drawio.png](docs/design/diagrams/use-cases.drawio.png)\n- [docs/design/scenarios/flood-example.md](docs/design/scenarios/flood-example.md)\n- [docs/design/scenarios/model-training.md](docs/design/scenarios/model-training.md)\n- [docs/design/use-cases.md](docs/design/use-cases.md)\n- [mkdocs.yml](mkdocs.yml)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis page provides a step-by-step guide through the complete model training lifecycle using the EOEPCA MLOps Building Block. It covers the process from initial project creation in GitLab through experiment tracking with MLflow to final model registration and publication in SharingHub's STAC catalog.\n\nFor detailed component architecture, see [Architecture](#2). For a practical worked example using a flood detection model, see [Flood Detection Example](#4.3). For dataset management workflows, see [Dataset Management](#4.2).\n\nSources: [docs/design/scenarios/model-training.md:1-53]()\n\n## Overview\n\nThe model training workflow involves three core components working together:\n\n| Component | Role in Training Workflow |\n|-----------|---------------------------|\n| **GitLab** | Project repository, version control, collaboration |\n| **MLflow SharingHub** | Experiment tracking, metrics logging, model registry |\n| **SharingHub** | Dataset discovery, model publication, STAC metadata |\n\nThe workflow is designed for ML Developers who need to train, evaluate, and share AI models within a collaborative environment. The platform supports popular ML frameworks and uses ONNX as the standard model representation format.\n\nSources: [docs/design/scenarios/model-training.md:1-53](), [docs/design/use-cases.md:17-69]()\n\n## Complete Workflow Diagram\n\n```mermaid\nsequenceDiagram\n    actor MLD as \"ML Developer\"\n    participant GL as \"GitLab\"\n    participant SH as \"SharingHub\"\n    participant MLC as \"MLflow Client\"\n    participant MLF as \"MLflow Server\"\n    participant UI as \"MLflow UI\"\n    \n    Note over MLD,UI: Step 1: Project Creation\n    MLD-\u003e\u003eGL: Create new project\n    GL--\u003e\u003eMLD: Project created\n    \n    Note over MLD,UI: Step 2: Metadata Configuration\n    MLD-\u003e\u003eGL: Add README.md metadata\n    MLD-\u003e\u003eGL: Add topic 'sharinghub:aimodel'\n    GL-\u003e\u003eSH: Project appears in catalog\n    \n    Note over MLD,UI: Step 3: Training Environment Setup\n    MLD-\u003e\u003eMLC: Install MLflow client\n    MLD-\u003e\u003eMLC: Configure tracking URI from SharingHub\n    MLD-\u003e\u003eMLD: Install model dependencies\n    \n    Note over MLD,UI: Step 4: Dataset Preparation\n    MLD-\u003e\u003eSH: Search for dataset\n    SH--\u003e\u003eMLD: Return STAC catalog results\n    MLD-\u003e\u003eSH: Retrieve dataset (Git LFS/DVC)\n    MLD-\u003e\u003eMLD: Prepare training data\n    \n    Note over MLD,UI: Step 5: Model Training\n    MLD-\u003e\u003eMLC: mlflow.start_run()\n    loop Training Iterations\n        MLD-\u003e\u003eMLC: mlflow.log_param()\n        MLD-\u003e\u003eMLC: mlflow.log_metric()\n    end\n    MLC-\u003e\u003eMLF: Send metrics and parameters\n    MLD-\u003e\u003eMLC: mlflow.log_model()\n    MLD-\u003e\u003eMLC: mlflow.end_run()\n    \n    Note over MLD,UI: Step 6: Model Evaluation\n    MLD-\u003e\u003eUI: View experiments\n    UI-\u003e\u003eMLF: Query run metrics\n    MLF--\u003e\u003eUI: Return metrics data\n    UI--\u003e\u003eMLD: Display performance metrics\n    \n    Note over MLD,UI: Step 7: Model Registration\n    MLD-\u003e\u003eUI: Register model in registry\n    UI-\u003e\u003eMLF: Create model version\n    MLF-\u003e\u003eSH: Auto-link to STAC item\n    SH--\u003e\u003eSH: Update STAC metadata with model version\n    Note over SH: Model now discoverable via STAC API\n```\n\nSources: [docs/design/scenarios/model-training.md:1-53]()\n\n## Prerequisites\n\nBefore starting the model training workflow, ensure the following are available:\n\n| Prerequisite | Description | Reference |\n|--------------|-------------|-----------|\n| GitLab Account | User account with project creation permissions | [GitLab Deployment](#5.2) |\n| MLflow Access | Access to MLflow SharingHub tracking server | [MLflow SharingHub Deployment](#5.4) |\n| SharingHub Access | Access to SharingHub for dataset discovery | [SharingHub Deployment](#5.3) |\n| Local Environment | Python environment with MLflow client installed | - |\n| Training Data | Dataset available via SharingHub or external source | [Dataset Management](#4.2) |\n\nSources: [docs/design/scenarios/model-training.md:23-33]()\n\n## Step 1: Project Creation in GitLab\n\nThe workflow begins with creating a new project in GitLab, which serves as the version control repository for model code, training scripts, and configuration files.\n\n### Actions\n\n1. **Login to GitLab**: Authenticate using OIDC credentials via Keycloak\n2. **Create New Project**: Navigate to \"New project\" in GitLab UI\n3. **Configure Repository**: Set project name, visibility, and initialization options\n4. **Clone Repository**: Clone the project to local development environment\n\n### Key Components\n\n- **GitLab OAuth Client**: Handles authentication flow with Keycloak\n- **GitLab API**: Provides programmatic access for project operations\n- **Git Repository**: Stores model source code and training artifacts\n\nSources: [docs/design/scenarios/model-training.md:13-15]()\n\n## Step 2: Project Metadata and SharingHub Integration\n\nAfter project creation, metadata must be added to enable discovery and categorization in SharingHub's STAC catalog.\n\n### Metadata Configuration\n\nThe following metadata should be added to make the project discoverable:\n\n| Metadata Location | Purpose | Required Fields |\n|-------------------|---------|-----------------|\n| `README.md` | Human-readable description | Model description, usage instructions, license |\n| Project Topics | SharingHub categorization | `sharinghub:aimodel` |\n| Project Tags | Filtering and search | Domain-specific tags (e.g., \"flood-detection\", \"segmentation\") |\n\n### Adding the AI Model Topic\n\nIn GitLab project settings:\n\n1. Navigate to \"Settings\"  \"General\"\n2. Add topic: `sharinghub:aimodel`\n3. Add relevant tags for model categorization\n\nThis topic triggers SharingHub to:\n- Create a STAC Item for the project\n- Add it to the \"AI Model\" collection\n- Enable discovery via STAC API\n\n### SharingHub Integration Flow\n\n```mermaid\ngraph TD\n    GP[\"GitLab Project\u003cbr/\u003e(e.g., flood-model)\"]\n    TOPIC[\"Project Topic\u003cbr/\u003e'sharinghub:aimodel'\"]\n    README[\"README.md\u003cbr/\u003eMetadata\"]\n    \n    SH[\"SharingHub\u003cbr/\u003eSTAC Catalog Generator\"]\n    GLAPI[\"GitLab API\"]\n    \n    COLL[\"STAC Collection\u003cbr/\u003e'AI Models'\"]\n    ITEM[\"STAC Item\u003cbr/\u003eml-model extension\"]\n    STACAPI[\"STAC API\u003cbr/\u003e/collections/ai-models/items\"]\n    \n    GP --\u003e|\"has\"| TOPIC\n    GP --\u003e|\"contains\"| README\n    \n    SH --\u003e|\"queries via\"| GLAPI\n    GLAPI --\u003e|\"filters by topic\"| TOPIC\n    GLAPI --\u003e|\"extracts metadata from\"| README\n    \n    SH --\u003e|\"generates\"| COLL\n    SH --\u003e|\"creates\"| ITEM\n    \n    COLL --\u003e|\"contains\"| ITEM\n    ITEM --\u003e|\"exposed via\"| STACAPI\n    \n    ITEM --\u003e|\"ml-model:architecture\"| META1[\"Model metadata\"]\n    ITEM --\u003e|\"ml-model:training-processor-type\"| META2[\"GPU/CPU info\"]\n    ITEM --\u003e|\"ml-model:learning_approach\"| META3[\"supervised/unsupervised\"]\n```\n\nSources: [docs/design/scenarios/model-training.md:17-21](), [mkdocs.yml:15]()\n\n## Step 3: Setting Up Training Environment\n\nThe training environment must be configured with the MLflow client and necessary dependencies.\n\n### Environment Setup Steps\n\n1. **Install MLflow Client**:\n   ```bash\n   pip install mlflow\n   ```\n\n2. **Configure MLflow Tracking URI**: Obtain from SharingHub deployment\n   ```bash\n   export MLFLOW_TRACKING_URI=https://sharinghub.domain/mlflow\n   ```\n\n3. **Set Authentication**: Configure MLflow credentials if authentication is enabled\n   ```bash\n   export MLFLOW_TRACKING_TOKEN=\u003ctoken\u003e\n   ```\n\n4. **Install Model Dependencies**: Install framework-specific libraries (PyTorch, TensorFlow, scikit-learn, etc.)\n\n### Environment Configuration Table\n\n| Configuration | Environment Variable | Source | Example |\n|---------------|---------------------|---------|---------|\n| Tracking URI | `MLFLOW_TRACKING_URI` | SharingHub MLflow endpoint | `https://sharinghub.develop.eoepca.org/mlflow` |\n| Authentication Token | `MLFLOW_TRACKING_TOKEN` | User credentials or service account | `\u003coauth-token\u003e` |\n| Experiment Name | `MLFLOW_EXPERIMENT_NAME` | User-defined | `flood-detection-v1` |\n\n### Computing Platform Options\n\nThe training environment can be:\n- **Local Machine**: For development and small-scale training\n- **Remote Computing Platform**: For production training with GPU/TPU resources\n- **Kubernetes Job**: For scalable distributed training\n\nSources: [docs/design/scenarios/model-training.md:23-27](), [docs/design/scenarios/flood-example.md:29-33]()\n\n## Step 4: Dataset Preparation\n\nBefore training, the appropriate dataset must be located and prepared.\n\n### Dataset Discovery via SharingHub\n\n1. **Browse Datasets**: Navigate to SharingHub web UI\n2. **Filter by Category**: Select \"Datasets\" collection\n3. **Search and Filter**: Use tags and text search to find relevant datasets\n4. **Access STAC Metadata**: Review dataset metadata, format, and access methods\n\n### Dataset Retrieval Methods\n\n| Method | Use Case | Tools |\n|--------|----------|-------|\n| Git LFS | Small-to-medium datasets (\u003c2GB) | `git lfs pull` |\n| DVC | Large datasets, versioned data | `dvc pull` |\n| Direct Download | One-time downloads | `wget`, `curl`, STAC API |\n| S3 Access | Streaming access to cloud storage | `boto3`, `s3fs` |\n\n### Dataset Preparation Workflow\n\n```mermaid\ngraph LR\n    SH[\"SharingHub\u003cbr/\u003eWeb UI\"]\n    STAC[\"STAC API\u003cbr/\u003e/collections/datasets\"]\n    \n    GL[\"GitLab\u003cbr/\u003eDataset Repository\"]\n    DVC[\"DVC\u003cbr/\u003eData Version Control\"]\n    S3[\"S3 Storage\u003cbr/\u003eDataset Files\"]\n    \n    LOCAL[\"Local Environment\u003cbr/\u003eTraining Data\"]\n    \n    MLD[\"ML Developer\"]\n    \n    MLD --\u003e|\"1. Browse datasets\"| SH\n    SH --\u003e|\"2. Query\"| STAC\n    STAC --\u003e|\"3. Return STAC items\"| SH\n    \n    MLD --\u003e|\"4. Clone repository\"| GL\n    GL --\u003e|\"5. .dvc files\"| LOCAL\n    \n    LOCAL --\u003e|\"6. dvc pull\"| DVC\n    DVC --\u003e|\"7. Download data\"| S3\n    S3 --\u003e|\"8. Dataset files\"| LOCAL\n    \n    LOCAL --\u003e|\"9. Prepare data\"| TRAIN[\"Training Pipeline\"]\n```\n\nSources: [docs/design/scenarios/model-training.md:29-33](), [docs/design/scenarios/flood-example.md:34-40]()\n\n## Step 5: Model Training and Experiment Tracking\n\nDuring training, MLflow tracks experiments, parameters, metrics, and artifacts.\n\n### MLflow Client Integration\n\nThe training script integrates with MLflow using the Python client API:\n\n**Key MLflow Operations**:\n\n| Operation | Method | Purpose |\n|-----------|--------|---------|\n| Start experiment | `mlflow.start_run()` | Begin tracking run |\n| Log parameters | `mlflow.log_param(key, value)` | Record hyperparameters |\n| Log metrics | `mlflow.log_metric(key, value, step)` | Record performance metrics |\n| Log model | `mlflow.log_model(model, artifact_path)` | Save model artifact |\n| Log artifacts | `mlflow.log_artifact(path)` | Save files (plots, configs) |\n| End run | `mlflow.end_run()` | Complete tracking |\n\n### Example Training Script Integration\n\nWhile we don't output new code, a typical integration pattern would:\n1. Import `mlflow` and model framework (e.g., `pytorch`, `sklearn`)\n2. Call `mlflow.start_run()` at training start\n3. Log hyperparameters with `mlflow.log_param()`\n4. Log metrics in training loop with `mlflow.log_metric()`\n5. Save final model with `mlflow.log_model()` or framework-specific flavor (e.g., `mlflow.pytorch.log_model()`)\n6. Call `mlflow.end_run()` at completion\n\n### Experiment Tracking Architecture\n\n```mermaid\ngraph TD\n    SCRIPT[\"Training Script\u003cbr/\u003eflood_model.py\"]\n    \n    subgraph \"MLflow Client API\"\n        STARTRUN[\"mlflow.start_run()\"]\n        LOGPARAM[\"mlflow.log_param()\"]\n        LOGMETRIC[\"mlflow.log_metric()\"]\n        LOGMODEL[\"mlflow.log_model()\"]\n        ENDRUN[\"mlflow.end_run()\"]\n    end\n    \n    MLAPI[\"MLflow Tracking API\u003cbr/\u003e/api/2.0/mlflow\"]\n    \n    subgraph \"MLflow Server Backend\"\n        MLFSERVER[\"MLflow Server\u003cbr/\u003eFlask App\"]\n        PGDB[(\"PostgreSQL\u003cbr/\u003eRuns/Params/Metrics\")]\n        S3STORE[\"S3 Storage\u003cbr/\u003eModel Artifacts\"]\n    end\n    \n    SCRIPT --\u003e STARTRUN\n    SCRIPT --\u003e LOGPARAM\n    SCRIPT --\u003e LOGMETRIC\n    SCRIPT --\u003e LOGMODEL\n    SCRIPT --\u003e ENDRUN\n    \n    STARTRUN --\u003e|\"POST /runs/create\"| MLAPI\n    LOGPARAM --\u003e|\"POST /runs/log-parameter\"| MLAPI\n    LOGMETRIC --\u003e|\"POST /runs/log-metric\"| MLAPI\n    LOGMODEL --\u003e|\"Upload artifact\"| MLAPI\n    ENDRUN --\u003e|\"POST /runs/update\"| MLAPI\n    \n    MLAPI --\u003e MLFSERVER\n    \n    MLFSERVER --\u003e|\"Store metadata\"| PGDB\n    MLFSERVER --\u003e|\"Store artifacts\"| S3STORE\n```\n\n### Logged Information\n\nDuring training, the following information is typically logged:\n\n**Parameters (Hyperparameters)**:\n- Learning rate\n- Batch size\n- Number of epochs\n- Model architecture details\n- Optimizer configuration\n\n**Metrics**:\n- Training loss (per epoch/step)\n- Validation loss\n- Accuracy metrics (precision, recall, F1)\n- Custom evaluation metrics\n\n**Artifacts**:\n- Trained model file (`.pth`, `.h5`, `.pkl`, `.onnx`)\n- Training plots and visualizations\n- Configuration files\n- Dataset metadata\n\nSources: [docs/design/scenarios/model-training.md:35-39](), [docs/design/use-cases.md:37-40]()\n\n## Step 6: Model Evaluation\n\nAfter training completes, the ML Developer evaluates model performance using the MLflow UI.\n\n### Accessing MLflow UI\n\nThe MLflow UI is accessed via the SharingHub domain:\n```\nhttps://sharinghub.domain/mlflow\n```\n\n### Evaluation Workflow\n\n1. **Navigate to Experiments**: View list of experiments in MLflow UI\n2. **Select Run**: Click on specific training run to view details\n3. **Review Metrics**: Examine logged metrics across training steps/epochs\n4. **Compare Runs**: Use comparison view to evaluate multiple training runs\n5. **Visualize Results**: View metric plots and artifacts\n6. **Download Artifacts**: Download trained models or other artifacts\n\n### MLflow UI Components\n\n| UI Section | Purpose | Key Information |\n|------------|---------|-----------------|\n| Experiments List | Browse all experiments | Experiment names, number of runs |\n| Runs Table | View runs within experiment | Run ID, metrics, parameters, start time |\n| Run Detail | Detailed run information | All parameters, metrics over time, artifacts |\n| Comparison View | Compare multiple runs | Side-by-side parameter and metric comparison |\n| Model Registry | Manage registered models | Model versions, stages, metadata |\n\n### Metrics Visualization\n\nThe MLflow UI provides:\n- **Line Charts**: Metric trends over epochs/steps\n- **Scatter Plots**: Parameter vs. metric correlations\n- **Parallel Coordinates**: Multi-dimensional parameter exploration\n- **Metric Tables**: Tabular view of final metric values\n\nSources: [docs/design/scenarios/model-training.md:41-45](), [docs/design/use-cases.md:42-50]()\n\n## Step 7: Model Registration and Publication\n\nOnce a satisfactory model is trained, it is registered in the MLflow Model Registry and automatically linked to SharingHub's STAC catalog.\n\n### Model Registration Process\n\n1. **Select Best Run**: Identify the run with best performance in MLflow UI\n2. **Register Model**: Click \"Register Model\" in the run's artifacts section\n3. **Provide Model Name**: Enter a descriptive model name (e.g., `flood-detection-model`)\n4. **Create Version**: MLflow creates a new model version (e.g., `1.0.0`)\n5. **Auto-Linking**: MLflow SharingHub automatically links the model version to the project's STAC item\n\n### Auto-Linking to STAC Metadata\n\nWhen a model is registered, MLflow SharingHub performs the following:\n\n```mermaid\ngraph TD\n    MLFUI[\"MLflow UI\u003cbr/\u003eRegister Model Action\"]\n    MLFREG[\"MLflow Model Registry\u003cbr/\u003eModel Versions Table\"]\n    \n    SHAPI[\"SharingHub API\u003cbr/\u003ePermission Check\"]\n    GLAPI[\"GitLab API\u003cbr/\u003eProject Lookup\"]\n    \n    STACITEM[\"STAC Item\u003cbr/\u003eml-model extension\"]\n    MLMODEL[\"ml-model:assets\u003cbr/\u003eONNX file reference\"]\n    \n    MLFUI --\u003e|\"1. Register model\u003cbr/\u003emodel_name, version\"| MLFREG\n    \n    MLFREG --\u003e|\"2. Check permissions\"| SHAPI\n    SHAPI --\u003e|\"3. Validate project access\"| GLAPI\n    \n    MLFREG --\u003e|\"4. Update STAC metadata\"| STACITEM\n    STACITEM --\u003e|\"5. Add model asset\"| MLMODEL\n    \n    MLMODEL --\u003e|\"href\"| S3URL[\"S3 URL\u003cbr/\u003es3://bucket/artifacts/model.onnx\"]\n    MLMODEL --\u003e|\"ml-model:framework\"| FRAMEWORK[\"Framework metadata\"]\n    MLMODEL --\u003e|\"ml-model:framework-version\"| VERSION[\"Version info\"]\n```\n\n### STAC ML-Model Extension\n\nThe registered model is exposed in the STAC item with the `ml-model` extension:\n\n**Key Properties**:\n- `ml-model:architecture`: Model architecture (e.g., \"U-Net\", \"ResNet-50\")\n- `ml-model:framework`: Training framework (e.g., \"pytorch\", \"tensorflow\")\n- `ml-model:framework-version`: Framework version\n- `ml-model:learning_approach`: Learning type (\"supervised\", \"unsupervised\", \"reinforcement\")\n- `ml-model:prediction_type`: Task type (\"classification\", \"regression\", \"segmentation\")\n- `ml-model:training-processor-type`: Hardware used (\"cpu\", \"gpu\", \"tpu\")\n\n**Assets**:\nThe STAC item includes an asset with the ONNX model file:\n- `href`: S3 URL to the model file\n- `type`: `application/x-onnx` or `application/octet-stream`\n- `roles`: `[\"ml-model\"]`\n\n### Model Discovery\n\nAfter registration, the model becomes discoverable through multiple channels:\n\n| Discovery Method | Access Point | Audience |\n|------------------|--------------|----------|\n| SharingHub Web UI | Browse AI Models collection | Interactive users |\n| STAC API | `/collections/ai-models/items/{model-id}` | Programmatic access |\n| MLflow UI | Model Registry section | ML developers |\n| GitLab Project | Project page with STAC metadata link | Collaborators |\n\nSources: [docs/design/scenarios/model-training.md:47-53](), [docs/design/use-cases.md:60-69]()\n\n## Workflow Summary\n\nThe complete model training workflow integrates GitLab, MLflow SharingHub, and SharingHub to provide:\n\n**For ML Developers**:\n- Version-controlled project repositories\n- Automated experiment tracking\n- Visual performance evaluation\n- Centralized model registry\n- Automatic STAC publication\n\n**For Model Consumers**:\n- Standardized model discovery via STAC API\n- ONNX model format for interoperability\n- Rich metadata for model selection\n- Access control through GitLab permissions\n\n**Integration Points**:\n- GitLab topics trigger SharingHub catalog generation\n- MLflow client sends tracking data to MLflow server\n- MLflow registry updates trigger STAC metadata updates\n- SharingHub validates permissions against GitLab projects\n\nThe workflow ensures that models are properly tracked, evaluated, and shared within a collaborative MLOps environment while maintaining standardization through STAC and ONNX formats.\n\nSources: [docs/design/scenarios/model-training.md:1-53](), [docs/design/use-cases.md:1-96](), [mkdocs.yml:14-16]()"])</script><script>self.__next_f.push([1,"21:T4cbe,"])</script><script>self.__next_f.push([1,"# Dataset Management\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/design/diagrams/use-cases.drawio.png](docs/design/diagrams/use-cases.drawio.png)\n- [docs/design/scenarios/flood-example.md](docs/design/scenarios/flood-example.md)\n- [docs/design/scenarios/model-training.md](docs/design/scenarios/model-training.md)\n- [docs/design/use-cases.md](docs/design/use-cases.md)\n- [docs/usage/howto/dataset_with_workspace.md](docs/usage/howto/dataset_with_workspace.md)\n- [mkdocs.yml](mkdocs.yml)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis document describes how to manage, version, and share datasets within the EOEPCA MLOps Building Block. Dataset management is primarily handled through **DVC (Data Version Control)** integrated with **GitLab** for metadata versioning and **S3 object storage** for actual data files. Datasets are automatically discoverable through **SharingHub** when properly configured.\n\nFor model training workflows that consume these datasets, see [Model Training Workflow](#4.1). For a practical example demonstrating dataset usage, see [Flood Detection Example](#4.3).\n\n**Sources**: [docs/design/use-cases.md:70-96](), [docs/design/scenarios/model-training.md:29-34]()\n\n---\n\n## Components and Architecture\n\nThe dataset management system integrates multiple components from the MLOps Building Block:\n\n| Component | Role in Dataset Management |\n|-----------|---------------------------|\n| **DVC** | Version control for large data files, tracks changes, enables data pipelines |\n| **GitLab** | Hosts DVC metadata (`.dvc` files), project README, and dataset documentation |\n| **S3 Object Storage** | Remote storage backend for actual dataset files (images, videos, text, etc.) |\n| **SharingHub** | Automatic discovery and STAC catalog generation for datasets with `sharinghub:dataset` topic |\n| **Workspace BB** | Optional: Provides user-specific S3 buckets for dataset storage |\n\n**Sources**: [docs/design/use-cases.md:71-88](), [docs/usage/howto/dataset_with_workspace.md:1-21]()\n\n---\n\n## Dataset Management Architecture\n\n```mermaid\ngraph TB\n    subgraph \"Data Scientist Workstation\"\n        DS[\"Data Scientist\"]\n        DVCLOCAL[\"DVC CLI\"]\n        GITCLI[\"Git CLI\"]\n        DATAFILES[\"Local Dataset Files\u003cbr/\u003e(images, CSVs, GeoTIFFs)\"]\n    end\n    \n    subgraph \"GitLab Repository\"\n        GITREPO[\"Dataset GitLab Project\u003cbr/\u003etopic: sharinghub:dataset\"]\n        DVCFILES[\".dvc Metadata Files\u003cbr/\u003e.dvc/config\"]\n        README[\"README.md\u003cbr/\u003eDataset Documentation\"]\n        GITLFS[\"Git LFS\u003cbr/\u003e(optional alternative)\"]\n    end\n    \n    subgraph \"S3 Object Storage\"\n        S3BUCKET[\"S3 Bucket\u003cbr/\u003eDataset Files Storage\"]\n        WORKSPACE[\"Workspace BB Bucket\u003cbr/\u003e(optional)\"]\n    end\n    \n    subgraph \"SharingHub Discovery\"\n        SHCATALOG[\"SharingHub STAC Catalog\"]\n        STACITEM[\"STAC Item\u003cbr/\u003ewith eo extension\"]\n        STACAPI[\"STAC API\u003cbr/\u003e/collections/datasets\"]\n    end\n    \n    DS --\u003e|\"1. dvc init\"| DVCLOCAL\n    DS --\u003e|\"2. dvc add data/\"| DVCLOCAL\n    DVCLOCAL --\u003e|\"3. generates\"| DVCFILES\n    DS --\u003e|\"4. git add .dvc files\"| GITCLI\n    GITCLI --\u003e|\"5. git push\"| GITREPO\n    DVCLOCAL --\u003e|\"6. dvc push\"| S3BUCKET\n    DVCLOCAL -.-\u003e|\"alternative: dvc push\"| WORKSPACE\n    \n    GITREPO --\u003e|\"7. extracts metadata\"| SHCATALOG\n    GITREPO --\u003e|\"filters by topic\"| SHCATALOG\n    SHCATALOG --\u003e|\"8. generates\"| STACITEM\n    STACITEM --\u003e|\"9. exposed via\"| STACAPI\n    \n    DATAFILES -.-\u003e|\"tracked by\"| DVCLOCAL\n    DVCFILES --\u003e|\"references\"| S3BUCKET\n    \n    README --\u003e|\"contains dataset info\"| STACITEM\n```\n\n**Diagram**: Dataset Management Architecture showing DVC workflow integration with GitLab and SharingHub\n\nThis diagram illustrates the complete dataset lifecycle from creation to discovery. DVC handles the version control of large files by storing metadata in GitLab while the actual data resides in S3. SharingHub automatically indexes datasets from GitLab projects tagged with the `sharinghub:dataset` topic.\n\n**Sources**: [docs/design/use-cases.md:74-88](), [docs/usage/howto/dataset_with_workspace.md:8-20]()\n\n---\n\n## Dataset Publishing Workflow\n\n### Step 1: Create Dataset Project in GitLab\n\nCreate a new GitLab project to host your dataset:\n\n1. Log in to GitLab\n2. Create new project (e.g., `sen1floods11-dataset`)\n3. Clone the repository locally\n\n### Step 2: Initialize DVC\n\nInitialize DVC in your dataset repository:\n\n```bash\ncd sen1floods11-dataset\ndvc init\ngit add .dvc .dvcignore\ngit commit -m \"Initialize DVC\"\n```\n\n### Step 3: Configure S3 Remote\n\nConfigure DVC to use an S3 bucket as the remote storage backend:\n\n```bash\n# Add S3 remote\ndvc remote add --default myremote s3://my-datasets-bucket/sen1floods11\n\n# Configure endpoint (if using custom S3 provider)\ndvc remote modify myremote endpointurl https://s3.example.com\n\n# Configure credentials (stored locally, not committed)\ndvc remote modify --local myremote access_key_id \u003caccess-key\u003e\ndvc remote modify --local myremote secret_access_key \u003csecret-key\u003e\n```\n\n**Workspace BB Integration**: To use the Workspace BB for dataset storage, configure the remote with your workspace bucket as shown in [docs/usage/howto/dataset_with_workspace.md:10-20]():\n\n```bash\ndvc remote add --default workspace s3://ws-username/my-dataset\ndvc remote modify workspace endpointurl https://minio.develop.eoepca.org\n```\n\n### Step 4: Add Dataset Files\n\nTrack your dataset files with DVC:\n\n```bash\n# Add entire data directory\ndvc add data/\n\n# Or add specific files\ndvc add data/images/\ndvc add data/labels.csv\n\n# Commit the .dvc metadata files\ngit add data.dvc .gitignore\ngit commit -m \"Add dataset files\"\n```\n\nDVC generates `.dvc` files that contain MD5 hashes and references to the actual data in S3.\n\n### Step 5: Push Data to S3\n\nUpload the actual dataset files to S3:\n\n```bash\ndvc push\n```\n\nThis command transfers the data files to the configured S3 remote while keeping only metadata in GitLab.\n\n### Step 6: Configure for SharingHub Discovery\n\nAdd the `sharinghub:dataset` topic to make the dataset discoverable:\n\n1. Navigate to your GitLab project settings\n2. Add topic: `sharinghub:dataset`\n3. Add descriptive tags (e.g., `flood-detection`, `sentinel-1`, `segmentation`)\n4. Update `README.md` with dataset description, format, and usage instructions\n\nThe project will automatically appear in the SharingHub catalog under the \"Datasets\" collection.\n\n**Sources**: [docs/design/use-cases.md:74-88](), [docs/design/scenarios/flood-example.md:34-39](), [docs/usage/howto/dataset_with_workspace.md:8-20]()\n\n---\n\n## Dataset Versioning and Iteration\n\n```mermaid\nsequenceDiagram\n    participant DS as Data Scientist\n    participant DVC as DVC CLI\n    participant Git as GitLab Repository\n    participant S3 as S3 Bucket\n    \n    Note over DS,S3: Initial Version\n    DS-\u003e\u003eDVC: dvc add data/\n    DVC-\u003e\u003eGit: commit data.dvc (v1 hash)\n    DVC-\u003e\u003eS3: push data files (v1)\n    DS-\u003e\u003eGit: git tag v1.0.0\n    \n    Note over DS,S3: Updated Version\n    DS-\u003e\u003eDS: modify/add data files\n    DS-\u003e\u003eDVC: dvc add data/\n    DVC-\u003e\u003eGit: commit data.dvc (v2 hash)\n    DVC-\u003e\u003eS3: push data files (v2)\n    DS-\u003e\u003eGit: git tag v1.1.0\n    \n    Note over DS,S3: Retrieve Specific Version\n    DS-\u003e\u003eGit: git checkout v1.0.0\n    DS-\u003e\u003eDVC: dvc pull\n    DVC-\u003e\u003eS3: fetch data files (v1 hash)\n    DVC-\u003e\u003eDS: restore v1.0.0 data\n```\n\n**Diagram**: Dataset Versioning Workflow with DVC and GitLab Tags\n\n### Version Control Best Practices\n\n| Practice | Implementation | Benefit |\n|----------|---------------|---------|\n| **Git Tags** | Use semantic versioning (v1.0.0, v1.1.0) | Clear version identification |\n| **Commit Messages** | Describe dataset changes in detail | Audit trail of modifications |\n| **Branching** | Experiment with dataset variations in branches | Safe iteration without affecting main |\n| **DVC Pipelines** | Define preprocessing pipelines in `dvc.yaml` | Reproducible data transformations |\n\n### Iterating on Datasets\n\nTo create a new version of a dataset:\n\n```bash\n# Make changes to dataset files\n# (e.g., add more samples, fix labels, augment data)\n\n# Track the changes\ndvc add data/\n\n# Push updated data to S3\ndvc push\n\n# Commit metadata changes\ngit add data.dvc\ngit commit -m \"v1.1.0: Added 500 new labeled samples\"\ngit tag v1.1.0\ngit push origin v1.1.0\n```\n\nTo retrieve a specific version:\n\n```bash\ngit checkout v1.0.0\ndvc pull\n```\n\n**Sources**: [docs/design/use-cases.md:79-83](), [docs/design/scenarios/flood-example.md:37-39]()\n\n---\n\n## Dataset Discovery and Retrieval\n\n### Discovering Datasets via SharingHub\n\n```mermaid\ngraph LR\n    subgraph \"ML Developer Discovery Workflow\"\n        DEV[\"ML Developer\"]\n        SHUI[\"SharingHub Web UI\u003cbr/\u003esharinghub.domain\"]\n        FILTER[\"Filter: datasets collection\u003cbr/\u003etags, keywords\"]\n        ITEM[\"STAC Item\u003cbr/\u003eDataset Metadata\"]\n        GITLAB[\"GitLab Project\u003cbr/\u003eREADME \u0026 Instructions\"]\n    end\n    \n    subgraph \"Retrieval Options\"\n        GITCLONE[\"git clone\u003cbr/\u003e+ dvc pull\"]\n        STACAPI[\"STAC API\u003cbr/\u003eGET /items/{id}\"]\n        DOWNLOAD[\"Direct S3 Download\u003cbr/\u003e(if public)\"]\n    end\n    \n    DEV --\u003e|\"1. Browse\"| SHUI\n    SHUI --\u003e|\"2. Apply\"| FILTER\n    FILTER --\u003e|\"3. Select\"| ITEM\n    ITEM --\u003e|\"4. View details\"| GITLAB\n    \n    GITLAB --\u003e|\"5a. Clone repo\"| GITCLONE\n    GITLAB --\u003e|\"5b. API access\"| STACAPI\n    GITLAB --\u003e|\"5c. Direct link\"| DOWNLOAD\n```\n\n**Diagram**: Dataset Discovery and Retrieval Workflow\n\n### Using SharingHub Web UI\n\n1. Navigate to SharingHub (e.g., `https://sharinghub.develop.eoepca.org`)\n2. Select \"Datasets\" category\n3. Apply filters by tags (e.g., `flood-detection`, `sentinel-1`)\n4. Click on a dataset to view STAC metadata\n5. Click \"Open in GitLab\" to access the repository\n\n### Using STAC API for Programmatic Access\n\nRetrieve dataset metadata using the STAC API:\n\n```python\nimport pystac_client\n\n# Connect to STAC API\ncatalog = pystac_client.Client.open(\"https://sharinghub.domain/api/catalog\")\n\n# Search for datasets\nsearch = catalog.search(\n    collections=[\"datasets\"],\n    query={\"tags\": {\"contains\": \"flood-detection\"}}\n)\n\n# Iterate through results\nfor item in search.items():\n    print(f\"Dataset: {item.id}\")\n    print(f\"Description: {item.properties.get('description')}\")\n    print(f\"GitLab URL: {item.properties.get('gitlab_web_url')}\")\n```\n\nFor detailed STAC API usage, see [STAC API Specification](#7.1) and [Using the STAC API](#7.2).\n\n### Retrieving Dataset Files\n\nAfter finding a dataset, retrieve it using DVC:\n\n```bash\n# Clone the GitLab repository\ngit clone https://gitlab.domain/group/dataset-name.git\ncd dataset-name\n\n# Configure DVC credentials (if private)\ndvc remote modify --local myremote access_key_id \u003ckey\u003e\ndvc remote modify --local myremote secret_access_key \u003csecret\u003e\n\n# Pull dataset files from S3\ndvc pull\n```\n\nThe dataset files will be downloaded from S3 to the `data/` directory (or as specified in `.dvc` files).\n\n**Sources**: [docs/design/use-cases.md:89-96](), [docs/design/scenarios/model-training.md:29-34](), [docs/design/scenarios/flood-example.md:34-39]()\n\n---\n\n## Dataset Formats and Types\n\nThe Training Data Manager supports various dataset formats commonly used in ML:\n\n| Format Type | File Extensions | Use Cases | Example Projects |\n|-------------|----------------|-----------|------------------|\n| **Images** | `.png`, `.jpg`, `.tif`, `.tiff` | Computer vision, segmentation | Sentinel-2 imagery, flood masks |\n| **Geospatial** | `.geotiff`, `.tif` | Earth observation, remote sensing | SAR images, elevation data |\n| **Tabular** | `.csv`, `.parquet`, `.tsv` | Classification, regression | Wine quality, sensor data |\n| **Text** | `.txt`, `.json`, `.xml` | NLP, text classification | Annotations, metadata |\n| **Video** | `.mp4`, `.avi` | Action recognition, tracking | Satellite video streams |\n| **Audio** | `.wav`, `.mp3` | Sound classification | Environmental audio |\n\n### Storage Considerations\n\n- **Large Files**: DVC is optimized for files \u003e10MB; Git LFS is an alternative for smaller binary files\n- **Dataset Structure**: Organize files in logical directories (e.g., `data/train/`, `data/test/`, `data/labels/`)\n- **Compression**: Consider compressing datasets before versioning to reduce storage costs\n- **Incremental Updates**: DVC only uploads changed files, not entire datasets\n\n**Sources**: [docs/design/use-cases.md:77-78]()\n\n---\n\n## Integration with Model Training\n\n```mermaid\ngraph TB\n    subgraph \"Dataset Preparation\"\n        DATASET[\"Dataset Project\u003cbr/\u003eGitLab + DVC\"]\n        DATAFILES[\"data/\u003cbr/\u003eimages, labels\"]\n    end\n    \n    subgraph \"Model Training Project\"\n        MODELREPO[\"Model GitLab Project\u003cbr/\u003etopic: sharinghub:aimodel\"]\n        TRAINSCRIPT[\"train.py\"]\n        REQUIREMENTS[\"requirements.txt\u003cbr/\u003emlflow, dvc, torch\"]\n    end\n    \n    subgraph \"Training Environment\"\n        MLDEV[\"ML Developer\"]\n        LOCALENV[\"Local/Remote\u003cbr/\u003eCompute Environment\"]\n        MLFLOWCLIENT[\"MLflow Client\"]\n        DVCCLI[\"DVC CLI\"]\n    end\n    \n    subgraph \"MLflow Tracking\"\n        MLFLOWSERVER[\"MLflow SharingHub\u003cbr/\u003eTracking Server\"]\n        EXPERIMENTS[\"Experiments\u003cbr/\u003e+ Metrics\"]\n        REGISTRY[\"Model Registry\"]\n    end\n    \n    DATASET -.-\u003e|\"references in README\"| MODELREPO\n    MLDEV --\u003e|\"1. git clone\"| MODELREPO\n    MLDEV --\u003e|\"2. git clone\"| DATASET\n    MLDEV --\u003e|\"3. dvc pull\"| DVCCLI\n    DVCCLI --\u003e|\"fetches\"| DATAFILES\n    \n    MLDEV --\u003e|\"4. python train.py\"| TRAINSCRIPT\n    TRAINSCRIPT --\u003e|\"reads\"| DATAFILES\n    TRAINSCRIPT --\u003e|\"logs metrics\"| MLFLOWCLIENT\n    MLFLOWCLIENT --\u003e|\"sends\"| MLFLOWSERVER\n    MLFLOWSERVER --\u003e|\"stores\"| EXPERIMENTS\n    \n    MLDEV --\u003e|\"5. register model\"| REGISTRY\n```\n\n**Diagram**: Dataset Integration with Model Training Workflow\n\n### Referencing Datasets in Model Projects\n\nModel projects should reference their training datasets in the README:\n\n```markdown\n## Dataset\n\nThis model is trained on the [Sen1Floods11 Dataset](https://gitlab.domain/group/sen1floods11-dataset).\n\n### Setup\n\n1. Clone the dataset repository:\n   ```bash\n   git clone https://gitlab.domain/group/sen1floods11-dataset.git\n   cd sen1floods11-dataset\n   ```\n\n2. Configure DVC credentials and pull data:\n   ```bash\n   dvc remote modify --local myremote access_key_id \u003ckey\u003e\n   dvc remote modify --local myremote secret_access_key \u003csecret\u003e\n   dvc pull\n   ```\n\n3. Update the dataset path in your training configuration.\n```\n\nThis creates a clear link between models and their training datasets, enabling reproducibility.\n\n**Sources**: [docs/design/scenarios/model-training.md:29-34](), [docs/design/scenarios/flood-example.md:34-40]()\n\n---\n\n## Dataset Metadata and STAC Extensions\n\nDatasets published through SharingHub are exposed as STAC items with appropriate extensions:\n\n### STAC Item Structure for Datasets\n\n```json\n{\n  \"type\": \"Feature\",\n  \"stac_version\": \"1.0.0\",\n  \"id\": \"sen1floods11-dataset\",\n  \"properties\": {\n    \"description\": \"Sentinel-1 SAR flood detection dataset\",\n    \"tags\": [\"flood-detection\", \"sentinel-1\", \"segmentation\"],\n    \"gitlab_web_url\": \"https://gitlab.domain/group/sen1floods11-dataset\"\n  },\n  \"stac_extensions\": [\n    \"https://stac-extensions.github.io/eo/v1.1.0/schema.json\"\n  ],\n  \"assets\": {\n    \"repository\": {\n      \"href\": \"https://gitlab.domain/group/sen1floods11-dataset.git\",\n      \"type\": \"application/x-git\",\n      \"title\": \"Git Repository\"\n    },\n    \"data\": {\n      \"href\": \"s3://datasets-bucket/sen1floods11/\",\n      \"type\": \"application/x-directory\",\n      \"title\": \"Dataset Files (via DVC)\"\n    }\n  }\n}\n```\n\n### Common STAC Extensions for Datasets\n\n| Extension | Purpose | Applicable Dataset Types |\n|-----------|---------|-------------------------|\n| **eo** | Earth Observation metadata (bands, resolution) | Satellite imagery, aerial photos |\n| **datacube** | Multi-dimensional array structure | Time-series, hyperspectral data |\n| **scientific** | Citations, DOIs, publications | Research datasets |\n| **file** | File format and size details | All dataset types |\n\n**Sources**: [docs/design/use-cases.md:70-88]()\n\n---\n\n## Workspace BB Integration\n\nThe Workspace Building Block provides personal S3-compatible storage for users. Datasets can be stored in user workspace buckets, enabling private dataset management.\n\n### Configuration Example\n\nConfigure DVC to use a Workspace BB bucket as shown in [docs/usage/howto/dataset_with_workspace.md:10-20]():\n\n```bash\n# Configure workspace bucket as DVC remote\ndvc remote add --default workspace s3://ws-bob/my-dataset\ndvc remote modify workspace endpointurl https://minio.develop.eoepca.org\n\n# Set credentials locally\ndvc remote modify --local workspace access_key_id \u003cworkspace-access-key\u003e\ndvc remote modify --local workspace secret_access_key \u003cworkspace-secret-key\u003e\n```\n\n### Benefits of Workspace Integration\n\n- **Per-User Storage**: Each user has isolated storage space\n- **Access Control**: Workspace BB handles authentication and authorization\n- **Quota Management**: Storage limits enforced at the workspace level\n- **Lifecycle Management**: Datasets tied to user workspace lifecycle\n\n**Sources**: [docs/usage/howto/dataset_with_workspace.md:1-21]()\n\n---\n\n## Best Practices\n\n### Dataset Organization\n\n```\ndataset-project/\n data/\n    train/\n       images/\n       labels/\n    val/\n       images/\n       labels/\n    test/\n        images/\n        labels/\n .dvc/\n    config\n data.dvc\n .dvcignore\n README.md\n LICENSE\n```\n\n### Documentation Requirements\n\nA well-documented dataset project should include:\n\n| File | Required Content |\n|------|-----------------|\n| `README.md` | Dataset description, structure, format, license, usage examples |\n| `LICENSE` | Clear licensing terms (e.g., CC-BY-4.0, MIT) |\n| `CHANGELOG.md` | Version history with changes per version |\n| `data/README.md` | Detailed schema, field descriptions, data format specifications |\n\n### Access Control Strategies\n\n| Strategy | Implementation | Use Case |\n|----------|---------------|----------|\n| **Public Datasets** | Public GitLab project + public S3 bucket | Open data for community use |\n| **Organization Datasets** | Internal GitLab project + private S3 bucket | Shared within organization |\n| **Private Datasets** | Private GitLab project + Workspace bucket | Personal research datasets |\n\n### Performance Optimization\n\n- **Chunking Large Files**: Split very large files into smaller chunks for better version control\n- **DVC Cache**: Enable local DVC cache to avoid repeated downloads\n- **S3 Transfer Acceleration**: Enable for faster uploads/downloads across regions\n- **Parallel Transfers**: Configure DVC to use multiple threads for transfers\n\n**Sources**: [docs/design/use-cases.md:74-88](), [docs/design/scenarios/flood-example.md:34-39]()\n\n---\n\n## Summary\n\nDataset management in the EOEPCA MLOps Building Block provides:\n\n1. **Version Control**: DVC tracks dataset versions alongside code in GitLab\n2. **Scalable Storage**: S3 object storage handles large datasets (GB to TB scale)\n3. **Automatic Discovery**: Datasets appear in SharingHub STAC catalog with `sharinghub:dataset` topic\n4. **Flexible Integration**: Works with Workspace BB, custom S3 providers, or cloud storage\n5. **Reproducibility**: Links between models and dataset versions enable reproducible training\n\nFor hands-on examples, see the [Flood Detection Example](#4.3) which demonstrates complete dataset usage with the Sen1Floods11 dataset. For deployment details, see [SharingHub Deployment](#5.3).\n\n**Sources**: [docs/design/use-cases.md:70-96](), [docs/usage/howto/dataset_with_workspace.md:1-21]()"])</script><script>self.__next_f.push([1,"22:T470e,"])</script><script>self.__next_f.push([1,"# Flood Detection Example\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/design/scenarios/flood-example.md](docs/design/scenarios/flood-example.md)\n- [docs/design/scenarios/model-training.md](docs/design/scenarios/model-training.md)\n- [mkdocs.yml](mkdocs.yml)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis page provides a complete, practical walkthrough of training and deploying a flood detection model using the EOEPCA MLOps Building Block. The example demonstrates how ML Developers and ML Users interact with the platform to train, register, and consume AI models for Earth Observation applications.\n\nFor general information about the model training workflow, see [Model Training Workflow](#4.1). For dataset management concepts, see [Dataset Management](#4.2).\n\n## Overview\n\nThe flood detection example showcases an end-to-end machine learning workflow using the following components:\n\n| Component | Repository | Purpose |\n|-----------|-----------|---------|\n| Flood Model | [sharinghub-test/flood-model](https://gitlab.develop.eoepca.org/sharinghub-test/flood-model) | Image segmentation model for flood detection |\n| Sen1Floods11 Dataset | [sharinghub-test/sen1floods11-dataset](https://gitlab.develop.eoepca.org/sharinghub-test/sen1floods11-dataset) | Training dataset with Sentinel-1 SAR imagery |\n\nBoth repositories are hosted on the develop cluster at `https://gitlab.develop.eoepca.org/` and are mirrored to:\n- GitHub: `https://github.com/EOEPCA/flood-model`\n- GitHub: `https://github.com/EOEPCA/Sen1Floods11-Dataset`\n\n**Sources:** [docs/design/scenarios/flood-example.md:1-13]()\n\n## Workflow Architecture\n\n```mermaid\ngraph TB\n    subgraph \"Discovery Phase\"\n        SHUI[\"SharingHub UI\u003cbr/\u003esharinghub.develop.eoepca.org\"]\n        FILTER[\"Filter: 'flood'\u003cbr/\u003eCategory: Models\"]\n        STACITEM[\"STAC Item:\u003cbr/\u003eflood-model\"]\n    end\n    \n    subgraph \"GitLab Repositories\"\n        FLOODREPO[\"flood-model\u003cbr/\u003esharinghub-test/flood-model\"]\n        DATAREPO[\"sen1floods11-dataset\u003cbr/\u003esharinghub-test/sen1floods11-dataset\"]\n    end\n    \n    subgraph \"Development Environment\"\n        POETRY[\"poetry install\u003cbr/\u003ePython dependencies\"]\n        ENVFILE[\".env file\u003cbr/\u003eMLflow credentials\"]\n        DVCPULL[\"dvc pull\u003cbr/\u003eDataset download\"]\n    end\n    \n    subgraph \"Training Execution\"\n        TRAIN[\"Training script\u003cbr/\u003eflood-model/train.py\"]\n        MLFLOW[\"MLflow Tracking\u003cbr/\u003eMetrics logging\"]\n        MLFUI[\"MLflow UI\u003cbr/\u003eExperiment visualization\"]\n    end\n    \n    subgraph \"Model Artifacts\"\n        ONNX[\"model.onnx\u003cbr/\u003eExported model\"]\n        PREDICTIONS[\"predictions/prediction.tif\u003cbr/\u003eInference output\"]\n    end\n    \n    subgraph \"Deployment\"\n        DOCKER_TRAIN[\"Docker image\u003cbr/\u003eTraining container\"]\n        DOCKER_INFER[\"Docker image\u003cbr/\u003eInference container\"]\n        CWL[\"inference.cwl\u003cbr/\u003erun_inference_input.yml\"]\n    end\n    \n    SHUI --\u003e FILTER\n    FILTER --\u003e STACITEM\n    STACITEM --\u003e FLOODREPO\n    FLOODREPO --\u003e POETRY\n    FLOODREPO --\u003e ENVFILE\n    DATAREPO --\u003e DVCPULL\n    \n    POETRY --\u003e TRAIN\n    ENVFILE --\u003e TRAIN\n    DVCPULL --\u003e TRAIN\n    \n    TRAIN --\u003e MLFLOW\n    MLFLOW --\u003e MLFUI\n    \n    TRAIN --\u003e ONNX\n    ONNX --\u003e PREDICTIONS\n    \n    TRAIN --\u003e DOCKER_TRAIN\n    ONNX --\u003e DOCKER_INFER\n    ONNX --\u003e CWL\n```\n\n**Workflow Architecture Diagram**: This diagram shows the complete flood detection workflow from discovery through deployment, mapping natural language concepts to specific code entities and files.\n\n**Sources:** [docs/design/scenarios/flood-example.md:1-72](), [docs/design/scenarios/model-training.md:1-53]()\n\n## ML Developer Workflow\n\n### Step 1: Browsing SharingHub for the Model\n\nThe ML Developer begins by discovering the flood detection model through the SharingHub web interface:\n\n1. Navigate to `https://sharinghub.develop.eoepca.org`\n2. Click on the **\"Models\"** category\n3. Apply filter: `\"flood\"`\n4. Select the flood-model STAC item\n5. Click **\"Open in GitLab\"** to access the project repository\n\nThis workflow leverages SharingHub's STAC catalog, which dynamically generates catalog entries from GitLab projects tagged with the `sharinghub:aimodel` topic. The flood-model project appears in the catalog because it has this topic configured in its GitLab project settings.\n\n**Sources:** [docs/design/scenarios/flood-example.md:17-24]()\n\n### Step 2: Cloning the Model Repository\n\nClone the flood model repository from GitLab:\n\n```bash\ngit clone https://gitlab.develop.eoepca.org/sharinghub-test/flood-model.git\ncd flood-model\n```\n\nThe repository contains:\n- Training scripts for model development\n- Model architecture definitions\n- Configuration files for MLflow integration\n- Inference scripts for model deployment\n- Docker configurations for containerization\n\n**Sources:** [docs/design/scenarios/flood-example.md:25-27]()\n\n### Step 3: Model Setup\n\nConfigure the development environment using Poetry for dependency management:\n\n```bash\npoetry install\n```\n\nCreate a `.env` file in the project root with MLflow credentials for experiment tracking:\n\n```\nMLFLOW_TRACKING_URI=https://sharinghub.develop.eoepca.org/mlflow\nMLFLOW_TRACKING_USERNAME=\u003cusername\u003e\nMLFLOW_TRACKING_PASSWORD=\u003cpassword\u003e\n```\n\nThe `.env` file enables the MLflow client to authenticate with the MLflow SharingHub instance, which delegates permission checks to SharingHub. This ensures that only authorized users can log experiments to the flood-model project.\n\n**Sources:** [docs/design/scenarios/flood-example.md:29-32]()\n\n### Step 4: Dataset Setup\n\nThe flood model requires the Sen1Floods11 dataset, which is managed using DVC (Data Version Control):\n\n```bash\n# Clone the dataset repository\ngit clone https://gitlab.develop.eoepca.org/sharinghub-test/sen1floods11-dataset.git\ncd sen1floods11-dataset\n\n# Configure DVC credentials for S3 backend\ndvc remote modify myremote access_key_id \u003caws_access_key_id\u003e\ndvc remote modify myremote secret_access_key \u003caws_secret_access_key\u003e\n\n# Pull dataset files from S3\ndvc pull\n```\n\nThe `dvc pull` command downloads the actual dataset files (Sentinel-1 SAR imagery and flood labels) from S3 object storage. DVC stores only metadata in Git, keeping the repository lightweight while providing full dataset versioning.\n\n**Sources:** [docs/design/scenarios/flood-example.md:34-39]()\n\n### Step 5: Training the Model\n\nExecute the training session:\n\n```bash\npoetry run python train.py\n```\n\nDuring training, the script:\n- Logs hyperparameters, metrics, and artifacts to MLflow using the tracking URI configured in `.env`\n- Supports streaming mode for large datasets that don't fit in memory\n- Provides no-cache options for processing fresh data\n\nMonitor training progress by accessing the MLflow UI at `https://sharinghub.develop.eoepca.org/mlflow`:\n- Navigate to **Experiments  Runs**\n- View real-time metrics (loss, accuracy, IoU)\n- Compare runs with different hyperparameters\n- Inspect logged artifacts (model checkpoints, plots)\n\n**Sources:** [docs/design/scenarios/flood-example.md:41-45]()\n\n### Step 6: Running Inference\n\nAfter training, test the model with a sample image:\n\n```bash\npoetry run python inference.py --input Pakistan_43105_S1Hand.tif --model model.onnx\n```\n\nThe inference script:\n- Loads the exported ONNX model (`model.onnx`)\n- Processes the input GeoTIFF file (`Pakistan_43105_S1Hand.tif`, 512512 pixels)\n- Generates a prediction mask showing flood extent\n- Saves the result to `predictions/prediction.tif`\n\nThe output file `predictions/prediction.tif` is a GeoTIFF with the same spatial dimensions as the input, where pixel values indicate flood probability or binary classification (flooded/not flooded).\n\n**Sources:** [docs/design/scenarios/flood-example.md:47-50]()\n\n## Packaging and Deployment\n\n```mermaid\ngraph TB\n    subgraph \"Training Package\"\n        TRAINCODE[\"Training code\u003cbr/\u003etrain.py, dataset loaders\"]\n        TRAINDEP[\"Dependencies\u003cbr/\u003epyproject.toml, poetry.lock\"]\n        TRAINENV[\"Environment config\u003cbr/\u003e.env, MLflow settings\"]\n        TRAINDOCKER[\"Dockerfile.train\u003cbr/\u003eTraining container\"]\n    end\n    \n    subgraph \"Inference Package\"\n        ONNXMODEL[\"model.onnx\u003cbr/\u003eExported model\"]\n        INFERCODE[\"inference.py\u003cbr/\u003eInference script\"]\n        INFERDEP[\"Runtime dependencies\u003cbr/\u003eonnxruntime, rasterio\"]\n        INFERDOCKER[\"Dockerfile.inference\u003cbr/\u003eInference container\"]\n    end\n    \n    subgraph \"CWL Workflow\"\n        CWLFILE[\"inference.cwl\u003cbr/\u003eWorkflow definition\"]\n        CWLINPUT[\"run_inference_input.yml\u003cbr/\u003eInput parameters\"]\n        CWLTOOL[\"cwltool\u003cbr/\u003eWorkflow executor\"]\n    end\n    \n    subgraph \"Execution\"\n        TRAINRUN[\"docker run\u003cbr/\u003eTraining container\"]\n        INFERRUN[\"docker run\u003cbr/\u003e-v input:/data\u003cbr/\u003eInference container\"]\n        CWLRUN[\"cwltool inference.cwl\u003cbr/\u003erun_inference_input.yml\"]\n    end\n    \n    TRAINCODE --\u003e TRAINDOCKER\n    TRAINDEP --\u003e TRAINDOCKER\n    TRAINENV --\u003e TRAINDOCKER\n    TRAINDOCKER --\u003e TRAINRUN\n    \n    ONNXMODEL --\u003e INFERDOCKER\n    INFERCODE --\u003e INFERDOCKER\n    INFERDEP --\u003e INFERDOCKER\n    INFERDOCKER --\u003e INFERRUN\n    \n    ONNXMODEL --\u003e CWLFILE\n    CWLFILE --\u003e CWLTOOL\n    CWLINPUT --\u003e CWLTOOL\n    CWLTOOL --\u003e CWLRUN\n```\n\n**Packaging and Deployment Architecture**: This diagram shows three deployment strategies for the flood detection model: Docker containers for training, Docker containers for inference, and CWL workflows for standardized execution.\n\n**Sources:** [docs/design/scenarios/flood-example.md:53-63]()\n\n### Docker Container for Training\n\nBuild and run the training container:\n\n```bash\n# Build training image\ndocker build -f Dockerfile.train -t flood-model-train:latest .\n\n# Run training container\ndocker run --rm \\\n  -v $(pwd)/data:/app/data \\\n  -v $(pwd)/models:/app/models \\\n  --env-file .env \\\n  flood-model-train:latest\n```\n\nThe training Docker image encapsulates:\n- Python environment with Poetry dependencies\n- Training scripts and model architecture\n- MLflow client configuration\n- Data loading and preprocessing pipelines\n\nThis containerization enables reproducible training across different environments and facilitates deployment on cloud platforms or HPC clusters.\n\n**Sources:** [docs/design/scenarios/flood-example.md:54-57]()\n\n### Docker Container for Inference\n\nBuild and run the inference container:\n\n```bash\n# Build inference image with embedded ONNX model\ndocker build -f Dockerfile.inference \\\n  --build-arg MODEL_PATH=model.onnx \\\n  -t flood-model-inference:latest .\n\n# Run inference on sample data\ndocker run --rm \\\n  -v $(pwd)/input:/input \\\n  -v $(pwd)/output:/output \\\n  flood-model-inference:latest \\\n  /input/Pakistan_43105_S1Hand.tif\n```\n\nThe inference Docker image:\n- Embeds the ONNX model specified at build time\n- Includes minimal runtime dependencies (onnxruntime, rasterio)\n- Accepts input GeoTIFF files via volume mounts\n- Outputs prediction masks to the mounted output directory\n\n**Sources:** [docs/design/scenarios/flood-example.md:59-62]()\n\n## ML User Workflow\n\n```mermaid\ngraph LR\n    subgraph \"Discovery\"\n        SHBROWSE[\"Browse SharingHub\u003cbr/\u003esharinghub.develop.eoepca.org\"]\n        STACAPI[\"STAC API\u003cbr/\u003e/api/stac/v1\"]\n        DOWNLOAD[\"Download model.onnx\u003cbr/\u003efrom artifacts\"]\n    end\n    \n    subgraph \"CWL Preparation\"\n        CWLDEF[\"inference.cwl\u003cbr/\u003eWorkflow definition\"]\n        CWLPARAMS[\"run_inference_input.yml\u003cbr/\u003eInput: Pakistan_43105_S1Hand.tif\u003cbr/\u003eModel: model.onnx\"]\n    end\n    \n    subgraph \"Execution\"\n        CWLEXEC[\"cwltool inference.cwl\u003cbr/\u003erun_inference_input.yml\"]\n        RESULT[\"Output:\u003cbr/\u003epredictions/prediction.tif\"]\n    end\n    \n    SHBROWSE --\u003e STACAPI\n    STACAPI --\u003e DOWNLOAD\n    DOWNLOAD --\u003e CWLDEF\n    CWLDEF --\u003e CWLPARAMS\n    CWLPARAMS --\u003e CWLEXEC\n    CWLEXEC --\u003e RESULT\n```\n\n**ML User Workflow Diagram**: This diagram shows how ML Users consume the trained flood detection model via the STAC API and execute inference using CWL workflows.\n\n**Sources:** [docs/design/scenarios/flood-example.md:66-71]()\n\n### Downloading the Model via STAC API\n\nML Users can programmatically download the trained model:\n\n```python\nfrom pystac_client import Client\n\n# Connect to SharingHub STAC API\nclient = Client.open(\"https://sharinghub.develop.eoepca.org/api/stac/v1\")\n\n# Search for flood model\nsearch = client.search(\n    collections=[\"aimodel\"],\n    query={\"name\": {\"eq\": \"flood-model\"}}\n)\n\n# Get model item\nitem = next(search.get_items())\n\n# Download ONNX model asset\nonnx_asset = item.assets[\"model\"]\nonnx_url = onnx_asset.href\n# Download from onnx_url to local file\n```\n\nThe STAC API provides standardized access to model artifacts stored in MLflow's S3 backend. The model's STAC metadata is automatically linked when the ML Developer registers the model in the MLflow registry.\n\n**Sources:** [docs/design/scenarios/flood-example.md:68-70]()\n\n### Running CWL Workflow\n\nExecute the inference workflow using CWL:\n\n```bash\ncwltool inference.cwl run_inference_input.yml\n```\n\nThe `run_inference_input.yml` file contains:\n\n```yaml\ninput_image:\n  class: File\n  path: Pakistan_43105_S1Hand.tif\nmodel_file:\n  class: File\n  path: model.onnx\noutput_dir: predictions/\n```\n\nThe CWL workflow (`inference.cwl`):\n- Defines inputs (GeoTIFF image, ONNX model)\n- Specifies runtime requirements (Docker container, memory, CPU)\n- Executes the inference script\n- Collects outputs (prediction GeoTIFF)\n\nThis approach provides a standardized, portable way to execute the flood detection model across different execution environments (local workstations, cloud platforms, HPC clusters).\n\n**Sources:** [docs/design/scenarios/flood-example.md:68-71]()\n\n## Component Integration\n\n```mermaid\ngraph TB\n    subgraph \"Project Management\"\n        GL[\"GitLab\u003cbr/\u003egitlab.develop.eoepca.org\"]\n        FLOODPROJ[\"flood-model project\u003cbr/\u003eTopic: sharinghub:aimodel\u003cbr/\u003eTags: Image Segmentation\"]\n        DATAPROJ[\"sen1floods11-dataset\u003cbr/\u003eTopic: sharinghub:dataset\u003cbr/\u003eTags: Flood Detection\"]\n    end\n    \n    subgraph \"Discovery Layer\"\n        SH[\"SharingHub\u003cbr/\u003esharinghub.develop.eoepca.org\"]\n        STACCAT[\"STAC Catalog\u003cbr/\u003eCollections: aimodel, dataset\"]\n        STACFLOOD[\"STAC Item: flood-model\u003cbr/\u003eml-model extension\u003cbr/\u003eAssets: model.onnx\"]\n    end\n    \n    subgraph \"Experiment Tracking\"\n        MLF[\"MLflow SharingHub\u003cbr/\u003e/mlflow\"]\n        MLFRUNS[\"Experiments and Runs\u003cbr/\u003eMetrics, parameters, artifacts\"]\n        MLFREG[\"Model Registry\u003cbr/\u003eflood-model v1.0.0\"]\n    end\n    \n    subgraph \"Storage\"\n        S3[\"S3 Object Storage\"]\n        S3ARTIFACTS[\"MLflow artifacts:\u003cbr/\u003emodel.onnx, checkpoints\"]\n        S3DATA[\"DVC dataset files:\u003cbr/\u003eSentinel-1 imagery\"]\n    end\n    \n    GL --\u003e FLOODPROJ\n    GL --\u003e DATAPROJ\n    FLOODPROJ -.topic.-\u003e STACFLOOD\n    DATAPROJ -.topic.-\u003e STACCAT\n    \n    SH --\u003e STACCAT\n    STACCAT --\u003e STACFLOOD\n    \n    FLOODPROJ --\u003e MLF\n    MLF --\u003e MLFRUNS\n    MLFRUNS --\u003e MLFREG\n    MLFREG -.auto-link.-\u003e STACFLOOD\n    \n    MLFRUNS --\u003e S3ARTIFACTS\n    MLFREG --\u003e S3ARTIFACTS\n    DATAPROJ --\u003e S3DATA\n    \n    S3 --\u003e S3ARTIFACTS\n    S3 --\u003e S3DATA\n```\n\n**Component Integration Diagram**: This diagram shows how GitLab, SharingHub, MLflow SharingHub, and S3 storage interact to support the flood detection workflow, from project management through model discovery and deployment.\n\n**Sources:** [docs/design/scenarios/flood-example.md:1-72](), [docs/design/scenarios/model-training.md:1-53]()\n\n## Key Technical Details\n\n### Model Metadata\n\nThe flood-model project in GitLab contains metadata that appears in the STAC catalog:\n\n| Metadata Field | Value | Source |\n|----------------|-------|--------|\n| Topic | `sharinghub:aimodel` | GitLab project settings |\n| Tags | `Image Segmentation`, `Flood Detection` | GitLab project tags |\n| README content | Model description, usage instructions | `README.md` file |\n| STAC extensions | `ml-model` | Inferred from project topic |\n| Assets | `model.onnx`, training logs | MLflow artifacts |\n\n**Sources:** [docs/design/scenarios/flood-example.md:1-13]()\n\n### Dataset Versioning\n\nThe Sen1Floods11 dataset uses DVC for version control:\n\n- **Git metadata**: `.dvc` files tracking data versions\n- **S3 storage**: Actual imagery files (GeoTIFFs)\n- **DVC remote**: S3 bucket configured as remote storage\n- **Version control**: Dataset changes tracked via Git commits\n\nThe separation of metadata (Git) and data (S3) enables:\n- Lightweight Git repositories\n- Full dataset versioning\n- Efficient storage and bandwidth usage\n- Reproducible dataset snapshots\n\n**Sources:** [docs/design/scenarios/flood-example.md:34-39]()\n\n### MLflow Integration\n\nThe flood model training script integrates with MLflow:\n\n```python\nimport mlflow\n\n# Tracking URI from .env file\nmlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n\n# Create or use existing experiment\nmlflow.set_experiment(\"flood-model\")\n\n# Log training run\nwith mlflow.start_run():\n    # Log parameters\n    mlflow.log_param(\"learning_rate\", 0.001)\n    mlflow.log_param(\"batch_size\", 32)\n    \n    # Training loop with metric logging\n    for epoch in range(epochs):\n        loss = train_epoch()\n        mlflow.log_metric(\"loss\", loss, step=epoch)\n    \n    # Log model artifact\n    mlflow.onnx.log_model(onnx_model, \"model\")\n```\n\nMLflow SharingHub validates that the user has write access to the flood-model project in GitLab before accepting logged metrics and artifacts. This permission check ensures that only authorized ML Developers can modify experiment data.\n\n**Sources:** [docs/design/scenarios/model-training.md:35-45]()\n\n## Summary\n\nThe flood detection example demonstrates the complete MLOps workflow:\n\n1. **Discovery**: ML Developers find models and datasets via SharingHub's STAC catalog\n2. **Setup**: Clone repositories, configure environments, download datasets with DVC\n3. **Training**: Execute training scripts with MLflow tracking integration\n4. **Packaging**: Containerize models for reproducible deployment\n5. **Consumption**: ML Users download models via STAC API and execute with CWL workflows\n\nThis end-to-end workflow showcases how GitLab, SharingHub, and MLflow SharingHub work together to provide a comprehensive MLOps platform for Earth Observation applications.\n\n**Sources:** [docs/design/scenarios/flood-example.md:1-72](), [docs/design/scenarios/model-training.md:1-53]()"])</script><script>self.__next_f.push([1,"23:T490b,"])</script><script>self.__next_f.push([1,"# Deployment Guide\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/deployment-guide/components/gitlab.md](docs/admin/deployment-guide/components/gitlab.md)\n- [docs/admin/deployment-guide/intro.md](docs/admin/deployment-guide/intro.md)\n\n\u003c/details\u003e\n\n\n\nThis document provides a comprehensive guide for deploying the EOEPCA MLOps Building Block on a Kubernetes cluster. The deployment uses ArgoCD for GitOps-based continuous deployment and Helm charts for component packaging.\n\nThe MLOps Building Block consists of three core components that must be deployed in sequence: GitLab (for code and project management), SharingHub (for discovery and collaboration), and MLflow SharingHub (for experiment tracking and model registry). Each component is deployed in its own Kubernetes namespace with dedicated resources.\n\nFor detailed component-specific deployment instructions, see:\n- GitLab deployment: [GitLab Deployment](#5.2)\n- SharingHub deployment: [SharingHub Deployment](#5.3)\n- MLflow SharingHub deployment: [MLflow SharingHub Deployment](#5.4)\n\nFor prerequisites and deployment architecture details, see [Prerequisites and Architecture](#5.1).\n\n## Deployment Overview\n\nThe MLOps Building Block deployment follows a GitOps approach using ArgoCD to manage the lifecycle of all components. Each component is defined as an ArgoCD `Application` resource that references a Helm chart from either the official GitLab chart repository (`https://charts.gitlab.io`) or the CS Group OSS Helm repository (`https://csgroup-oss.github.io/charts`).\n\nThe deployment architecture consists of:\n\n| Component | Namespace | Chart Source | Version |\n|-----------|-----------|--------------|---------|\n| ArgoCD | `argocd` | ArgoCD Operator or Helm | Latest stable |\n| GitLab | `gitlab` | `gitlab/gitlab` | 8.1.0+ |\n| SharingHub | `sharinghub` | `csgroup-oss/sharinghub` | Latest |\n| MLflow SharingHub | `mlflow` | `csgroup-oss/mlflow-sharinghub` | Latest |\n| cert-manager | `cert-manager` | `jetstack/cert-manager` | v1.x |\n| NGINX Ingress | `ingress-nginx` | `ingress-nginx/ingress-nginx` | Latest |\n\n**Sources:** [docs/admin/deployment-guide/intro.md:1-15](), [docs/admin/deployment-guide/components/gitlab.md:120-125]()\n\n## Deployment Strategy\n\n### ArgoCD-Based GitOps\n\nThe deployment uses ArgoCD `Application` resources to declaratively manage component deployments. Each `Application` manifest defines:\n\n- `spec.destination.namespace`: Target Kubernetes namespace\n- `spec.destination.server`: Target cluster (typically `https://kubernetes.default.svc`)\n- `spec.source.repoURL`: Helm chart repository URL\n- `spec.source.chart`: Chart name\n- `spec.source.targetRevision`: Chart version\n- `spec.source.helm.valuesObject`: Helm values configuration\n- `spec.syncPolicy`: Automatic or manual sync policies\n\n**Deployment Flow**\n\n```mermaid\nsequenceDiagram\n    participant Admin as \"Administrator\"\n    participant kubectl as \"kubectl\"\n    participant ArgoCD as \"ArgoCD Controller\"\n    participant Helm as \"Helm Chart Repo\"\n    participant K8s as \"Kubernetes API\"\n    \n    Admin-\u003e\u003ekubectl: \"kubectl apply -f gitlab.yaml\"\n    kubectl-\u003e\u003eK8s: \"Create Application resource\"\n    K8s-\u003e\u003eArgoCD: \"Watch Application created\"\n    ArgoCD-\u003e\u003eHelm: \"Fetch gitlab chart v8.1.0\"\n    Helm--\u003e\u003eArgoCD: \"Chart templates + values\"\n    ArgoCD-\u003e\u003eK8s: \"Apply manifests to gitlab namespace\"\n    K8s--\u003e\u003eArgoCD: \"Resources created\"\n    ArgoCD-\u003e\u003eArgoCD: \"Monitor resource health\"\n    \n    Note over Admin,K8s: \"Repeat for sharinghub and mlflow-sharinghub\"\n```\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:105-240]()\n\n### Helm Charts and Values\n\nEach component uses Helm charts with custom `valuesObject` configurations embedded in the ArgoCD `Application` manifest. Key configuration areas include:\n\n**GitLab Helm Values** (`gitlab/gitlab` chart):\n- `global.hosts.domain`: Base domain for GitLab services\n- `global.ingress`: TLS and ingress controller settings\n- `global.minio.enabled: false`: Disable built-in MinIO, use external S3\n- `global.appConfig.omniauth`: OIDC authentication configuration\n- `global.appConfig.lfs`: Git LFS object storage configuration\n- `global.appConfig.backups`: S3 backup configuration\n\n**SharingHub Helm Values** (`csgroup-oss/sharinghub` chart):\n- `ingress.hosts[0].host`: SharingHub domain\n- `sharinghub.gitlabUrl`: GitLab instance URL\n- `sharinghub.stacApi.enabled: true`: Enable STAC API\n- `sharinghub.categories`: AI model, dataset, and processor collections\n- `sharinghub.s3Store`: S3 configuration for STAC assets\n\n**MLflow SharingHub Helm Values** (`csgroup-oss/mlflow-sharinghub` chart):\n- `mlflow.backendStoreUri`: PostgreSQL connection string\n- `mlflow.defaultArtifactRoot`: S3 artifact storage path\n- `mlflow.sharinghubUrl`: SharingHub instance URL\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:125-225]()\n\n## Component Dependencies\n\nThe components must be deployed in a specific order due to dependencies:\n\n```mermaid\ngraph TD\n    Prerequisites[\"Prerequisites\u003cbr/\u003e- Kubernetes cluster\u003cbr/\u003e- kubectl configured\u003cbr/\u003e- ArgoCD installed\u003cbr/\u003e- S3 buckets created\u003cbr/\u003e- Keycloak realm configured\"]\n    \n    Infrastructure[\"Infrastructure Components\u003cbr/\u003e- cert-manager namespace\u003cbr/\u003e- ingress-nginx namespace\u003cbr/\u003e- LetsEncrypt ClusterIssuer\"]\n    \n    GitLab[\"GitLab Deployment\u003cbr/\u003e- gitlab namespace\u003cbr/\u003e- storage-config Secret\u003cbr/\u003e- object-storage Secret\u003cbr/\u003e- openid-connect Secret\u003cbr/\u003e- gitlab Application\"]\n    \n    SharingHub[\"SharingHub Deployment\u003cbr/\u003e- sharinghub namespace\u003cbr/\u003e- sharinghub-oidc Secret\u003cbr/\u003e- sharinghub Application\"]\n    \n    MLflow[\"MLflow SharingHub Deployment\u003cbr/\u003e- mlflow namespace\u003cbr/\u003e- mlflow-postgresql Secret\u003cbr/\u003e- mlflow-s3 Secret\u003cbr/\u003e- mlflow-sharinghub Application\"]\n    \n    Prerequisites --\u003e Infrastructure\n    Infrastructure --\u003e GitLab\n    GitLab --\u003e SharingHub\n    SharingHub --\u003e MLflow\n```\n\n**Dependency Rationale:**\n\n1. **Infrastructure First**: cert-manager must be deployed before any component to provision TLS certificates. NGINX Ingress must exist to route traffic.\n\n2. **GitLab First**: SharingHub requires a GitLab instance to extract project metadata and authenticate users via OAuth.\n\n3. **SharingHub Before MLflow**: MLflow SharingHub delegates permission checks to SharingHub, requiring SharingHub to be operational first.\n\n**Sources:** [docs/admin/deployment-guide/intro.md:1-15]()\n\n## Kubernetes Resources Created\n\nEach component deployment creates a set of Kubernetes resources across namespaces:\n\n### GitLab Namespace Resources\n\n```mermaid\ngraph TB\n    subgraph \"gitlab namespace\"\n        App1[\"Application\u003cbr/\u003egitlab.argocd\"]\n        \n        Secrets[\"Secrets\u003cbr/\u003e- storage-config\u003cbr/\u003e- object-storage\u003cbr/\u003e- openid-connect\u003cbr/\u003e- gitlab-postgresql\u003cbr/\u003e- gitlab-redis\"]\n        \n        Deployments[\"Deployments\u003cbr/\u003e- gitlab-webservice\u003cbr/\u003e- gitlab-sidekiq\u003cbr/\u003e- gitlab-kas\u003cbr/\u003e- gitlab-toolbox\"]\n        \n        StatefulSets[\"StatefulSets\u003cbr/\u003e- gitlab-postgresql\u003cbr/\u003e- gitlab-redis-master\"]\n        \n        Services[\"Services\u003cbr/\u003e- gitlab-webservice\u003cbr/\u003e- gitlab-kas\u003cbr/\u003e- gitlab-postgresql\u003cbr/\u003e- gitlab-redis\"]\n        \n        Ingress[\"Ingress\u003cbr/\u003e- gitlab-webservice\u003cbr/\u003eTLS: gitlab.domain-tls\u003cbr/\u003e- gitlab-kas\u003cbr/\u003eTLS: kas.domain-tls\"]\n        \n        PVCs[\"PersistentVolumeClaims\u003cbr/\u003e- gitlab-postgresql\u003cbr/\u003e- gitlab-redis\"]\n    end\n    \n    App1 --\u003e Secrets\n    App1 --\u003e Deployments\n    App1 --\u003e StatefulSets\n    App1 --\u003e Services\n    App1 --\u003e Ingress\n    App1 --\u003e PVCs\n    \n    Secrets -.mounted by.-\u003e Deployments\n    Services --\u003e Deployments\n    Services --\u003e StatefulSets\n    Ingress --\u003e Services\n    PVCs --\u003e StatefulSets\n```\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:169-199]()\n\n### SharingHub Namespace Resources\n\n```mermaid\ngraph TB\n    subgraph \"sharinghub namespace\"\n        App2[\"Application\u003cbr/\u003esharinghub.argocd\"]\n        \n        Secrets2[\"Secrets\u003cbr/\u003e- sharinghub-oidc\u003cbr/\u003e- sharinghub-s3\"]\n        \n        Deployment2[\"Deployment\u003cbr/\u003e- sharinghub\"]\n        \n        Service2[\"Service\u003cbr/\u003e- sharinghub\"]\n        \n        Ingress2[\"Ingress\u003cbr/\u003e- sharinghub\u003cbr/\u003eTLS: sharinghub.domain-tls\u003cbr/\u003ePaths: /, /api/stac/*\"]\n        \n        ConfigMap2[\"ConfigMap\u003cbr/\u003e- sharinghub-config\"]\n    end\n    \n    App2 --\u003e Secrets2\n    App2 --\u003e Deployment2\n    App2 --\u003e Service2\n    App2 --\u003e Ingress2\n    App2 --\u003e ConfigMap2\n    \n    Secrets2 -.mounted by.-\u003e Deployment2\n    ConfigMap2 -.mounted by.-\u003e Deployment2\n    Service2 --\u003e Deployment2\n    Ingress2 --\u003e Service2\n```\n\n### MLflow Namespace Resources\n\n```mermaid\ngraph TB\n    subgraph \"mlflow namespace\"\n        App3[\"Application\u003cbr/\u003emlflow-sharinghub.argocd\"]\n        \n        Secrets3[\"Secrets\u003cbr/\u003e- mlflow-postgresql\u003cbr/\u003e- mlflow-s3\u003cbr/\u003e- mlflow-sharinghub\"]\n        \n        Deployment3[\"Deployment\u003cbr/\u003e- mlflow-sharinghub\"]\n        \n        StatefulSet3[\"StatefulSet\u003cbr/\u003e- mlflow-postgresql\"]\n        \n        Services3[\"Services\u003cbr/\u003e- mlflow-sharinghub\u003cbr/\u003e- mlflow-postgresql\"]\n        \n        Ingress3[\"Ingress\u003cbr/\u003e- mlflow-sharinghub\u003cbr/\u003eTLS: sharinghub.domain-tls\u003cbr/\u003ePath: /mlflow/*\"]\n        \n        PVC3[\"PersistentVolumeClaim\u003cbr/\u003e- mlflow-postgresql\"]\n    end\n    \n    App3 --\u003e Secrets3\n    App3 --\u003e Deployment3\n    App3 --\u003e StatefulSet3\n    App3 --\u003e Services3\n    App3 --\u003e Ingress3\n    App3 --\u003e PVC3\n    \n    Secrets3 -.mounted by.-\u003e Deployment3\n    Services3 --\u003e Deployment3\n    Services3 --\u003e StatefulSet3\n    Ingress3 --\u003e Services3\n    PVC3 --\u003e StatefulSet3\n```\n\n**Sources:** Based on standard Kubernetes patterns for Helm deployments and ArgoCD structure.\n\n## External Dependencies\n\nAll components require access to external services that must be provisioned before deployment:\n\n### S3 Object Storage\n\nEach component requires dedicated S3 buckets:\n\n| Component | Bucket Purpose | Bucket Name Example | Required |\n|-----------|----------------|---------------------|----------|\n| GitLab | Backup storage | `gitlab-backup-storage` | Yes |\n| GitLab | Temporary storage | `gitlab-tmp-storage` | Yes |\n| GitLab | Git LFS objects | `gitlab-lfs-storage` | Optional |\n| SharingHub | STAC assets | `sharinghub-assets` | Yes |\n| MLflow | Model artifacts | `mlflow-artifacts` | Yes |\n\nS3 credentials are stored in Kubernetes `Secret` resources:\n- `storage-config` in `gitlab` namespace: S3cmd format configuration\n- `object-storage` in `gitlab` namespace: YAML format for LFS\n- `sharinghub-s3` in `sharinghub` namespace: S3 endpoint and credentials\n- `mlflow-s3` in `mlflow` namespace: AWS-style credentials\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:16-66]()\n\n### Keycloak OIDC Provider\n\nComponents authenticate users through Keycloak OIDC:\n\n| Component | Client ID | Redirect URI | Secret Name |\n|-----------|-----------|--------------|-------------|\n| GitLab | `gitlab` | `https://gitlab.domain/users/auth/openid_connect/callback` | `openid-connect` |\n| SharingHub | `sharinghub` | `https://sharinghub.domain/oauth/callback` | `sharinghub-oidc` |\n\nThe OIDC configuration includes:\n- `issuer`: Keycloak realm URL (`https://keycloak.domain/realms/eoepca`)\n- `scope`: `[\"openid\", \"profile\", \"email\"]`\n- `response_type`: `\"code\"`\n- `pkce`: `true` (for enhanced security)\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:68-103]()\n\n### TLS Certificate Management\n\nAll Ingress resources use cert-manager to automatically provision Let's Encrypt certificates:\n\n```yaml\ningress:\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n  tls:\n    - secretName: gitlab.domain-tls\n      hosts:\n        - gitlab.domain\n```\n\nThe `cert-manager.io/cluster-issuer` annotation references a `ClusterIssuer` resource that must exist before deployment. The certificate is stored in a Kubernetes `Secret` with name pattern `\u003chostname\u003e-tls`.\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:132-178]()\n\n## Deployment Process Overview\n\nThe complete deployment process follows these steps:\n\n**1. Prepare Prerequisites**\n- Provision Kubernetes cluster\n- Install ArgoCD\n- Install cert-manager and create `ClusterIssuer`\n- Install NGINX Ingress Controller\n- Create S3 buckets\n- Configure Keycloak realm and clients\n\nSee [Prerequisites and Architecture](#5.1) for details.\n\n**2. Deploy GitLab**\n- Create `gitlab` namespace\n- Create S3 configuration `Secret` resources (`storage-config`, `object-storage`)\n- Create OIDC provider `Secret` resource (`openid-connect`)\n- Apply GitLab ArgoCD `Application` manifest\n- Wait for GitLab to become healthy\n- Configure GitLab root user and create OAuth applications\n\nSee [GitLab Deployment](#5.2) for step-by-step instructions.\n\n**3. Deploy SharingHub**\n- Create `sharinghub` namespace\n- Create OIDC client `Secret` resource (`sharinghub-oidc`)\n- Create S3 configuration `Secret` resource (if using S3 store)\n- Apply SharingHub ArgoCD `Application` manifest\n- Configure STAC categories and tags\n- Verify STAC API accessibility\n\nSee [SharingHub Deployment](#5.3) for detailed configuration.\n\n**4. Deploy MLflow SharingHub**\n- Create `mlflow` namespace\n- Create PostgreSQL `Secret` resource\n- Create S3 configuration `Secret` resource\n- Create SharingHub integration `Secret` resource\n- Apply MLflow SharingHub ArgoCD `Application` manifest\n- Verify MLflow UI accessibility and experiment tracking\n\nSee [MLflow SharingHub Deployment](#5.4) for configuration details.\n\n**Sources:** [docs/admin/deployment-guide/intro.md:1-15](), [docs/admin/deployment-guide/components/gitlab.md:6-11]()\n\n## Ingress and URL Structure\n\nAll components are exposed through NGINX Ingress with the following URL structure:\n\n```mermaid\ngraph LR\n    Internet[\"Internet Traffic\"]\n    \n    NGINX[\"NGINX Ingress Controller\u003cbr/\u003eingress-nginx namespace\"]\n    \n    GitLabIngress[\"gitlab-webservice Ingress\u003cbr/\u003eHost: gitlab.domain\u003cbr/\u003ePath: /\u003cbr/\u003eTLS: gitlab.domain-tls\"]\n    \n    KasIngress[\"gitlab-kas Ingress\u003cbr/\u003eHost: kas.domain\u003cbr/\u003ePath: /\u003cbr/\u003eTLS: kas.domain-tls\"]\n    \n    SHIngress[\"sharinghub Ingress\u003cbr/\u003eHost: sharinghub.domain\u003cbr/\u003ePaths: /, /api/stac/*\u003cbr/\u003eTLS: sharinghub.domain-tls\"]\n    \n    MLFIngress[\"mlflow-sharinghub Ingress\u003cbr/\u003eHost: sharinghub.domain\u003cbr/\u003ePath: /mlflow/*\u003cbr/\u003eTLS: sharinghub.domain-tls\"]\n    \n    GitLabSvc[\"gitlab-webservice Service\u003cbr/\u003egitlab namespace\"]\n    KasSvc[\"gitlab-kas Service\u003cbr/\u003egitlab namespace\"]\n    SHSvc[\"sharinghub Service\u003cbr/\u003esharinghub namespace\"]\n    MLFSvc[\"mlflow-sharinghub Service\u003cbr/\u003emlflow namespace\"]\n    \n    Internet --\u003e NGINX\n    NGINX --\u003e GitLabIngress\n    NGINX --\u003e KasIngress\n    NGINX --\u003e SHIngress\n    NGINX --\u003e MLFIngress\n    \n    GitLabIngress --\u003e GitLabSvc\n    KasIngress --\u003e KasSvc\n    SHIngress --\u003e SHSvc\n    MLFIngress --\u003e MLFSvc\n```\n\n**URL Endpoints:**\n\n| Service | URL | Purpose |\n|---------|-----|---------|\n| GitLab Web UI | `https://gitlab.domain/` | GitLab web interface, project management |\n| GitLab KAS | `wss://kas.domain/` | GitLab Agent Server for Kubernetes integration |\n| SharingHub Web UI | `https://sharinghub.domain/` | Discovery and collaboration interface |\n| SharingHub STAC API | `https://sharinghub.domain/api/stac/` | STAC catalog API endpoints |\n| MLflow UI | `https://sharinghub.domain/mlflow/` | Experiment tracking and model registry UI |\n| MLflow Tracking API | `https://sharinghub.domain/mlflow/` | MLflow client tracking API |\n\nNote that both SharingHub and MLflow SharingHub share the same domain (`sharinghub.domain`) but use different paths. This allows unified access under a single domain with shared TLS certificate.\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:169-193]()\n\n## ArgoCD Application Structure\n\nEach component is managed by an ArgoCD `Application` resource in the `argocd` namespace:\n\n```mermaid\ngraph TB\n    subgraph \"argocd namespace\"\n        GitLabApp[\"Application\u003cbr/\u003ename: gitlab\u003cbr/\u003echart: gitlab/gitlab:8.1.0\"]\n        SHApp[\"Application\u003cbr/\u003ename: sharinghub\u003cbr/\u003echart: csgroup-oss/sharinghub\"]\n        MLFApp[\"Application\u003cbr/\u003ename: mlflow-sharinghub\u003cbr/\u003echart: csgroup-oss/mlflow-sharinghub\"]\n    end\n    \n    subgraph \"Target Namespaces\"\n        GitLabNS[\"gitlab namespace\u003cbr/\u003eAll GitLab resources\"]\n        SHNS[\"sharinghub namespace\u003cbr/\u003eAll SharingHub resources\"]\n        MLFNS[\"mlflow namespace\u003cbr/\u003eAll MLflow resources\"]\n    end\n    \n    subgraph \"Helm Chart Repositories\"\n        GitLabRepo[\"https://charts.gitlab.io\"]\n        CSGroupRepo[\"https://csgroup-oss.github.io/charts\"]\n    end\n    \n    GitLabApp --\u003e GitLabNS\n    SHApp --\u003e SHNS\n    MLFApp --\u003e MLFNS\n    \n    GitLabApp -.fetch chart.-\u003e GitLabRepo\n    SHApp -.fetch chart.-\u003e CSGroupRepo\n    MLFApp -.fetch chart.-\u003e CSGroupRepo\n```\n\nThe `spec.syncPolicy` in each `Application` defines synchronization behavior:\n\n```yaml\nsyncPolicy:\n  syncOptions:\n    - FailOnSharedResource=true  # Prevent resource conflicts\n    - CreateNamespace=true       # Auto-create target namespace\n```\n\n**Sources:** [docs/admin/deployment-guide/components/gitlab.md:109-230]()\n\n## Verification and Health Checks\n\nAfter deploying each component, verify health using ArgoCD and kubectl:\n\n**ArgoCD Health Status:**\n```bash\nkubectl get applications -n argocd\n```\n\nExpected output:\n```\nNAME                 SYNC STATUS   HEALTH STATUS\ngitlab               Synced        Healthy\nsharinghub           Synced        Healthy\nmlflow-sharinghub    Synced        Healthy\n```\n\n**Pod Status by Namespace:**\n```bash\nkubectl get pods -n gitlab\nkubectl get pods -n sharinghub\nkubectl get pods -n mlflow\n```\n\nAll pods should show `Running` status with `READY` count matching container count.\n\n**Ingress Verification:**\n```bash\nkubectl get ingress -A\n```\n\nAll Ingress resources should show hostnames and addresses assigned.\n\n**TLS Certificate Status:**\n```bash\nkubectl get certificates -A\n```\n\nAll `Certificate` resources should show `READY: True`.\n\n**Sources:** Standard Kubernetes and ArgoCD verification procedures.\n\n## Next Steps\n\nProceed to the detailed deployment instructions for each component:\n\n1. **[Prerequisites and Architecture](#5.1)**: Review Kubernetes requirements, ArgoCD setup, and deployment architecture details.\n\n2. **[GitLab Deployment](#5.2)**: Deploy GitLab with S3 object storage, Git LFS support, and Keycloak OIDC integration.\n\n3. **[SharingHub Deployment](#5.3)**: Deploy SharingHub with STAC catalog, GitLab OAuth integration, and category/tag configuration.\n\n4. **[MLflow SharingHub Deployment](#5.4)**: Deploy MLflow with PostgreSQL backend, S3 artifacts storage, and SharingHub permission integration.\n\nFor configuration details, see [Configuration Reference](#6). For operational maintenance, see [Operations and Maintenance](#8).\n\n**Sources:** [docs/admin/deployment-guide/intro.md:1-15]()"])</script><script>self.__next_f.push([1,"24:T5e01,"])</script><script>self.__next_f.push([1,"# Prerequisites and Architecture\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/deployment-guide/components/gitlab.md](docs/admin/deployment-guide/components/gitlab.md)\n- [docs/admin/deployment-guide/intro.md](docs/admin/deployment-guide/intro.md)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis page describes the prerequisites and deployment architecture for the EOEPCA MLOps Building Block. It covers the Kubernetes infrastructure requirements, external service dependencies, and the ArgoCD-based GitOps deployment model used to install GitLab, SharingHub, and MLflow SharingHub components.\n\nFor step-by-step deployment instructions for each component, see [GitLab Deployment](#5.2), [SharingHub Deployment](#5.3), and [MLflow SharingHub Deployment](#5.4). For configuration details, see the [Configuration Reference](#6).\n\nSources: [docs/admin/deployment-guide/intro.md](), [docs/admin/deployment-guide/components/gitlab.md:1-15]()\n\n---\n\n## Prerequisites\n\n### Kubernetes Cluster\n\nA functional Kubernetes cluster is required with the following characteristics:\n\n| Requirement | Description |\n|-------------|-------------|\n| **Kubernetes Version** | 1.23+ recommended |\n| **Cluster Access** | `kubectl` access with cluster-admin privileges |\n| **Namespace Creation** | Ability to create namespaces for component isolation |\n| **Resource Capacity** | Sufficient CPU, memory, and storage for GitLab, SharingHub, and MLflow workloads |\n| **Persistent Volumes** | Dynamic volume provisioning for PostgreSQL databases |\n\n### Required Tools\n\nThe following command-line tools must be installed on the deployment machine:\n\n- **kubectl** - Kubernetes command-line tool for cluster management\n- **helm** (optional) - Package manager for Kubernetes, useful for testing configurations\n- **argocd CLI** (optional) - ArgoCD command-line interface for application management\n\n### External Services\n\n#### S3-Compatible Object Storage\n\nS3-compatible storage is required for GitLab backups, temporary storage, and optionally for Git LFS. The following buckets must be created before deployment:\n\n| Bucket Name | Purpose | Required For |\n|-------------|---------|--------------|\n| `gitlab-backup-storage` | GitLab backup storage | GitLab |\n| `gitlab-tmp-storage` | GitLab temporary files | GitLab |\n| `gitlab-lfs-storage` | Git Large File Storage | GitLab (optional) |\n| `mlflow-artifacts` | MLflow experiment artifacts and models | MLflow SharingHub |\n| `sharinghub-assets` | SharingHub cached assets | SharingHub (optional) |\n\nAccess credentials (access key, secret key, endpoint URL) for the S3 provider must be available during deployment.\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:16-20](), [docs/admin/deployment-guide/components/gitlab.md:42-43]()\n\n#### Keycloak Identity Provider (Optional)\n\nIf Single Sign-On (SSO) authentication is desired, a Keycloak instance with the following configuration is required:\n\n- A configured realm (e.g., `eoepca`)\n- OIDC client created for GitLab with client ID `gitlab`\n- Callback URL configured: `https://gitlab.\u003cdomain\u003e/users/auth/openid_connect/callback`\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:68-92]()\n\n### Infrastructure Services\n\nThe following services must be deployed in the Kubernetes cluster before deploying the MLOps components:\n\n#### NGINX Ingress Controller\n\nAn NGINX Ingress Controller must be installed to handle external HTTP/HTTPS traffic routing to the MLOps components.\n\n#### cert-manager\n\nThe `cert-manager` controller must be deployed to automate TLS certificate provisioning and renewal. A ClusterIssuer named `letsencrypt-prod` should be configured to issue certificates from Let's Encrypt.\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:131-135]()\n\n---\n\n## Deployment Architecture\n\n### GitOps with ArgoCD\n\nThe MLOps Building Block uses a **GitOps deployment model** managed by ArgoCD. Each component (GitLab, SharingHub, MLflow SharingHub) is deployed as an ArgoCD `Application` resource that continuously reconciles the desired state from Helm charts.\n\n```mermaid\ngraph TB\n    subgraph \"ArgoCD Control Plane\"\n        ARGOCD[\"ArgoCD Server\u003cbr/\u003e(argocd namespace)\"]\n        APPGL[\"Application: gitlab\u003cbr/\u003e(argocd namespace)\"]\n        APPSH[\"Application: sharinghub\u003cbr/\u003e(argocd namespace)\"]\n        APPMLF[\"Application: mlflow-sharinghub\u003cbr/\u003e(argocd namespace)\"]\n    end\n    \n    subgraph \"Helm Chart Repositories\"\n        GLCHART[\"charts.gitlab.io\u003cbr/\u003eChart: gitlab v8.1.0\"]\n        SHCHART[\"csgroup-oss helm repo\u003cbr/\u003eChart: sharinghub\"]\n        MLFCHART[\"csgroup-oss helm repo\u003cbr/\u003eChart: mlflow-sharinghub\"]\n    end\n    \n    subgraph \"Deployed Components\"\n        GLNS[\"gitlab namespace\u003cbr/\u003ePods, Services, ConfigMaps\"]\n        SHNS[\"sharinghub namespace\u003cbr/\u003ePods, Services, ConfigMaps\"]\n        MLFNS[\"mlflow namespace\u003cbr/\u003ePods, Services, ConfigMaps\"]\n    end\n    \n    ARGOCD --\u003e APPGL\n    ARGOCD --\u003e APPSH\n    ARGOCD --\u003e APPMLF\n    \n    APPGL --\u003e GLCHART\n    APPSH --\u003e SHCHART\n    APPMLF --\u003e MLFCHART\n    \n    APPGL --\u003e GLNS\n    APPSH --\u003e SHNS\n    APPMLF --\u003e MLFNS\n```\n\n**ArgoCD-Based Deployment Flow**\n\nEach component is deployed by:\n1. Creating an ArgoCD `Application` manifest in the `argocd` namespace\n2. Specifying the Helm chart repository and version\n3. Providing Helm values configuration in `spec.source.helm.valuesObject`\n4. ArgoCD automatically syncs the desired state to the cluster\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:107-230]()\n\n---\n\n### Namespace Architecture\n\nThe deployment follows a **multi-namespace architecture** for component isolation:\n\n| Namespace | Components | Purpose |\n|-----------|------------|---------|\n| `argocd` | ArgoCD Application resources | GitOps control plane |\n| `gitlab` | GitLab pods, PostgreSQL, Redis, secrets | Code repository and CI/CD platform |\n| `sharinghub` | SharingHub pod, secrets | Discovery and collaboration platform |\n| `mlflow` | MLflow pod, PostgreSQL, secrets | Experiment tracking and model registry |\n| `cert-manager` | cert-manager controller | TLS certificate automation |\n| `ingress-nginx` | NGINX Ingress Controller | HTTP/HTTPS traffic routing |\n\n```mermaid\ngraph TB\n    subgraph K8s[\"Kubernetes Cluster\"]\n        subgraph NS_ARGOCD[\"Namespace: argocd\"]\n            APP_GL[\"Application: gitlab\"]\n            APP_SH[\"Application: sharinghub\"]\n            APP_MLF[\"Application: mlflow-sharinghub\"]\n        end\n        \n        subgraph NS_GITLAB[\"Namespace: gitlab\"]\n            GL_WEB[\"Deployment: gitlab-webservice\"]\n            GL_SIDEKIQ[\"Deployment: gitlab-sidekiq\"]\n            GL_KAS[\"Deployment: gitlab-kas\"]\n            GL_PG[\"StatefulSet: gitlab-postgresql\"]\n            GL_REDIS[\"Deployment: gitlab-redis\"]\n            SECRET_GL_OIDC[\"Secret: openid-connect\"]\n            SECRET_GL_STORAGE[\"Secret: storage-config\"]\n            SECRET_GL_LFS[\"Secret: object-storage\"]\n        end\n        \n        subgraph NS_SH[\"Namespace: sharinghub\"]\n            SH_POD[\"Deployment: sharinghub\"]\n            SECRET_SH_OIDC[\"Secret: sharinghub-oidc\"]\n        end\n        \n        subgraph NS_MLF[\"Namespace: mlflow\"]\n            MLF_POD[\"Deployment: mlflow-sharinghub\"]\n            MLF_PG[\"StatefulSet: mlflow-postgresql\"]\n            SECRET_MLF_KEY[\"Secret: mlflow-sharinghub\"]\n        end\n        \n        subgraph NS_CERT[\"Namespace: cert-manager\"]\n            CERT_MGR[\"Deployment: cert-manager\"]\n            ISSUER[\"ClusterIssuer: letsencrypt-prod\"]\n        end\n        \n        subgraph NS_INGRESS[\"Namespace: ingress-nginx\"]\n            NGINX[\"Deployment: ingress-nginx-controller\"]\n        end\n    end\n    \n    APP_GL -.deploys.-\u003e GL_WEB\n    APP_GL -.deploys.-\u003e GL_SIDEKIQ\n    APP_SH -.deploys.-\u003e SH_POD\n    APP_MLF -.deploys.-\u003e MLF_POD\n    \n    GL_WEB --\u003e SECRET_GL_OIDC\n    GL_WEB --\u003e SECRET_GL_STORAGE\n    SH_POD --\u003e SECRET_SH_OIDC\n    MLF_POD --\u003e SECRET_MLF_KEY\n    \n    NGINX --\u003e CERT_MGR\n```\n\n**Namespace Isolation Benefits:**\n- **Security**: Secrets and resources are isolated per namespace\n- **Resource Management**: Resource quotas and limits can be applied per namespace\n- **Access Control**: RBAC policies can be scoped to specific namespaces\n- **Organization**: Clear separation of component responsibilities\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:35-36]()\n\n---\n\n### Kubernetes Secret Management\n\nSensitive configuration data is stored in Kubernetes `Secret` resources created before deploying the ArgoCD Applications:\n\n#### GitLab Namespace Secrets\n\n| Secret Name | Keys | Purpose |\n|-------------|------|---------|\n| `storage-config` | `config` | S3 credentials for GitLab backups (s3cmd format) |\n| `object-storage` | `connection` | S3 credentials for Git LFS (YAML format) |\n| `openid-connect` | `provider` | Keycloak OIDC configuration |\n\nCreation example for `storage-config`:\n\n```bash\nkubectl create ns gitlab\nkubectl create secret generic storage-config \\\n  --from-file=config=storage.config -n gitlab\n```\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:21-37](), [docs/admin/deployment-guide/components/gitlab.md:60-64](), [docs/admin/deployment-guide/components/gitlab.md:94-98]()\n\n#### SharingHub Namespace Secrets\n\nSecrets for SharingHub OIDC authentication and optional default access tokens are created in the `sharinghub` namespace (documented in [SharingHub Deployment](#5.3)).\n\n#### MLflow Namespace Secrets\n\nSecrets for MLflow SharingHub integration and database credentials are created in the `mlflow` namespace (documented in [MLflow SharingHub Deployment](#5.4)).\n\n---\n\n### Ingress and TLS Architecture\n\nAll external traffic is routed through the NGINX Ingress Controller with automated TLS certificate management:\n\n```mermaid\ngraph LR\n    subgraph \"External Access\"\n        USER[\"End User\"]\n        DNS[\"DNS Resolution\"]\n    end\n    \n    subgraph \"Ingress Layer\"\n        NGINX[\"NGINX Ingress Controller\u003cbr/\u003e(ingress-nginx namespace)\"]\n        \n        ING_GL[\"Ingress: gitlab-webservice\u003cbr/\u003eHost: gitlab.domain\"]\n        ING_KAS[\"Ingress: gitlab-kas\u003cbr/\u003eHost: kas.domain\"]\n        ING_SH[\"Ingress: sharinghub\u003cbr/\u003eHost: sharinghub.domain\"]\n        ING_MLF[\"Ingress: mlflow-sharinghub\u003cbr/\u003ePath: /mlflow\"]\n    end\n    \n    subgraph \"TLS Certificate Management\"\n        CERT[\"cert-manager\u003cbr/\u003e(cert-manager namespace)\"]\n        ISSUER[\"ClusterIssuer: letsencrypt-prod\"]\n        \n        TLS_GL[\"Secret: gitlab.domain-tls\"]\n        TLS_KAS[\"Secret: kas.domain-tls\"]\n        TLS_SH[\"Secret: sharinghub.domain-tls\"]\n    end\n    \n    subgraph \"Backend Services\"\n        SVC_GL[\"Service: gitlab-webservice\u003cbr/\u003e(gitlab namespace)\"]\n        SVC_KAS[\"Service: gitlab-kas\u003cbr/\u003e(gitlab namespace)\"]\n        SVC_SH[\"Service: sharinghub\u003cbr/\u003e(sharinghub namespace)\"]\n        SVC_MLF[\"Service: mlflow-sharinghub\u003cbr/\u003e(mlflow namespace)\"]\n    end\n    \n    USER --\u003e DNS\n    DNS --\u003e NGINX\n    \n    NGINX --\u003e ING_GL\n    NGINX --\u003e ING_KAS\n    NGINX --\u003e ING_SH\n    NGINX --\u003e ING_MLF\n    \n    ING_GL --\u003e TLS_GL\n    ING_KAS --\u003e TLS_KAS\n    ING_SH --\u003e TLS_SH\n    \n    CERT --\u003e ISSUER\n    CERT --\u003e TLS_GL\n    CERT --\u003e TLS_KAS\n    CERT --\u003e TLS_SH\n    \n    ING_GL --\u003e SVC_GL\n    ING_KAS --\u003e SVC_KAS\n    ING_SH --\u003e SVC_SH\n    ING_MLF --\u003e SVC_MLF\n```\n\n**TLS Certificate Automation:**\n1. Each `Ingress` resource includes `cert-manager.io/cluster-issuer: letsencrypt-prod` annotation\n2. cert-manager detects the annotation and requests a certificate from Let's Encrypt\n3. Certificate is stored in a Kubernetes `Secret` (e.g., `gitlab.domain-tls`)\n4. NGINX Ingress Controller uses the secret for TLS termination\n5. cert-manager automatically renews certificates before expiration\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:131-135](), [docs/admin/deployment-guide/components/gitlab.md:170-198]()\n\n---\n\n### External Dependencies\n\nThe deployed components interact with external services outside the Kubernetes cluster:\n\n```mermaid\ngraph TB\n    subgraph \"Kubernetes Cluster\"\n        GL[\"GitLab\u003cbr/\u003e(gitlab namespace)\"]\n        SH[\"SharingHub\u003cbr/\u003e(sharinghub namespace)\"]\n        MLF[\"MLflow SharingHub\u003cbr/\u003e(mlflow namespace)\"]\n    end\n    \n    subgraph \"External S3 Storage\"\n        S3_GL_BACKUP[\"S3 Bucket:\u003cbr/\u003egitlab-backup-storage\"]\n        S3_GL_TMP[\"S3 Bucket:\u003cbr/\u003egitlab-tmp-storage\"]\n        S3_GL_LFS[\"S3 Bucket:\u003cbr/\u003egitlab-lfs-storage\"]\n        S3_MLF[\"S3 Bucket:\u003cbr/\u003emlflow-artifacts\"]\n    end\n    \n    subgraph \"External Identity Provider\"\n        KC[\"Keycloak IdP\u003cbr/\u003eOIDC Provider\"]\n        KC_REALM[\"Realm: eoepca\"]\n        KC_CLIENT_GL[\"Client: gitlab\"]\n    end\n    \n    subgraph \"External Certificate Authority\"\n        LE[\"Let's Encrypt CA\u003cbr/\u003eACME Protocol\"]\n    end\n    \n    GL --\u003e|\"Backups\"| S3_GL_BACKUP\n    GL --\u003e|\"Temporary files\"| S3_GL_TMP\n    GL --\u003e|\"Git LFS objects\"| S3_GL_LFS\n    \n    MLF --\u003e|\"Experiment artifacts\u003cbr/\u003eModel files\"| S3_MLF\n    \n    GL --\u003e|\"OIDC authentication\"| KC\n    SH --\u003e|\"OIDC authentication\"| KC\n    KC --\u003e KC_REALM\n    KC_REALM --\u003e KC_CLIENT_GL\n    \n    CERT[\"cert-manager\"] --\u003e|\"Certificate requests\"| LE\n```\n\n**External Service Requirements:**\n\n| Service | Protocol | Purpose | Configuration |\n|---------|----------|---------|---------------|\n| S3 Storage | HTTPS | Persistent storage for artifacts, backups, and LFS | Access key, secret key, endpoint URL, bucket names |\n| Keycloak | HTTPS | OIDC-based authentication (optional) | Issuer URL, client ID, client secret |\n| Let's Encrypt | ACME | TLS certificate issuance | Email address for certificate notifications |\n| Helm Repositories | HTTPS | Helm chart retrieval | `charts.gitlab.io`, csgroup-oss repository |\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:16-39](), [docs/admin/deployment-guide/components/gitlab.md:68-92]()\n\n---\n\n## Component Deployment Order\n\nComponents should be deployed in the following order to satisfy dependencies:\n\n```mermaid\ngraph TD\n    PREREQ[\"1. Prerequisites\u003cbr/\u003e- Kubernetes cluster\u003cbr/\u003e- kubectl access\u003cbr/\u003e- S3 buckets created\"]\n    INFRA[\"2. Infrastructure Services\u003cbr/\u003e- NGINX Ingress Controller\u003cbr/\u003e- cert-manager\u003cbr/\u003e- ArgoCD\"]\n    SECRETS[\"3. Create Kubernetes Secrets\u003cbr/\u003e- storage-config (gitlab ns)\u003cbr/\u003e- object-storage (gitlab ns)\u003cbr/\u003e- openid-connect (gitlab ns)\"]\n    GITLAB[\"4. Deploy GitLab\u003cbr/\u003eApply Application manifest\u003cbr/\u003eWait for pods ready\"]\n    SHARINGHUB[\"5. Deploy SharingHub\u003cbr/\u003eConfigure GitLab integration\u003cbr/\u003eApply Application manifest\"]\n    MLFLOW[\"6. Deploy MLflow SharingHub\u003cbr/\u003eConfigure SharingHub integration\u003cbr/\u003eApply Application manifest\"]\n    VERIFY[\"7. Verify Deployment\u003cbr/\u003e- Check pod status\u003cbr/\u003e- Test web UIs\u003cbr/\u003e- Verify integration\"]\n    \n    PREREQ --\u003e INFRA\n    INFRA --\u003e SECRETS\n    SECRETS --\u003e GITLAB\n    GITLAB --\u003e SHARINGHUB\n    SHARINGHUB --\u003e MLFLOW\n    MLFLOW --\u003e VERIFY\n```\n\n**Rationale for Deployment Order:**\n\n1. **Infrastructure First**: NGINX and cert-manager must exist before deploying components that create Ingress resources\n2. **GitLab Foundation**: GitLab must be deployed before SharingHub since SharingHub integrates with GitLab for project discovery\n3. **SharingHub Before MLflow**: MLflow SharingHub delegates permission checks to SharingHub, requiring SharingHub to be operational first\n\nSources: [docs/admin/deployment-guide/intro.md:14]()\n\n---\n\n## Storage Architecture\n\nEach component has specific storage requirements:\n\n| Component | Storage Type | Purpose | Implementation |\n|-----------|--------------|---------|----------------|\n| **GitLab PostgreSQL** | PersistentVolume | Metadata, users, projects | `StatefulSet: gitlab-postgresql` with PVC |\n| **GitLab Redis** | In-memory / PV | Cache, job queues | `Deployment: gitlab-redis` |\n| **GitLab Backups** | S3 Object Storage | Scheduled backups | `gitlab-backup-storage` bucket |\n| **GitLab LFS** | S3 Object Storage | Large file storage (optional) | `gitlab-lfs-storage` bucket |\n| **MLflow PostgreSQL** | PersistentVolume | Experiment metadata, model registry | `StatefulSet: mlflow-postgresql` with PVC |\n| **MLflow Artifacts** | S3 Object Storage | Model files, artifacts | `mlflow-artifacts` bucket |\n| **SharingHub** | None (stateless) | Queries GitLab API dynamically | No persistent storage required |\n\n**Backup Strategy:**\n- GitLab: Automated backups to S3 configured via `global.appConfig.backups` in Helm values\n- MLflow PostgreSQL: Database backups should be configured using standard PostgreSQL backup tools\n- S3 buckets: Configure bucket versioning and lifecycle policies at the S3 provider level\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:162-164](), [docs/admin/deployment-guide/components/gitlab.md:179-184]()\n\n---\n\n## Helm Chart Configuration Model\n\nEach ArgoCD Application references a Helm chart with configuration provided via `spec.source.helm.valuesObject`:\n\n```mermaid\ngraph TB\n    subgraph \"ArgoCD Application Manifest\"\n        APP[\"Application Resource\u003cbr/\u003e(gitlab.yaml)\"]\n        SPEC[\"spec.source.repoURL\u003cbr/\u003espec.source.chart\u003cbr/\u003espec.source.targetRevision\"]\n        VALUES[\"spec.source.helm.valuesObject\"]\n    end\n    \n    subgraph \"Helm Chart Repository\"\n        CHART[\"Helm Chart\u003cbr/\u003e(gitlab-8.1.0.tgz)\"]\n        DEFAULT[\"Default values.yaml\"]\n        TEMPLATES[\"Kubernetes templates\"]\n    end\n    \n    subgraph \"Generated Kubernetes Resources\"\n        DEPLOY[\"Deployments\"]\n        SVC[\"Services\"]\n        ING[\"Ingresses\"]\n        CM[\"ConfigMaps\"]\n        SEC[\"Secrets (generated)\"]\n    end\n    \n    APP --\u003e SPEC\n    APP --\u003e VALUES\n    \n    SPEC --\u003e CHART\n    CHART --\u003e DEFAULT\n    CHART --\u003e TEMPLATES\n    \n    VALUES -.overrides.-\u003e DEFAULT\n    DEFAULT --\u003e TEMPLATES\n    TEMPLATES --\u003e DEPLOY\n    TEMPLATES --\u003e SVC\n    TEMPLATES --\u003e ING\n    TEMPLATES --\u003e CM\n    TEMPLATES --\u003e SEC\n```\n\n**Configuration Hierarchy:**\n\n1. **Default Values**: Defined in the Helm chart's `values.yaml`\n2. **Override Values**: Specified in `spec.source.helm.valuesObject` in the ArgoCD Application manifest\n3. **Template Rendering**: Helm merges defaults with overrides and renders Kubernetes resource templates\n4. **ArgoCD Sync**: ArgoCD applies rendered resources to the cluster\n\n**Example from GitLab Application:**\n\nThe `valuesObject` section in [docs/admin/deployment-guide/components/gitlab.md:125-225]() demonstrates configuration for:\n- Domain name: `global.hosts.domain`\n- Ingress class and TLS: `global.ingress.class`, `global.ingress.annotations`\n- Component enablement: `global.registry.enabled`, `global.minio.enabled`\n- OIDC integration: `global.appConfig.omniauth.enabled`, `global.appConfig.omniauth.providers`\n- S3 bucket configuration: `global.appConfig.backups.bucket`, `global.appConfig.lfs.bucket`\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:107-230]()\n\n---\n\n## Network Architecture\n\nThe network architecture shows how components communicate within the Kubernetes cluster:\n\n```mermaid\ngraph TB\n    subgraph \"External Network\"\n        INTERNET[\"Internet\"]\n    end\n    \n    subgraph \"Ingress Layer\"\n        LB[\"Load Balancer\u003cbr/\u003eExternal IP\"]\n        NGINX[\"NGINX Ingress Controller\u003cbr/\u003eService: ingress-nginx\"]\n    end\n    \n    subgraph \"Application Layer\"\n        GL_SVC[\"GitLab WebService\u003cbr/\u003eService (ClusterIP)\u003cbr/\u003ePort: 8181\"]\n        SH_SVC[\"SharingHub\u003cbr/\u003eService (ClusterIP)\u003cbr/\u003ePort: 8000\"]\n        MLF_SVC[\"MLflow SharingHub\u003cbr/\u003eService (ClusterIP)\u003cbr/\u003ePort: 5000\"]\n    end\n    \n    subgraph \"Data Layer\"\n        GL_PG_SVC[\"GitLab PostgreSQL\u003cbr/\u003eService (ClusterIP)\u003cbr/\u003ePort: 5432\"]\n        GL_REDIS_SVC[\"GitLab Redis\u003cbr/\u003eService (ClusterIP)\u003cbr/\u003ePort: 6379\"]\n        MLF_PG_SVC[\"MLflow PostgreSQL\u003cbr/\u003eService (ClusterIP)\u003cbr/\u003ePort: 5432\"]\n    end\n    \n    subgraph \"External Services\"\n        S3[\"S3 Storage\u003cbr/\u003eHTTPS\"]\n        KC[\"Keycloak\u003cbr/\u003eHTTPS\"]\n    end\n    \n    INTERNET --\u003e|HTTPS 443| LB\n    LB --\u003e NGINX\n    \n    NGINX --\u003e|gitlab.domain| GL_SVC\n    NGINX --\u003e|sharinghub.domain| SH_SVC\n    NGINX --\u003e|sharinghub.domain/mlflow| MLF_SVC\n    \n    GL_SVC --\u003e GL_PG_SVC\n    GL_SVC --\u003e GL_REDIS_SVC\n    GL_SVC --\u003e S3\n    GL_SVC --\u003e KC\n    \n    SH_SVC --\u003e|GitLab API| GL_SVC\n    SH_SVC --\u003e S3\n    SH_SVC --\u003e KC\n    \n    MLF_SVC --\u003e|Permission API| SH_SVC\n    MLF_SVC --\u003e MLF_PG_SVC\n    MLF_SVC --\u003e S3\n```\n\n**Network Security:**\n- **External Access**: Only HTTPS (port 443) exposed via Load Balancer\n- **Internal Communication**: All services use `ClusterIP` type, accessible only within cluster\n- **Service Mesh**: No service mesh required; standard Kubernetes Service discovery used\n- **Network Policies**: Can be optionally configured for additional isolation (not included in base deployment)\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:131-135](), [docs/admin/deployment-guide/components/gitlab.md:170-178]()\n\n---\n\n## Resource Requirements\n\nRecommended resource allocations for each component:\n\n| Component | CPU Request | Memory Request | CPU Limit | Memory Limit | Storage |\n|-----------|-------------|----------------|-----------|--------------|---------|\n| GitLab webservice | 1-2 cores | 2-4 GB | 4 cores | 8 GB | N/A |\n| GitLab sidekiq | 0.5-1 core | 1-2 GB | 2 cores | 4 GB | N/A |\n| GitLab PostgreSQL | 0.5-1 core | 1-2 GB | 2 cores | 4 GB | 20-100 GB PV |\n| GitLab Redis | 0.2 cores | 256 MB | 1 core | 1 GB | 5-10 GB PV |\n| SharingHub | 0.5 cores | 512 MB | 2 cores | 2 GB | N/A |\n| MLflow SharingHub | 0.5 cores | 512 MB | 2 cores | 2 GB | N/A |\n| MLflow PostgreSQL | 0.5 cores | 512 MB | 1 core | 2 GB | 10-50 GB PV |\n\n**Sizing Considerations:**\n- GitLab resource requirements scale with number of users and repositories\n- MLflow PostgreSQL size depends on experiment tracking volume\n- S3 storage is effectively unlimited and usage-based\n\n**Production Recommendations:**\n- Enable pod autoscaling for GitLab webservice based on CPU/memory utilization\n- Configure resource limits to prevent resource exhaustion\n- Monitor actual usage and adjust requests/limits accordingly\n\n---\n\n## High Availability Considerations\n\nThe default deployment configuration is **single-instance** for simplicity. For production high availability:\n\n| Component | HA Strategy | Implementation |\n|-----------|-------------|----------------|\n| GitLab webservice | Horizontal scaling | Increase `replicaCount` in Helm values |\n| GitLab PostgreSQL | Primary-replica replication | Use external managed PostgreSQL service |\n| GitLab Redis | Sentinel/Cluster mode | Enable GitLab Redis HA in Helm chart |\n| SharingHub | Horizontal scaling | Deploy multiple replicas (stateless) |\n| MLflow SharingHub | Horizontal scaling | Deploy multiple replicas with shared PostgreSQL |\n| MLflow PostgreSQL | Primary-replica replication | Use external managed PostgreSQL service |\n| S3 Storage | Provider-managed | S3 providers handle replication |\n| NGINX Ingress | Multiple replicas | Default configuration typically includes HA |\n\nFor production deployments, consider:\n- Using managed database services (e.g., Amazon RDS, Google Cloud SQL) instead of in-cluster PostgreSQL\n- Configuring multiple replicas for all stateless components\n- Implementing pod anti-affinity rules to distribute replicas across nodes\n- Setting up monitoring and alerting for component health\n\n---\n\n## Summary\n\nThe MLOps Building Block deployment architecture is characterized by:\n\n1. **GitOps Management**: ArgoCD continuously reconciles desired state from Helm charts\n2. **Namespace Isolation**: Each component deployed in dedicated namespace with isolated secrets\n3. **External Dependencies**: Relies on S3 storage, optional Keycloak, and Let's Encrypt for TLS\n4. **Automated TLS**: cert-manager handles certificate lifecycle without manual intervention\n5. **Modular Design**: Components can be deployed independently with clear dependency order\n\nProceed to component-specific deployment guides:\n- [GitLab Deployment](#5.2) for deploying the GitLab instance\n- [SharingHub Deployment](#5.3) for deploying the discovery platform\n- [MLflow SharingHub Deployment](#5.4) for deploying the experiment tracking platform\n\nSources: [docs/admin/deployment-guide/intro.md](), [docs/admin/deployment-guide/components/gitlab.md]()"])</script><script>self.__next_f.push([1,"25:T4892,"])</script><script>self.__next_f.push([1,"# GitLab Deployment\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/deployment-guide/components/gitlab.md](docs/admin/deployment-guide/components/gitlab.md)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis page provides detailed instructions for deploying GitLab to a Kubernetes cluster using ArgoCD and Helm. GitLab serves as the foundation of the MLOps Building Block, providing version control, project management, CI/CD capabilities, and serving as the source of truth for the SharingHub STAC catalog.\n\nThis deployment guide covers GitLab in minimal mode with optional Keycloak OIDC integration. For overall deployment architecture and prerequisites, see [Prerequisites and Architecture](#5.1). For deploying the other components, see [SharingHub Deployment](#5.3) and [MLflow SharingHub Deployment](#5.4).\n\n**Note**: This deployment is optional. If you already have a GitLab instance that meets the platform requirements, you may skip this section and configure SharingHub to use your existing instance.\n\n## GitLab Role in the MLOps Platform\n\nGitLab functions as the central repository and project management system within the EOEPCA MLOps platform. It provides:\n\n- **Version Control**: Git repository hosting for model code, training scripts, and configuration files\n- **Project Organization**: Project-based structure with topics that map to SharingHub categories\n- **Authentication**: OAuth provider for SharingHub and identity integration with Keycloak via OIDC\n- **Metadata Source**: Project metadata (topics, tags, descriptions) extracted by SharingHub for STAC catalog generation\n- **Artifact Storage**: Integration with S3 for backups and optional Git LFS for large file storage\n\n### GitLab Integration Points\n\n```mermaid\ngraph TB\n    subgraph \"External Services\"\n        Keycloak[\"Keycloak\u003cbr/\u003eOIDC Provider\"]\n        S3Backup[\"S3 Bucket\u003cbr/\u003egitlab-backup-storage\"]\n        S3Tmp[\"S3 Bucket\u003cbr/\u003egitlab-tmp-storage\"]\n        S3LFS[\"S3 Bucket\u003cbr/\u003egitlab-lfs-storage\u003cbr/\u003e(optional)\"]\n    end\n    \n    subgraph \"Kubernetes Cluster\"\n        ArgoCD[\"ArgoCD Application\u003cbr/\u003egitlab.yaml\"]\n        \n        subgraph \"gitlab namespace\"\n            Webservice[\"gitlab-webservice\u003cbr/\u003eMain UI \u0026 API\"]\n            Sidekiq[\"gitlab-sidekiq\u003cbr/\u003eBackground Jobs\"]\n            KAS[\"gitlab-kas\u003cbr/\u003eKubernetes Agent Server\"]\n            Toolbox[\"gitlab-toolbox\u003cbr/\u003eBackup \u0026 Maintenance\"]\n            \n            Redis[\"gitlab-redis\"]\n            PostgreSQL[\"gitlab-postgresql\"]\n            \n            StorageConfig[\"Secret: storage-config\u003cbr/\u003eS3 credentials\"]\n            OIDCSecret[\"Secret: openid-connect\u003cbr/\u003eKeycloak configuration\"]\n            LFSSecret[\"Secret: object-storage\u003cbr/\u003eLFS S3 configuration\"]\n        end\n        \n        CertManager[\"cert-manager\u003cbr/\u003eTLS Certificate Management\"]\n        NginxIngress[\"NGINX Ingress Controller\"]\n    end\n    \n    subgraph \"SharingHub Integration\"\n        SharingHub[\"SharingHub\u003cbr/\u003eOAuth Client\"]\n    end\n    \n    ArgoCD --\u003e|\"Deploys Helm Chart\u003cbr/\u003echarts.gitlab.io/gitlab\"| Webservice\n    ArgoCD --\u003e|\"Creates namespace\"| StorageConfig\n    \n    Webservice --\u003e|\"Authenticates via OIDC\"| Keycloak\n    Webservice --\u003e|\"Reads config\"| OIDCSecret\n    Webservice --\u003e|\"OAuth 2.0 Provider\"| SharingHub\n    \n    Toolbox --\u003e|\"Stores backups\"| S3Backup\n    Toolbox --\u003e|\"Temporary storage\"| S3Tmp\n    Toolbox --\u003e|\"Reads credentials\"| StorageConfig\n    \n    Webservice --\u003e|\"Stores LFS objects\"| S3LFS\n    Webservice --\u003e|\"Reads LFS config\"| LFSSecret\n    \n    Webservice --\u003e Redis\n    Webservice --\u003e PostgreSQL\n    Sidekiq --\u003e Redis\n    Sidekiq --\u003e PostgreSQL\n    \n    NginxIngress --\u003e|\"Routes traffic to\"| Webservice\n    NginxIngress --\u003e|\"Routes traffic to\"| KAS\n    \n    CertManager --\u003e|\"Provisions TLS certificates\"| NginxIngress\n```\n\n**Diagram: GitLab Deployment Architecture and Dependencies**\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:1-243]()\n\n## Deployment Workflow\n\nThe GitLab deployment follows a four-step process:\n\n```mermaid\ngraph LR\n    Step1[\"1. Create S3 Buckets\u003cbr/\u003e\u0026 Configure Credentials\"]\n    Step2[\"2. Configure Git LFS\u003cbr/\u003e(Optional)\"]\n    Step3[\"3. Configure OIDC\u003cbr/\u003ewith Keycloak (Optional)\"]\n    Step4[\"4. Deploy ArgoCD\u003cbr/\u003eApplication\"]\n    \n    Step1 --\u003e|\"Required\"| Step4\n    Step2 --\u003e|\"Optional\"| Step4\n    Step3 --\u003e|\"Optional\"| Step4\n    \n    Step4 --\u003e|\"ArgoCD applies\"| HelmChart[\"Helm Chart\u003cbr/\u003egitlab/gitlab:8.1.0\"]\n    HelmChart --\u003e|\"Creates\"| K8sResources[\"Kubernetes Resources\u003cbr/\u003ein gitlab namespace\"]\n```\n\n**Diagram: GitLab Deployment Workflow**\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:6-11]()\n\n## Prerequisites\n\nBefore deploying GitLab, ensure the following prerequisites are met:\n\n| Requirement | Description | Reference |\n|------------|-------------|-----------|\n| Kubernetes Cluster | Running cluster with sufficient resources | See [Prerequisites and Architecture](#5.1) |\n| ArgoCD | Installed and configured | See [Prerequisites and Architecture](#5.1) |\n| cert-manager | Installed for TLS certificate management | See [Prerequisites and Architecture](#5.1) |\n| NGINX Ingress Controller | Installed for ingress routing | See [Prerequisites and Architecture](#5.1) |\n| S3 Provider | Compatible S3 service for object storage | Required |\n| Keycloak | OIDC provider (optional) | For OIDC authentication |\n| Domain Name | DNS records configured | Required for ingress |\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:1-14]()\n\n## S3 Storage Configuration\n\nGitLab requires S3-compatible object storage for backups and temporary storage. Git LFS requires an additional bucket if enabled.\n\n### Required S3 Buckets\n\nCreate the following S3 buckets in your S3 provider:\n\n| Bucket Name | Purpose | Required |\n|------------|---------|----------|\n| `gitlab-backup-storage` | GitLab backups | Yes |\n| `gitlab-tmp-storage` | Temporary storage | Yes |\n| `gitlab-lfs-storage` | Git LFS objects | Only if LFS enabled |\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:16-19]()\n\n### S3 Configuration File\n\nCreate a configuration file `storage.config` with S3 credentials and endpoint information:\n\n```conf\n[default]\naccess_key = \u003caccess_key\u003e\nbucket_location = \u003cbucket_region\u003e\nhost_base = \u003cs3_endpoint\u003e\nsecret_key = \u003csecret_key\u003e\nuse_https = True\n```\n\nThis configuration format follows the s3cmd configuration specification used by GitLab's toolbox component for backup operations.\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:21-30]()\n\n### Create Storage Config Secret\n\nCreate the `gitlab` namespace and the `storage-config` secret:\n\n```bash\nkubectl create ns gitlab\nkubectl create secret generic storage-config --from-file=config=storage.config -n gitlab\n```\n\nThe secret key `config` maps to the file content and is referenced in the GitLab Helm values at [docs/admin/deployment-guide/components/gitlab.md:182-184]().\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:32-37]()\n\n## Git LFS Configuration (Optional)\n\nGit Large File Storage (LFS) enables efficient handling of large binary files in Git repositories. This is particularly useful for ML datasets and model artifacts.\n\n### LFS S3 Configuration File\n\nCreate a configuration file `lfs-s3.yaml`:\n\n```yaml\nprovider: AWS\nregion: eu\naws_access_key_id: \u003caccess_key\u003e\naws_secret_access_key: \u003csecret_key\u003e\naws_signature_version: 4\nhost: \u003cs3_endpoint\u003e\nendpoint: \"https://\u003cs3_endpoint\u003e\"\npath_style: true\n```\n\nKey parameters:\n- `provider`: Set to `AWS` for S3-compatible services\n- `region`: S3 bucket region\n- `aws_signature_version`: Use version 4 for compatibility\n- `path_style`: Use path-style URLs for S3-compatible services\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:44-58]()\n\n### Create LFS Secret\n\nCreate the `object-storage` secret in the `gitlab` namespace:\n\n```bash\nkubectl create secret generic object-storage --from-file=connection=lfs-s3.yaml -n gitlab\n```\n\nThis secret is referenced in the Helm values at [docs/admin/deployment-guide/components/gitlab.md:153-155]() under `global.appConfig.lfs.connection`.\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:60-64]()\n\n## OIDC Configuration (Optional)\n\nIntegrating GitLab with Keycloak enables Single Sign-On (SSO) authentication across the MLOps platform.\n\n### Keycloak Client Setup\n\n1. Access your Keycloak admin console\n2. Navigate to your realm (e.g., `eoepca`)\n3. Create a new client with ID `gitlab`\n4. Configure the client:\n   - **Client Protocol**: openid-connect\n   - **Access Type**: confidential\n   - **Valid Redirect URIs**: `https://gitlab.\u003cdomain_name\u003e/users/auth/openid_connect/callback`\n\n### OIDC Provider Configuration File\n\nCreate a configuration file `provider.yaml`:\n\n```yaml\nname: openid_connect\nlabel: EOEPCA\nicon: \"https://eoepca.readthedocs.io/img/favicon.ico\"\nargs:\n  name: openid_connect\n  scope: [\"openid\", \"profile\", \"email\"]\n  response_type: \"code\"\n  issuer: \"https://\u003ckeycloak_domain\u003e/realms/\u003cyour_realm\u003e\"\n  client_auth_method: \"query\"\n  discovery: true\n  uid_field: \"preferred_username\"\n  pkce: true\n  client_options:\n    identifier: \"gitlab\"\n    secret: \u003cclient_secret\u003e\n    redirect_uri: \"https://gitlab.\u003cdomain_name\u003e/users/auth/openid_connect/callback\"\n```\n\nConfiguration parameters:\n- `name`: OmniAuth strategy name (`openid_connect`)\n- `label`: Display name shown on login page\n- `issuer`: Keycloak realm issuer URL\n- `discovery`: Enable automatic endpoint discovery\n- `pkce`: Enable Proof Key for Code Exchange for enhanced security\n- `uid_field`: OIDC claim used as GitLab username\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:70-92]()\n\n### Create OIDC Secret\n\nCreate the `openid-connect` secret:\n\n```bash\nkubectl create secret generic -n gitlab openid-connect --from-file=provider=provider.yaml\n```\n\nThis secret is referenced in the Helm values at [docs/admin/deployment-guide/components/gitlab.md:147-148]() under `global.appConfig.omniauth.providers`.\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:94-98]()\n\n### OIDC Authentication Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Browser\n    participant GitLab as gitlab-webservice\n    participant Keycloak\n    \n    User-\u003e\u003eBrowser: Access GitLab UI\n    Browser-\u003e\u003eGitLab: GET /\n    GitLab-\u003e\u003eBrowser: Login page with OIDC option\n    \n    User-\u003e\u003eBrowser: Click \"Sign in with EOEPCA\"\n    Browser-\u003e\u003eGitLab: GET /users/auth/openid_connect\n    GitLab-\u003e\u003eBrowser: Redirect to Keycloak\n    \n    Browser-\u003e\u003eKeycloak: Authorization request with PKCE\n    Keycloak-\u003e\u003eBrowser: Login page\n    \n    User-\u003e\u003eBrowser: Enter credentials\n    Browser-\u003e\u003eKeycloak: POST credentials\n    Keycloak-\u003e\u003eBrowser: Redirect with authorization code\n    \n    Browser-\u003e\u003eGitLab: GET /users/auth/openid_connect/callback?code=...\n    GitLab-\u003e\u003eKeycloak: POST /token (exchange code)\n    Keycloak-\u003e\u003eGitLab: Access token + ID token\n    GitLab-\u003e\u003eGitLab: Validate token, extract uid_field\n    GitLab-\u003e\u003eBrowser: Set session, redirect to dashboard\n```\n\n**Diagram: OIDC Authentication Flow**\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:68-103]()\n\n## ArgoCD Application Deployment\n\nThe GitLab deployment is managed through an ArgoCD Application manifest that references the official GitLab Helm chart.\n\n### Application Manifest Structure\n\n```mermaid\ngraph TB\n    subgraph \"gitlab.yaml ArgoCD Application\"\n        Metadata[\"metadata:\u003cbr/\u003ename: gitlab\u003cbr/\u003enamespace: argocd\"]\n        Spec[\"spec:\"]\n        Destination[\"destination:\u003cbr/\u003enamespace: gitlab\u003cbr/\u003eserver: kubernetes.default.svc\"]\n        Source[\"source:\u003cbr/\u003erepoURL: charts.gitlab.io\u003cbr/\u003echart: gitlab\u003cbr/\u003etargetRevision: 8.1.0\"]\n        HelmValues[\"helm.valuesObject\"]\n        \n        Metadata --\u003e Spec\n        Spec --\u003e Destination\n        Spec --\u003e Source\n        Source --\u003e HelmValues\n        \n        subgraph \"Helm Values Structure\"\n            Global[\"global:\u003cbr/\u003eedition: ce\u003cbr/\u003ehosts.domain\u003cbr/\u003eingress config\u003cbr/\u003eappConfig\"]\n            Components[\"gitlab:\u003cbr/\u003ewebservice\u003cbr/\u003ekas\u003cbr/\u003etoolbox\u003cbr/\u003esidekiq\"]\n            Disabled[\"Disabled components:\u003cbr/\u003eregistry: false\u003cbr/\u003eminio: false\u003cbr/\u003eprometheus: false\u003cbr/\u003egitlab-runner: false\"]\n            \n            HelmValues --\u003e Global\n            HelmValues --\u003e Components\n            HelmValues --\u003e Disabled\n        end\n    end\n```\n\n**Diagram: ArgoCD Application Manifest Structure**\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:107-230]()\n\n### Create Application Manifest\n\nCreate a file `gitlab.yaml` with the ArgoCD Application definition. The manifest structure is as follows:\n\n| Section | Purpose | Configuration |\n|---------|---------|---------------|\n| `metadata` | Application identity | Name: `gitlab`, Namespace: `argocd` |\n| `spec.destination` | Target cluster and namespace | Namespace: `gitlab`, Server: local cluster |\n| `spec.source` | Helm chart source | Chart: `gitlab` from `charts.gitlab.io`, Version: `8.1.0` |\n| `spec.source.helm.valuesObject` | Helm values override | GitLab configuration values |\n| `spec.syncPolicy` | Synchronization behavior | Create namespace, fail on shared resources |\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:107-230]()\n\n### Helm Values Configuration\n\nThe Helm values in the ArgoCD Application configure GitLab's deployment. Key sections:\n\n#### Global Configuration\n\n[docs/admin/deployment-guide/components/gitlab.md:126-164]()\n\n```yaml\nglobal:\n  edition: ce\n  hosts:\n    domain: \u003cdomain_name\u003e\n  \n  ingress:\n    configureCertmanager: false\n    class: nginx\n    annotations:\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n  \n  registry:\n    enabled: false\n  \n  minio:\n    enabled: false\n```\n\nParameters:\n- `edition: ce` - GitLab Community Edition\n- `hosts.domain` - Base domain for all GitLab services\n- `ingress.configureCertmanager: false` - Use existing cert-manager installation\n- `ingress.class: nginx` - Use NGINX ingress controller\n- `registry.enabled: false` - Disable built-in container registry (minimal mode)\n- `minio.enabled: false` - Use external S3 instead of embedded MinIO\n\n#### Application Configuration\n\n[docs/admin/deployment-guide/components/gitlab.md:143-164]()\n\n```yaml\nglobal:\n  appConfig:\n    omniauth:\n      enabled: false  # Set to true for OIDC\n      # allowSingleSignOn: [\"saml\", \"openid_connect\"]\n      # providers:\n      #   - secret: openid-connect\n    \n    lfs:\n      enabled: false  # Set to true for Git LFS\n      bucket: gitlab-lfs-storage\n      connection:\n        secret: object-storage\n        key: connection\n    \n    artifacts:\n      enabled: false\n    uploads:\n      enabled: false\n    packages:\n      enabled: false\n    backups:\n      bucket: gitlab-backup-storage\n      tmpBucket: gitlab-tmp-storage\n```\n\nConfiguration options:\n- `omniauth.enabled` - Enable/disable OIDC authentication\n- `omniauth.providers[].secret` - References the `openid-connect` Kubernetes secret\n- `lfs.enabled` - Enable/disable Git LFS\n- `lfs.connection.secret` - References the `object-storage` Kubernetes secret\n- `backups.bucket` - S3 bucket for GitLab backups (uses `storage-config` secret)\n\n#### Component Configuration\n\n[docs/admin/deployment-guide/components/gitlab.md:169-187]()\n\n```yaml\ngitlab:\n  webservice:\n    ingress:\n      tls:\n        secretName: gitlab.\u003cdomain_name\u003e-tls\n  \n  kas:\n    ingress:\n      tls:\n        secretName: kas.\u003cdomain_name\u003e-tls\n  \n  toolbox:\n    backups:\n      objectStorage:\n        config:\n          secret: storage-config\n          key: config\n  \n  sidekiq:\n    enabled: true\n```\n\nComponents:\n- `webservice` - Main GitLab web UI and API server\n- `kas` - Kubernetes Agent Server for GitLab Agent integration\n- `toolbox` - Maintenance tasks including backups (references `storage-config` secret)\n- `sidekiq` - Background job processor\n\n#### Disabled Components\n\n[docs/admin/deployment-guide/components/gitlab.md:189-224]()\n\nIn minimal mode, the following components are disabled:\n\n| Component | Purpose | Status |\n|-----------|---------|--------|\n| `registry` | Container image registry | Disabled |\n| `certmanager` | Certificate management | Disabled (use existing) |\n| `nginx-ingress` | Ingress controller | Disabled (use existing) |\n| `nginx-ingress-geo` | Geo replication ingress | Disabled |\n| `prometheus` | Metrics collection | Disabled |\n| `gitlab-runner` | CI/CD runner | Disabled |\n\n### Deploy the Application\n\n1. **Update placeholders** in `gitlab.yaml`:\n   - Replace `\u003cdomain_name\u003e` with your actual domain (e.g., `example.com`)\n   - Update `certmanager-issuer.email` with your email address\n\n2. **Apply the manifest**:\n\n```bash\nkubectl apply -f gitlab.yaml\n```\n\n3. **Monitor deployment**:\n\n```bash\n# Watch ArgoCD Application status\nkubectl get application gitlab -n argocd -w\n\n# Check pod status in gitlab namespace\nkubectl get pods -n gitlab\n\n# View GitLab logs\nkubectl logs -n gitlab -l app=webservice\n```\n\nThe deployment typically takes 5-10 minutes as ArgoCD synchronizes the application and Kubernetes creates all resources.\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:232-242]()\n\n## Post-Deployment Verification\n\nAfter successful deployment, verify the GitLab installation:\n\n1. **Access GitLab UI**:\n   - Navigate to `https://gitlab.\u003cdomain_name\u003e`\n   - The TLS certificate should be automatically provisioned by cert-manager\n\n2. **Retrieve initial root password**:\n   ```bash\n   kubectl get secret gitlab-gitlab-initial-root-password -n gitlab -o jsonpath='{.data.password}' | base64 --decode\n   ```\n\n3. **Login as root user**:\n   - Username: `root`\n   - Password: Retrieved from secret above\n\n4. **Verify OIDC integration** (if enabled):\n   - Check for \"Sign in with EOEPCA\" button on login page\n   - Test authentication flow with Keycloak\n\n5. **Verify S3 backup configuration**:\n   - Check GitLab admin area  Settings  Backups\n   - Confirm connection to S3 buckets\n\n6. **Create test project**:\n   - Create a new project to verify basic functionality\n   - If LFS enabled, test large file push\n\n## Configuration Reference\n\nFor detailed GitLab configuration options beyond this deployment guide:\n\n- [GitLab Helm Chart Documentation](https://docs.gitlab.com/charts/)\n- [External Object Storage Configuration](https://docs.gitlab.com/charts/advanced/external-object-storage/)\n- [GitLab OIDC Configuration](https://docs.gitlab.com/ee/administration/auth/oidc.html)\n- [OmniAuth Configuration](https://docs.gitlab.com/charts/charts/globals.html#omniauth)\n\nFor SharingHub integration with this GitLab instance, see [SharingHub Deployment](#5.3).\n\nSources: [docs/admin/deployment-guide/components/gitlab.md:14-242]()"])</script><script>self.__next_f.push([1,"26:T7017,"])</script><script>self.__next_f.push([1,"# SharingHub Deployment\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/deployment-guide/components/sharinghub.md](docs/admin/deployment-guide/components/sharinghub.md)\n\n\u003c/details\u003e\n\n\n\nThis document provides step-by-step instructions for deploying SharingHub on a Kubernetes cluster using ArgoCD and Helm charts. SharingHub serves as the discovery and collaboration platform within the MLOps Building Block, exposing GitLab projects as a STAC-compliant catalog.\n\nFor general deployment prerequisites and architecture, see [Prerequisites and Architecture](#5.1). For deploying the required GitLab instance, see [GitLab Deployment](#5.2). For deploying MLflow SharingHub that integrates with this deployment, see [MLflow SharingHub Deployment](#5.4).\n\n## Deployment Overview\n\nSharingHub deployment involves three main phases: preparation of Kubernetes secrets, configuration of the ArgoCD Application manifest with Helm values, and application of the manifest to trigger deployment. The deployment process uses GitOps principles with ArgoCD managing the Helm chart from the upstream SharingHub repository.\n\n```mermaid\ngraph TB\n    subgraph \"Preparation Phase\"\n        SECRET1[\"kubectl create secret\u003cbr/\u003esharinghub\u003cbr/\u003e(session-secret-key)\"]\n        GITLAB_APP[\"Configure GitLab\u003cbr/\u003eOAuth Application\"]\n        SECRET2[\"kubectl create secret\u003cbr/\u003esharinghub-oidc\u003cbr/\u003e(client-id, client-secret, default-token)\"]\n    end\n    \n    subgraph \"Configuration Phase\"\n        MANIFEST[\"Create sharinghub.yaml\u003cbr/\u003eArgoCD Application\"]\n        HELM_VALUES[\"Configure Helm values:\u003cbr/\u003e- gitlab.url\u003cbr/\u003e- stac.root\u003cbr/\u003e- stac.categories\u003cbr/\u003e- tags.sections\u003cbr/\u003e- ingress.hosts\"]\n        S3_CONFIG[\"Optional: Configure\u003cbr/\u003es3.bucket\u003cbr/\u003es3.endpoint\"]\n    end\n    \n    subgraph \"Deployment Phase\"\n        APPLY[\"kubectl apply -f\u003cbr/\u003esharinghub.yaml\"]\n        ARGOCD[\"ArgoCD reconciles\u003cbr/\u003eApplication\"]\n        HELM[\"Helm chart deployed\u003cbr/\u003efrom csgroup-oss/sharinghub\"]\n    end\n    \n    subgraph \"Runtime Resources\"\n        NAMESPACE[\"sharinghub namespace\"]\n        POD[\"sharinghub Pod\u003cbr/\u003e(eoepca/sharinghub image)\"]\n        INGRESS[\"Ingress\u003cbr/\u003e(sharinghub.domain)\"]\n        CERT[\"TLS Certificate\u003cbr/\u003e(cert-manager)\"]\n    end\n    \n    SECRET1 --\u003e MANIFEST\n    GITLAB_APP --\u003e SECRET2\n    SECRET2 --\u003e MANIFEST\n    MANIFEST --\u003e HELM_VALUES\n    HELM_VALUES --\u003e S3_CONFIG\n    S3_CONFIG --\u003e APPLY\n    APPLY --\u003e ARGOCD\n    ARGOCD --\u003e HELM\n    HELM --\u003e NAMESPACE\n    NAMESPACE --\u003e POD\n    NAMESPACE --\u003e INGRESS\n    INGRESS --\u003e CERT\n    \n    POD -.reads.-\u003e SECRET1\n    POD -.reads.-\u003e SECRET2\n```\n\n**Deployment workflow from preparation to runtime resources**\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:1-215]()\n\n## Prerequisites\n\nBefore deploying SharingHub, ensure the following prerequisites are met:\n\n| Requirement | Description | Reference |\n|------------|-------------|-----------|\n| Kubernetes Cluster | Running cluster with kubectl access | [Prerequisites and Architecture](#5.1) |\n| ArgoCD | Installed and configured in `argocd` namespace | [Prerequisites and Architecture](#5.1) |\n| GitLab Instance | Deployed and accessible | [GitLab Deployment](#5.2) |\n| cert-manager | Installed for TLS certificate management | [Prerequisites and Architecture](#5.1) |\n| NGINX Ingress | Ingress controller configured | [Prerequisites and Architecture](#5.1) |\n| Domain Name | DNS configured for `sharinghub.\u003cdomain\u003e` | [Prerequisites and Architecture](#5.1) |\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:6-46]()\n\n## Preparation Steps\n\n### Create Session Secret\n\nSharingHub requires a secret key for session management and security purposes. Create the `sharinghub` secret in the `sharinghub` namespace:\n\n```bash\nkubectl create secret generic sharinghub \\\n  --from-literal session-secret-key=\"\u003cuuid\u003e\" \\\n  --namespace sharinghub\n```\n\nThe `session-secret-key` should be a randomly generated UUID or similar cryptographically secure value. This secret is mounted by the SharingHub Pod at runtime.\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:8-14]()\n\n### Configure GitLab OAuth Application\n\nSharingHub uses OpenID Connect (OIDC) for authentication via GitLab. Configure an OAuth application in your GitLab instance:\n\n1. Navigate to GitLab Admin Area  Applications  New Application\n2. Configure the application with the following settings:\n   - **Name**: SharingHub\n   - **Redirect URI / Callback URL**:\n     ```\n     https://sharinghub.\u003cdomain-name\u003e/api/auth/login/callback\n     ```\n   - **Scopes**: Select `openid`, `profile`, `email`\n   - **Confidential**: Yes\n\n3. After creation, GitLab provides an **Application ID** and **Application Secret**. Save these values for the next step.\n\n```mermaid\ngraph LR\n    subgraph \"GitLab Admin\"\n        APP[\"OAuth Application\u003cbr/\u003eName: SharingHub\"]\n        REDIRECT[\"Redirect URI:\u003cbr/\u003esharinghub.domain/api/auth/login/callback\"]\n        SCOPES[\"Scopes:\u003cbr/\u003eopenid, profile, email\"]\n    end\n    \n    subgraph \"OAuth Credentials\"\n        APP_ID[\"Application ID\u003cbr/\u003e(client-id)\"]\n        APP_SECRET[\"Application Secret\u003cbr/\u003e(client-secret)\"]\n    end\n    \n    APP --\u003e APP_ID\n    APP --\u003e APP_SECRET\n    REDIRECT --\u003e APP\n    SCOPES --\u003e APP\n```\n\n**GitLab OAuth application configuration flow**\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:16-37]()\n\n### Create OIDC Secret\n\nCreate the `sharinghub-oidc` secret with the OAuth credentials obtained from GitLab:\n\n```bash\nkubectl create secret generic sharinghub-oidc \\\n  --from-literal client-id=\"\u003capplication-id\u003e\" \\\n  --from-literal client-secret=\"\u003capplication-secret\u003e\" \\\n  --namespace sharinghub\n```\n\n#### Optional: Default Token for Public Access\n\nTo allow unauthenticated users to access public projects, configure a `default-token`. This can be either a GitLab Personal Access Token (PAT) or a Group Access Token:\n\n**For Group Access Token:**\n- Role: `Reporter` (minimum)\n- Scopes: `read_api`, `read_repository`\n\n**For Personal Access Token:**\n- Scopes: `api`\n\nAdd the `default-token` to the secret:\n\n```bash\nkubectl create secret generic sharinghub-oidc \\\n  --from-literal default-token=\"\u003cdefault-token\u003e\" \\\n  --from-literal client-id=\"\u003capplication-id\u003e\" \\\n  --from-literal client-secret=\"\u003capplication-secret\u003e\" \\\n  --namespace sharinghub\n```\n\nWithout a default token, users must authenticate to view any projects, including public ones.\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:39-45]()\n\n## ArgoCD Application Configuration\n\n### Application Manifest Structure\n\nCreate a file named `sharinghub.yaml` with the ArgoCD Application manifest. The manifest references the upstream Helm chart from the SharingHub repository and configures all necessary values:\n\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: sharinghub\n  namespace: argocd\nspec:\n  destination:\n    namespace: sharinghub\n    server: https://kubernetes.default.svc\n  project: default\n  source:\n    repoURL: https://github.com/csgroup-oss/sharinghub.git\n    path: deploy/helm/sharinghub\n    targetRevision: \"0.4.0\"\n    helm:\n      valuesObject:\n        # Configuration detailed in following sections\n  syncPolicy:\n    syncOptions:\n      - FailOnSharedResource=true\n      - CreateNamespace=true\n    automated:\n      selfHeal: true\n```\n\nKey manifest fields:\n\n| Field | Value | Purpose |\n|-------|-------|---------|\n| `metadata.name` | `sharinghub` | Application identifier in ArgoCD |\n| `metadata.namespace` | `argocd` | ArgoCD control plane namespace |\n| `spec.destination.namespace` | `sharinghub` | Target Kubernetes namespace |\n| `spec.source.repoURL` | `https://github.com/csgroup-oss/sharinghub.git` | Upstream Helm chart repository |\n| `spec.source.path` | `deploy/helm/sharinghub` | Path to Helm chart in repository |\n| `spec.source.targetRevision` | `\"0.4.0\"` | SharingHub version tag |\n| `syncPolicy.automated.selfHeal` | `true` | Auto-remediate configuration drift |\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:49-191]()\n\n### Helm Values Configuration\n\nThe `spec.source.helm.valuesObject` section contains the SharingHub server configuration. Below are the essential configuration blocks.\n\n#### GitLab Integration\n\nConfigure the GitLab instance URL:\n\n```yaml\nconfig: |-\n  gitlab:\n    url: https://gitlab.\u003cdomain_name\u003e\n```\n\nSharingHub connects to this URL to:\n- Authenticate users via OIDC\n- Fetch project metadata\n- Validate project permissions\n- Extract topics and tags from projects\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:68-71]()\n\n#### Documentation URL\n\nConfigure the documentation URL (typically co-located with SharingHub):\n\n```yaml\nconfig: |-\n  docs:\n    url: https://sharinghub.\u003cdomain_name\u003e/docs\n```\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:73-74]()\n\n### STAC Catalog Configuration\n\nSharingHub dynamically generates a STAC-compliant catalog from GitLab projects. The STAC configuration defines the catalog structure, extensions, and root metadata.\n\n```mermaid\ngraph TB\n    subgraph \"STAC Configuration\"\n        ROOT[\"stac.root\u003cbr/\u003e(id, title, description)\"]\n        EXTENSIONS[\"stac.extensions\u003cbr/\u003e(eo, label, sci, ml-model)\"]\n        CATEGORIES[\"stac.categories\u003cbr/\u003e(collections)\"]\n        CACHE[\"stac.projects.cache-timeout\u003cbr/\u003e(30 seconds)\"]\n    end\n    \n    subgraph \"Generated STAC Catalog\"\n        STAC_ROOT[\"STAC Root Catalog\u003cbr/\u003eid: gitlab-cs\"]\n        COLLECTIONS[\"STAC Collections\u003cbr/\u003e(ai-model, dataset, processor)\"]\n        ITEMS[\"STAC Items\u003cbr/\u003e(GitLab projects)\"]\n    end\n    \n    subgraph \"GitLab Projects\"\n        PROJECT1[\"Project with topic:\u003cbr/\u003esharinghub:aimodel\"]\n        PROJECT2[\"Project with topic:\u003cbr/\u003esharinghub:dataset\"]\n    end\n    \n    ROOT --\u003e STAC_ROOT\n    CATEGORIES --\u003e COLLECTIONS\n    EXTENSIONS --\u003e ITEMS\n    \n    COLLECTIONS -.filters by topic.-\u003e PROJECT1\n    COLLECTIONS -.filters by topic.-\u003e PROJECT2\n    PROJECT1 --\u003e ITEMS\n    PROJECT2 --\u003e ITEMS\n```\n\n**STAC catalog generation from configuration to GitLab projects**\n\n#### Root Catalog\n\nDefine the root STAC catalog metadata:\n\n```yaml\nstac:\n  projects:\n    cache-timeout: 30\n  extensions:\n    eo: https://stac-extensions.github.io/eo/v1.1.0/schema.json\n    label: https://stac-extensions.github.io/label/v1.0.1/schema.json\n    sci: https://stac-extensions.github.io/scientific/v1.0.0/schema.json\n    ml-model: https://stac-extensions.github.io/ml-model/v1.0.0/schema.json\n  root:\n    id: gitlab-cs\n    title: SharingHub brings your data and models closer.\n    description: Your platform for collaborating on ML and NLP projects store in [GitLab](https://gitlab.com) instance STAC catalog.\n```\n\nConfiguration keys:\n\n| Key | Description |\n|-----|-------------|\n| `stac.projects.cache-timeout` | Cache duration (seconds) for project metadata |\n| `stac.extensions` | STAC extensions enabled for items |\n| `stac.root.id` | Unique identifier for root catalog |\n| `stac.root.title` | Human-readable catalog title |\n| `stac.root.description` | Markdown-formatted catalog description |\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:76-91]()\n\n#### Localization Support\n\nThe STAC root catalog supports multiple locales:\n\n```yaml\nstac:\n  root:\n    locales:\n      fr:\n        title: SharingHub rapproche vos donnes et vos modles.\n        description: Votre plateforme de collaboration sur les projets ML et NLP stocks dans le catalogue STAC de l'instance [GitLab](https://gitlab.com).\n```\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:88-91]()\n\n### Categories and GitLab Topics\n\nCategories in SharingHub map to STAC collections and are filtered by GitLab topics. Each category configuration includes metadata, features, and GitLab topic mapping.\n\n```mermaid\ngraph TB\n    subgraph \"Category Configuration\"\n        CAT_KEY[\"categories[N]\u003cbr/\u003e(ai-model, dataset)\"]\n        CAT_TOPIC[\"gitlab_topic\u003cbr/\u003e(sharinghub:aimodel)\"]\n        CAT_META[\"title, description\u003cbr/\u003elogo, icon\"]\n        CAT_FEATURES[\"features\u003cbr/\u003e(map-viewer, store-s3, mlflow)\"]\n    end\n    \n    subgraph \"GitLab\"\n        TOPIC_FILTER[\"Topic Filter\u003cbr/\u003eGET /projects?topic=sharinghub:aimodel\"]\n        PROJECTS[\"Filtered Projects\"]\n    end\n    \n    subgraph \"STAC Collection\"\n        COLLECTION[\"STAC Collection\u003cbr/\u003eid: ai-model\"]\n        ITEMS[\"STAC Items\u003cbr/\u003e(one per project)\"]\n    end\n    \n    CAT_KEY --\u003e CAT_TOPIC\n    CAT_KEY --\u003e CAT_META\n    CAT_KEY --\u003e CAT_FEATURES\n    \n    CAT_TOPIC --\u003e TOPIC_FILTER\n    TOPIC_FILTER --\u003e PROJECTS\n    PROJECTS --\u003e COLLECTION\n    COLLECTION --\u003e ITEMS\n    CAT_META --\u003e COLLECTION\n```\n\n**Category-to-collection mapping with GitLab topic filtering**\n\n#### AI Model Category Example\n\n```yaml\nstac:\n  categories:\n    - ai-model:\n        title: \"AI Models\"\n        description: \"AI models are the core of our platform, go and browse them to discover our models.\"\n        gitlab_topic: sharinghub:aimodel\n        logo: https://data.web.\u003cdomain_name\u003e/sharinghub/ai-model.jpg\n        icon: https://img.icons8.com/material/24/artificial-intelligence.png\n        locales:\n          fr:\n            title: \"Modles IA\"\n            description: \"Les modles d'IA sont au cur de notre plateforme, allez les parcourir pour dcouvrir nos modles.\"\n        features:\n          map-viewer: enable\n          store-s3: enable\n          mlflow: enable\n```\n\nCategory configuration fields:\n\n| Field | Description | Example Value |\n|-------|-------------|---------------|\n| `ai-model` | Category identifier (becomes STAC collection ID) | `ai-model` |\n| `title` | Display name | `\"AI Models\"` |\n| `description` | Category description | Markdown text |\n| `gitlab_topic` | GitLab topic for filtering projects | `sharinghub:aimodel` |\n| `logo` | Banner image URL | `https://...` |\n| `icon` | Small icon URL | `https://...` |\n| `features.map-viewer` | Enable geospatial map viewer | `enable` / `disable` |\n| `features.store-s3` | Enable S3 asset storage | `enable` / `disable` |\n| `features.mlflow` | Enable MLflow integration | `enable` / `disable` |\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:92-120]()\n\n#### Dataset Category Example\n\n```yaml\n    - dataset:\n        title: \"Datasets\"\n        description: \"Datasets are very important in the process of training an AI, discover those that we put at your disposal.\"\n        gitlab_topic: sharinghub:dataset\n        logo: https://data.web.\u003cdomain_name\u003e/sharinghub/datasets.jpg\n        icon: https://img.icons8.com/ios/50/data-backup.png\n        features:\n          map-viewer: enable\n          store-s3: enable\n          mlflow: disable\n```\n\nNote that the `dataset` category has `mlflow: disable` since datasets are not tracked in MLflow, only AI models.\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:107-120]()\n\n### Tags Configuration\n\nTags provide additional organization within categories. Projects are tagged using GitLab project tags, and SharingHub organizes them into sections.\n\n```yaml\ntags:\n  gitlab:\n    minimum_count: 1\n  sections:\n    - name: \"Computer Vision\"\n      enabled_for:\n        - ai-model\n        - dataset\n      keywords:\n        - \"Image qualification\"\n        - \"Object detection\"\n        - \"Image segmentation\"\n        - \"Mask generation\"\n    - name: \"Multimodal\"\n      keywords:\n        - \"Feature Extraction\"\n        - \"Text-to-Image\"\n        - \"Image-to-3D\"\n        - \"Text-to-3D\"\n      enabled_for:\n        - ai-model\n        - dataset\n    - name: \"Tabular\"\n      keywords:\n        - \"Tabular Classification\"\n        - \"Tabular Regression\"\n      enabled_for:\n        - ai-model\n        - dataset\n```\n\nTags configuration structure:\n\n| Field | Description |\n|-------|-------------|\n| `tags.gitlab.minimum_count` | Minimum occurrences for a tag to appear in UI |\n| `tags.sections[].name` | Tag section display name |\n| `tags.sections[].enabled_for` | Categories where this section applies |\n| `tags.sections[].keywords` | List of recognized tag keywords |\n\nTags from GitLab projects that match the keywords appear organized under their respective sections in the SharingHub UI.\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:122-150]()\n\n### Alert Configuration\n\nConfigure optional informational alerts displayed in the web UI:\n\n```yaml\nalerts:\n  timeout: 3\n  type: info\n  title: \"Welcome to SharingHub\"\n  message: \"To see all projects and unlock all features, please login...\"\n  locales:\n    fr:\n      title: \"Bienvenue sur le SharingHub\"\n      message: \"Pour voir tous les projets et dbloquer toutes les fonctionnalits, veuillez vous connecter...\"\n```\n\n| Field | Description |\n|-------|-------------|\n| `alerts.timeout` | Display duration in seconds (0 = persistent) |\n| `alerts.type` | Alert type: `info`, `warning`, `error` |\n| `alerts.title` | Alert title |\n| `alerts.message` | Alert message text |\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:152-160]()\n\n### Container Image Configuration\n\nConfigure the SharingHub container image:\n\n```yaml\nimage:\n  repository: eoepca/sharinghub\n  pullPolicy: IfNotPresent\n  tag: \"latest\"\n```\n\nThe `eoepca/sharinghub` image is built from the SharingHub repository and published to Docker Hub. For production, pin to a specific version tag instead of `latest`.\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:162-166]()\n\n### Ingress Configuration\n\nConfigure the Ingress resource for external access:\n\n```yaml\ningress:\n  enabled: true\n  className: \"nginx\"\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/proxy-body-size: 10g\n  hosts:\n    - host: sharinghub.\u003cdomain_name\u003e\n      paths:\n        - path: /\n          pathType: ImplementationSpecific\n  tls:\n    - secretName: sharinghub.\u003cdomain_name\u003e-tls\n      hosts:\n        - sharinghub.\u003cdomain_name\u003e\n```\n\nIngress configuration fields:\n\n| Field | Value | Purpose |\n|-------|-------|---------|\n| `ingress.className` | `nginx` | Uses NGINX Ingress Controller |\n| `annotations.cert-manager.io/cluster-issuer` | `letsencrypt-prod` | Automated TLS certificate provisioning |\n| `annotations.nginx.ingress.kubernetes.io/ssl-redirect` | `\"true\"` | Force HTTPS |\n| `annotations.nginx.ingress.kubernetes.io/proxy-body-size` | `10g` | Allow large file uploads |\n| `tls[].secretName` | `sharinghub.\u003cdomain_name\u003e-tls` | Kubernetes secret for TLS certificate |\n\nReplace `\u003cdomain_name\u003e` with your actual domain (e.g., `example.com`  `sharinghub.example.com`).\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:168-183]()\n\n### S3 Integration (Optional)\n\nIf using S3 for storing model artifacts and assets, add S3 configuration:\n\n```yaml\nconfig: |-\n  s3:\n    enable: true\n    bucket: \u003cs3-bucket\u003e\n    region: \u003cs3-region\u003e\n    endpoint: https://\u003cs3-endpoint\u003e\n```\n\nS3 configuration fields:\n\n| Field | Description | Example |\n|-------|-------------|---------|\n| `s3.enable` | Enable S3 integration | `true` / `false` |\n| `s3.bucket` | S3 bucket name | `mlops-artifacts` |\n| `s3.region` | AWS region | `eu-west-1` |\n| `s3.endpoint` | S3-compatible endpoint URL | `https://s3.amazonaws.com` |\n\nWhen enabled, SharingHub can:\n- Upload model artifacts to S3 from the web UI\n- Generate STAC assets pointing to S3 URLs\n- Provide presigned URLs for artifact downloads\n\nThis feature is particularly useful when categories have `features.store-s3: enable`.\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:199-206]()\n\n## Complete Configuration Example\n\nBelow is the complete ArgoCD Application manifest with all sections integrated:\n\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: sharinghub\n  namespace: argocd\nspec:\n  destination:\n    namespace: sharinghub\n    server: https://kubernetes.default.svc\n  project: default\n  source:\n    repoURL: https://github.com/csgroup-oss/sharinghub.git\n    path: deploy/helm/sharinghub\n    targetRevision: \"0.4.0\"\n    helm:\n      valuesObject:\n        config: |-\n          gitlab:\n            url: https://gitlab.\u003cdomain_name\u003e\n          docs:\n            url: https://sharinghub.\u003cdomain_name\u003e/docs\n          stac:\n            projects:\n              cache-timeout: 30\n            extensions:\n              eo: https://stac-extensions.github.io/eo/v1.1.0/schema.json\n              label: https://stac-extensions.github.io/label/v1.0.1/schema.json\n              sci: https://stac-extensions.github.io/scientific/v1.0.0/schema.json\n              ml-model: https://stac-extensions.github.io/ml-model/v1.0.0/schema.json\n            root:\n              id: gitlab-cs\n              title: SharingHub brings your data and models closer.\n              description: Your platform for collaborating on ML and NLP projects store in [GitLab](https://gitlab.com) instance STAC catalog.\n            categories:\n              - ai-model:\n                  title: \"AI Models\"\n                  description: \"AI models are the core of our platform, go and browse them to discover our models.\"\n                  gitlab_topic: sharinghub:aimodel\n                  features:\n                    map-viewer: enable\n                    store-s3: enable\n                    mlflow: enable\n              - dataset:\n                  title: \"Datasets\"\n                  description: \"Datasets are very important in the process of training an AI, discover those that we put at your disposal.\"\n                  gitlab_topic: sharinghub:dataset\n                  features:\n                    map-viewer: enable\n                    store-s3: enable\n                    mlflow: disable\n          tags:\n            gitlab:\n              minimum_count: 1\n            sections:\n              - name: \"Computer Vision\"\n                enabled_for:\n                  - ai-model\n                  - dataset\n                keywords:\n                  - \"Image qualification\"\n                  - \"Object detection\"\n                  - \"Image segmentation\"\n              - name: \"Tabular\"\n                keywords:\n                  - \"Tabular Classification\"\n                  - \"Tabular Regression\"\n                enabled_for:\n                  - ai-model\n                  - dataset\n          # Optional S3 configuration\n          s3:\n            enable: true\n            bucket: \u003cs3-bucket\u003e\n            region: \u003cs3-region\u003e\n            endpoint: https://\u003cs3-endpoint\u003e\n        image:\n          repository: eoepca/sharinghub\n          pullPolicy: IfNotPresent\n          tag: \"latest\"\n        ingress:\n          enabled: true\n          className: \"nginx\"\n          annotations:\n            cert-manager.io/cluster-issuer: letsencrypt-prod\n            nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n            nginx.ingress.kubernetes.io/proxy-body-size: 10g\n          hosts:\n            - host: sharinghub.\u003cdomain_name\u003e\n              paths:\n                - path: /\n                  pathType: ImplementationSpecific\n          tls:\n            - secretName: sharinghub.\u003cdomain_name\u003e-tls\n              hosts:\n                - sharinghub.\u003cdomain_name\u003e\n  syncPolicy:\n    syncOptions:\n      - FailOnSharedResource=true\n      - CreateNamespace=true\n    automated:\n      selfHeal: true\n```\n\nReplace the following placeholders:\n- `\u003cdomain_name\u003e`: Your domain name (e.g., `example.com`)\n- `\u003cs3-bucket\u003e`: S3 bucket name (if using S3)\n- `\u003cs3-region\u003e`: AWS region (if using S3)\n- `\u003cs3-endpoint\u003e`: S3 endpoint URL (if using S3)\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:49-191]()\n\n## Deployment Process\n\nAfter configuring the `sharinghub.yaml` manifest, deploy SharingHub:\n\n```bash\nkubectl apply -f sharinghub.yaml\n```\n\nArgoCD will:\n1. Detect the new Application resource\n2. Clone the Helm chart from `https://github.com/csgroup-oss/sharinghub.git`\n3. Render the chart with provided values\n4. Create the `sharinghub` namespace (if it doesn't exist)\n5. Deploy Kubernetes resources:\n   - `Deployment` with `eoepca/sharinghub` container\n   - `Service` for internal cluster communication\n   - `Ingress` with TLS certificate request\n   - `ConfigMap` for server configuration\n\nMonitor deployment progress:\n\n```bash\n# Watch ArgoCD Application status\nkubectl get application sharinghub -n argocd -w\n\n# Watch Pod creation\nkubectl get pods -n sharinghub -w\n\n# Check deployment logs\nkubectl logs -n sharinghub -l app.kubernetes.io/name=sharinghub -f\n```\n\n```mermaid\ngraph TB\n    subgraph \"kubectl\"\n        APPLY[\"kubectl apply -f\u003cbr/\u003esharinghub.yaml\"]\n    end\n    \n    subgraph \"ArgoCD Control Plane\"\n        APP_CONTROLLER[\"Application Controller\u003cbr/\u003eDetects new Application\"]\n        REPO_SERVER[\"Repo Server\u003cbr/\u003eClones csgroup-oss/sharinghub\"]\n        HELM_RENDER[\"Helm Render\u003cbr/\u003eTemplate with valuesObject\"]\n    end\n    \n    subgraph \"Kubernetes API\"\n        API[\"API Server\"]\n        WATCH[\"Watch Application\u003cbr/\u003ekubectl get application\"]\n    end\n    \n    subgraph \"sharinghub Namespace\"\n        NAMESPACE[\"Namespace: sharinghub\u003cbr/\u003e(auto-created)\"]\n        DEPLOYMENT[\"Deployment\u003cbr/\u003esharinghub\"]\n        SERVICE[\"Service\u003cbr/\u003esharinghub\"]\n        INGRESS[\"Ingress\u003cbr/\u003esharinghub.domain\"]\n        CONFIGMAP[\"ConfigMap\u003cbr/\u003esharinghub-config\"]\n        POD[\"Pod\u003cbr/\u003esharinghub-xxxxx\"]\n    end\n    \n    subgraph \"cert-manager\"\n        CERTMGR[\"Certificate Controller\"]\n        CERT_SECRET[\"Secret\u003cbr/\u003esharinghub.domain-tls\"]\n    end\n    \n    APPLY --\u003e API\n    API --\u003e APP_CONTROLLER\n    APP_CONTROLLER --\u003e REPO_SERVER\n    REPO_SERVER --\u003e HELM_RENDER\n    HELM_RENDER --\u003e API\n    \n    API --\u003e NAMESPACE\n    NAMESPACE --\u003e DEPLOYMENT\n    NAMESPACE --\u003e SERVICE\n    NAMESPACE --\u003e INGRESS\n    NAMESPACE --\u003e CONFIGMAP\n    \n    DEPLOYMENT --\u003e POD\n    INGRESS --\u003e CERTMGR\n    CERTMGR --\u003e CERT_SECRET\n    \n    WATCH --\u003e APP_CONTROLLER\n```\n\n**ArgoCD deployment reconciliation flow**\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:210-214]()\n\n## Verification\n\nVerify the deployment is successful:\n\n### Check Pod Status\n\n```bash\nkubectl get pods -n sharinghub\n```\n\nExpected output:\n```\nNAME                          READY   STATUS    RESTARTS   AGE\nsharinghub-xxxxxxxxxx-xxxxx   1/1     Running   0          2m\n```\n\n### Check Ingress and Certificate\n\n```bash\nkubectl get ingress -n sharinghub\nkubectl get certificate -n sharinghub\n```\n\nVerify the Ingress has an ADDRESS and the certificate is READY.\n\n### Access SharingHub Web UI\n\nNavigate to `https://sharinghub.\u003cdomain_name\u003e` in a web browser. You should see:\n- The SharingHub landing page\n- Categories configured in `stac.categories` (e.g., \"AI Models\", \"Datasets\")\n- Login option (redirects to GitLab OAuth)\n\n### Test STAC API\n\nTest the STAC API root endpoint:\n\n```bash\ncurl https://sharinghub.\u003cdomain_name\u003e/api/stac/\n```\n\nExpected response:\n```json\n{\n  \"id\": \"gitlab-cs\",\n  \"type\": \"Catalog\",\n  \"stac_version\": \"1.0.0\",\n  \"title\": \"SharingHub brings your data and models closer.\",\n  \"description\": \"Your platform for collaborating on ML and NLP projects...\",\n  \"links\": [...]\n}\n```\n\n### Test Authentication Flow\n\n1. Click \"Login\" in the SharingHub UI\n2. Redirect to GitLab OAuth consent screen\n3. Approve access\n4. Redirect back to SharingHub with authenticated session\n\nIf authentication fails, verify:\n- GitLab OAuth application callback URL matches SharingHub Ingress host\n- `sharinghub-oidc` secret contains correct `client-id` and `client-secret`\n- GitLab is accessible from the SharingHub Pod\n\n### View Logs\n\nIf issues occur, check SharingHub logs:\n\n```bash\nkubectl logs -n sharinghub -l app.kubernetes.io/name=sharinghub --tail=100\n```\n\nCommon log indicators:\n- `Connected to GitLab: \u003cgitlab-url\u003e` - Successful GitLab connection\n- `STAC catalog initialized` - STAC catalog generation successful\n- `OAuth authentication successful` - User login successful\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:1-215]()\n\n## Configuration Reference\n\nFor detailed configuration options beyond this deployment guide, refer to:\n- [SharingHub Configuration](#6.1) - Complete configuration reference\n- [SharingHub README](https://github.com/csgroup-oss/sharinghub/blob/main/README.md) - Upstream documentation\n- [CONFIGURATION.md](https://github.com/csgroup-oss/sharinghub-server/blob/main/CONFIGURATION.md) - Server configuration details\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:208]()\n\n## Next Steps\n\nAfter deploying SharingHub:\n1. Deploy MLflow SharingHub for experiment tracking - see [MLflow SharingHub Deployment](#5.4)\n2. Create GitLab projects with appropriate topics (e.g., `sharinghub:aimodel`)\n3. Configure project metadata for STAC item generation\n4. Test model registration and STAC catalog population\n\nSources: [docs/admin/deployment-guide/components/sharinghub.md:1-215]()"])</script><script>self.__next_f.push([1,"27:T54a5,"])</script><script>self.__next_f.push([1,"# MLflow SharingHub Deployment\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/deployment-guide/components/mlflow-sharinghub.md](docs/admin/deployment-guide/components/mlflow-sharinghub.md)\n\n\u003c/details\u003e\n\n\n\nThis document provides step-by-step instructions for deploying MLflow SharingHub on a Kubernetes cluster using ArgoCD and Helm. MLflow SharingHub extends MLflow with SharingHub integration for permission management and automatic model publication to the STAC catalog.\n\n**Scope**: This page covers the deployment process for MLflow SharingHub, including preparation steps, secret creation, ArgoCD Application manifest configuration, and verification. For detailed configuration options, see [MLflow SharingHub Configuration](#6.2). For prerequisites and overall deployment architecture, see [Prerequisites and Architecture](#5.1). This deployment assumes that GitLab ([GitLab Deployment](#5.2)) and SharingHub ([SharingHub Deployment](#5.3)) are already deployed and operational.\n\n## Overview\n\nMLflow SharingHub is a custom MLflow deployment that integrates with SharingHub for:\n\n- **Permission Management**: Delegates project access control to SharingHub/GitLab\n- **Automatic Model Publication**: Registered models are automatically published as STAC items\n- **Experiment Tracking**: Provides the MLflow Tracking API for logging metrics, parameters, and artifacts\n- **Model Registry**: Manages model versions and lifecycle stages\n\nThe deployment uses the Helm chart from the [csgroup-oss/mlflow-sharinghub](https://github.com/csgroup-oss/mlflow-sharinghub) repository and is managed via ArgoCD for GitOps-style deployment.\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:1-8]()\n\n## Deployment Architecture\n\nThe following diagram shows the Kubernetes resources created during MLflow SharingHub deployment and their relationships:\n\n```mermaid\ngraph TB\n    subgraph \"argocd namespace\"\n        ArgoApp[\"ArgoCD Application\u003cbr/\u003ename: mlflow-sharinghub\"]\n    end\n    \n    subgraph \"sharinghub namespace\"\n        subgraph \"MLflow SharingHub Deployment\"\n            MLFPod[\"Pod\u003cbr/\u003emlflow-sharinghub-*\"]\n            MLFContainer[\"Container\u003cbr/\u003eimage: eoepca/mlflow-sharinghub:latest\"]\n        end\n        \n        subgraph \"PostgreSQL StatefulSet\"\n            PGPod[\"Pod\u003cbr/\u003emlflow-sharinghub-postgresql-0\"]\n            PGPVC[\"PersistentVolumeClaim\u003cbr/\u003edata-mlflow-sharinghub-postgresql-0\"]\n        end\n        \n        subgraph \"Secrets\"\n            SecretKey[\"Secret\u003cbr/\u003emlflow-sharinghub\u003cbr/\u003e(secret-key)\"]\n            SecretS3[\"Secret\u003cbr/\u003emlflow-sharinghub-s3\u003cbr/\u003e(access-key-id, secret-access-key)\"]\n            SecretPG[\"Secret\u003cbr/\u003emlflow-sharinghub-postgres\u003cbr/\u003e(password, postgres-password)\"]\n        end\n        \n        subgraph \"Services\"\n            MLFSvc[\"Service\u003cbr/\u003emlflow-sharinghub\u003cbr/\u003eport: 5000\"]\n            PGSvc[\"Service\u003cbr/\u003emlflow-sharinghub-postgresql\u003cbr/\u003eport: 5432\"]\n        end\n        \n        subgraph \"Ingress\"\n            MLFIngress[\"Ingress\u003cbr/\u003ehost: sharinghub.domain\u003cbr/\u003epath: /mlflow/\"]\n            TLSSecret[\"Secret\u003cbr/\u003esharinghub.domain-tls\u003cbr/\u003e(cert-manager)\"]\n        end\n    end\n    \n    subgraph \"External Dependencies\"\n        SHService[\"SharingHub Service\u003cbr/\u003ehttps://sharinghub.domain\"]\n        S3Bucket[\"S3 Bucket\u003cbr/\u003eArtifacts Storage\"]\n        CertManager[\"cert-manager\u003cbr/\u003eTLS Certificate Provisioning\"]\n    end\n    \n    ArgoApp --\u003e|\"deploys\"| MLFPod\n    ArgoApp --\u003e|\"deploys\"| PGPod\n    ArgoApp --\u003e|\"deploys\"| MLFIngress\n    \n    MLFPod --\u003e MLFContainer\n    MLFContainer --\u003e|\"mounts\"| SecretKey\n    MLFContainer --\u003e|\"mounts\"| SecretS3\n    MLFContainer --\u003e|\"mounts\"| SecretPG\n    \n    MLFContainer --\u003e|\"connects to\"| PGSvc\n    MLFContainer --\u003e|\"stores artifacts in\"| S3Bucket\n    MLFContainer --\u003e|\"checks permissions via\"| SHService\n    \n    PGPod --\u003e|\"uses\"| PGPVC\n    PGPod --\u003e|\"exposes\"| PGSvc\n    \n    MLFPod --\u003e|\"exposes\"| MLFSvc\n    MLFIngress --\u003e|\"routes to\"| MLFSvc\n    MLFIngress --\u003e|\"uses\"| TLSSecret\n    \n    CertManager --\u003e|\"provisions\"| TLSSecret\n```\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:29-96]()\n\n## Prerequisites\n\nBefore deploying MLflow SharingHub, ensure the following are in place:\n\n| Prerequisite | Description | Reference |\n|-------------|-------------|-----------|\n| Kubernetes Cluster | Running cluster with ArgoCD installed | [Prerequisites and Architecture](#5.1) |\n| SharingHub | Deployed and accessible | [SharingHub Deployment](#5.3) |\n| GitLab | Deployed and accessible | [GitLab Deployment](#5.2) |\n| S3 Storage | S3 bucket for artifacts storage | [Prerequisites and Architecture](#5.1) |\n| kubectl | Command-line access to cluster | [Prerequisites and Architecture](#5.1) |\n| cert-manager | For TLS certificate automation | [Prerequisites and Architecture](#5.1) |\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:3-4]()\n\n## Preparation Steps\n\n### Create Secret Key\n\nMLflow SharingHub requires a secret key for Flask session security. Generate and create the secret:\n\n```bash\nkubectl create secret generic mlflow-sharinghub \\\n  --from-literal secret-key=\"\u003crandom-secret-key\u003e\" \\\n  --namespace sharinghub\n```\n\n**Secret Structure**: The `mlflow-sharinghub` secret must contain:\n- `secret-key`: A randomly generated string (recommended: 32+ characters)\n\nThis secret is mounted by the MLflow SharingHub pod and used for cryptographic operations.\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:11-17]()\n\n### Create S3 Secrets\n\nMLflow stores model artifacts in S3 object storage. Create the S3 credentials secret:\n\n```bash\nkubectl create secret generic mlflow-sharinghub-s3 \\\n  --from-literal access-key-id=\"\u003caccess-key\u003e\" \\\n  --from-literal secret-access-key=\"\u003csecret-key\u003e\" \\\n  --namespace sharinghub\n```\n\n**Secret Structure**: The `mlflow-sharinghub-s3` secret must contain:\n- `access-key-id`: S3 access key\n- `secret-access-key`: S3 secret access key\n\nThese credentials must have read/write permissions to the S3 bucket specified in the configuration.\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:19-25]()\n\n### PostgreSQL Secret (Optional)\n\nThe Helm chart automatically creates a PostgreSQL secret (`mlflow-sharinghub-postgres`) for the database password. If you need to use a pre-existing PostgreSQL instance or want to specify the password manually, create the secret before deployment:\n\n```bash\nkubectl create secret generic mlflow-sharinghub-postgres \\\n  --from-literal password=\"\u003cpostgres-password\u003e\" \\\n  --from-literal postgres-password=\"\u003cpostgres-password\u003e\" \\\n  --namespace sharinghub\n```\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:87-90]()\n\n## Configuration Structure\n\nThe following diagram maps the ArgoCD Application manifest structure to the actual Helm chart values:\n\n```mermaid\ngraph LR\n    subgraph \"ArgoCD Application Manifest\"\n        AppMeta[\"metadata:\u003cbr/\u003ename: mlflow-sharinghub\u003cbr/\u003enamespace: argocd\"]\n        AppSpec[\"spec.destination:\u003cbr/\u003enamespace: sharinghub\"]\n        AppSource[\"spec.source:\u003cbr/\u003erepoURL, path, targetRevision\"]\n        AppHelm[\"spec.source.helm.valuesObject\"]\n    end\n    \n    subgraph \"Helm Values Categories\"\n        ImageVals[\"image:\u003cbr/\u003erepository, tag\"]\n        MLFVals[\"mlflowSharinghub:\u003cbr/\u003eartifactsDestination\u003cbr/\u003esharinghubUrl\u003cbr/\u003esharinghubStacCollection\u003cbr/\u003esharinghubAuthDefaultToken\"]\n        S3Vals[\"s3:\u003cbr/\u003eenabled\u003cbr/\u003eendpointUrl\"]\n        PersistVals[\"persistence:\u003cbr/\u003eenabled\"]\n        IngressVals[\"ingress:\u003cbr/\u003eenabled, className\u003cbr/\u003eannotations, hosts, tls\"]\n        PGVals[\"postgresql:\u003cbr/\u003eenabled\u003cbr/\u003eauth.existingSecret\"]\n    end\n    \n    subgraph \"Deployed Resources\"\n        DeployRes[\"Deployment\u003cbr/\u003emlflow-sharinghub\"]\n        SvcRes[\"Service\u003cbr/\u003emlflow-sharinghub\"]\n        IngressRes[\"Ingress\u003cbr/\u003esharinghub.domain/mlflow\"]\n        PGRes[\"StatefulSet\u003cbr/\u003emlflow-sharinghub-postgresql\"]\n    end\n    \n    AppHelm --\u003e ImageVals\n    AppHelm --\u003e MLFVals\n    AppHelm --\u003e S3Vals\n    AppHelm --\u003e PersistVals\n    AppHelm --\u003e IngressVals\n    AppHelm --\u003e PGVals\n    \n    ImageVals --\u003e DeployRes\n    MLFVals --\u003e DeployRes\n    S3Vals --\u003e DeployRes\n    IngressVals --\u003e IngressRes\n    PGVals --\u003e PGRes\n    \n    DeployRes --\u003e SvcRes\n```\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:46-90]()\n\n## ArgoCD Application Manifest\n\nCreate the ArgoCD Application manifest file `mlflow-sharinghub.yaml`:\n\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: mlflow-sharinghub\n  namespace: argocd\nspec:\n  destination:\n    namespace: sharinghub\n    server: https://kubernetes.default.svc\n  project: default\n  source:\n    repoURL: https://github.com/csgroup-oss/mlflow-sharinghub.git\n    path: deploy/helm/mlflow-sharinghub\n    targetRevision: \"0.2.0\"\n    helm:\n      valuesObject:\n        image:\n          repository: eoepca/mlflow-sharinghub\n          tag: latest\n\n        mlflowSharinghub:\n          artifactsDestination: s3://\u003cbucket\u003e\n          sharinghubUrl: https://sharinghub.\u003cdomain_name\u003e\n          sharinghubStacCollection: ai-model\n          sharinghubAuthDefaultToken: false\n\n        s3:\n          enabled: true\n          endpointUrl: https://\u003cs3_endpoint\u003e\n\n        persistence:\n          enabled: false\n\n        podSecurityContext:\n          fsGroup: 999\n\n        ingress:\n          enabled: true\n          className: nginx\n          annotations:\n            cert-manager.io/cluster-issuer: letsencrypt-prod\n            nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n            nginx.ingress.kubernetes.io/proxy-body-size: 10g\n            nginx.ingress.kubernetes.io/configuration-snippet: |\n              proxy_set_header X-Script-Name /mlflow;\n              rewrite ^/mlflow/(.*)$ /$1 break;\n          hosts:\n            - host: sharinghub.\u003cdomain_name\u003e\n              paths:\n                - path: /mlflow/\n                  pathType: ImplementationSpecific\n          tls:\n            - secretName: sharinghub.\u003cdomain_name\u003e-tls\n              hosts:\n                - sharinghub.\u003cdomain_name\u003e\n        postgresql:\n          enabled: true\n          auth:\n            existingSecret: mlflow-sharinghub-postgres\n\n  syncPolicy:\n    syncOptions:\n      - FailOnSharedResource=true\n      - CreateNamespace=true\n```\n\n### Configuration Parameters\n\nReplace the following placeholders in the manifest:\n\n| Parameter | Description | Example |\n|-----------|-------------|---------|\n| `\u003cdomain_name\u003e` | Your platform's domain name | `example.com` |\n| `\u003cbucket\u003e` | S3 bucket name for artifacts | `mlflow-artifacts` |\n| `\u003cs3_endpoint\u003e` | S3 provider endpoint URL | `https://s3.amazonaws.com` |\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:29-103]()\n\n## Key Configuration Sections\n\n### Image Configuration\n\n```yaml\nimage:\n  repository: eoepca/mlflow-sharinghub\n  tag: latest\n```\n\nSpecifies the Docker image for MLflow SharingHub. The `eoepca/mlflow-sharinghub` image extends the official MLflow image with SharingHub integration.\n\n### MLflow SharingHub Settings\n\n```yaml\nmlflowSharinghub:\n  artifactsDestination: s3://\u003cbucket\u003e\n  sharinghubUrl: https://sharinghub.\u003cdomain_name\u003e\n  sharinghubStacCollection: ai-model\n  sharinghubAuthDefaultToken: false\n```\n\n| Parameter | Description |\n|-----------|-------------|\n| `artifactsDestination` | S3 bucket URI where model artifacts are stored |\n| `sharinghubUrl` | URL of the SharingHub instance for permission checks |\n| `sharinghubStacCollection` | STAC collection where models are published (typically `ai-model`) |\n| `sharinghubAuthDefaultToken` | Whether to allow unauthenticated access with a default token (set to `false` for production) |\n\n### S3 Configuration\n\n```yaml\ns3:\n  enabled: true\n  endpointUrl: https://\u003cs3_endpoint\u003e\n```\n\nEnables S3 artifacts storage. The `mlflow-sharinghub-s3` secret provides the credentials. Set `endpointUrl` to your S3 provider's endpoint (AWS, MinIO, etc.).\n\n### Ingress Configuration\n\n```yaml\ningress:\n  enabled: true\n  className: nginx\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/proxy-body-size: 10g\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      proxy_set_header X-Script-Name /mlflow;\n      rewrite ^/mlflow/(.*)$ /$1 break;\n  hosts:\n    - host: sharinghub.\u003cdomain_name\u003e\n      paths:\n        - path: /mlflow/\n          pathType: ImplementationSpecific\n  tls:\n    - secretName: sharinghub.\u003cdomain_name\u003e-tls\n      hosts:\n        - sharinghub.\u003cdomain_name\u003e\n```\n\n**Key Annotations**:\n- `cert-manager.io/cluster-issuer`: Automatic TLS certificate provisioning via cert-manager\n- `nginx.ingress.kubernetes.io/proxy-body-size: 10g`: Allows large artifact uploads (adjust as needed)\n- `configuration-snippet`: Configures MLflow to run under the `/mlflow/` path by setting `X-Script-Name` and rewriting URLs\n\n**Path Configuration**: MLflow is exposed at `https://sharinghub.\u003cdomain_name\u003e/mlflow/`, sharing the same domain as SharingHub but under a different path.\n\n### PostgreSQL Configuration\n\n```yaml\npostgresql:\n  enabled: true\n  auth:\n    existingSecret: mlflow-sharinghub-postgres\n```\n\nDeploys a PostgreSQL StatefulSet for MLflow's backend store (experiments, runs, metrics). The `mlflow-sharinghub-postgres` secret provides the database password.\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:46-90]()\n\n## Deployment Execution\n\nApply the ArgoCD Application manifest to deploy MLflow SharingHub:\n\n```bash\nkubectl apply -f mlflow-sharinghub.yaml\n```\n\nArgoCD will:\n1. Clone the Helm chart from `https://github.com/csgroup-oss/mlflow-sharinghub.git`\n2. Render the chart using the provided `valuesObject`\n3. Create the `sharinghub` namespace if it doesn't exist\n4. Deploy the MLflow SharingHub Deployment, Service, and Ingress\n5. Deploy the PostgreSQL StatefulSet and Service\n6. Configure cert-manager to provision the TLS certificate\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:106-110]()\n\n## Integration Flow\n\nThe following diagram shows how MLflow SharingHub integrates with SharingHub and other components during typical operations:\n\n```mermaid\nsequenceDiagram\n    participant User as \"ML Developer\"\n    participant MLFClient as \"MLflow Client\u003cbr/\u003e(Python SDK)\"\n    participant MLFServer as \"MLflow Server\u003cbr/\u003emlflow-sharinghub\"\n    participant SHServer as \"SharingHub\u003cbr/\u003eSTAC API\"\n    participant GitLab as \"GitLab\u003cbr/\u003eProjects API\"\n    participant PostgreSQL as \"PostgreSQL\u003cbr/\u003eBackend Store\"\n    participant S3 as \"S3\u003cbr/\u003eArtifacts Store\"\n    \n    User-\u003e\u003eMLFClient: \"mlflow.set_tracking_uri()\"\n    User-\u003e\u003eMLFClient: \"mlflow.log_metric()\"\n    MLFClient-\u003e\u003eMLFServer: \"POST /api/2.0/mlflow/runs/log-metric\"\n    MLFServer-\u003e\u003eSHServer: \"Check project permissions\"\n    SHServer-\u003e\u003eGitLab: \"Validate user access to project\"\n    GitLab--\u003e\u003eSHServer: \"Access granted\"\n    SHServer--\u003e\u003eMLFServer: \"Permission granted\"\n    MLFServer-\u003e\u003ePostgreSQL: \"INSERT metric data\"\n    PostgreSQL--\u003e\u003eMLFServer: \"Success\"\n    MLFServer--\u003e\u003eMLFClient: \"200 OK\"\n    \n    User-\u003e\u003eMLFClient: \"mlflow.log_artifact()\"\n    MLFClient-\u003e\u003eMLFServer: \"POST /api/2.0/mlflow/artifacts\"\n    MLFServer-\u003e\u003eSHServer: \"Check project permissions\"\n    SHServer--\u003e\u003eMLFServer: \"Permission granted\"\n    MLFServer-\u003e\u003eS3: \"PUT object to s3://bucket/path\"\n    S3--\u003e\u003eMLFServer: \"Success\"\n    MLFServer-\u003e\u003ePostgreSQL: \"UPDATE artifact location\"\n    MLFServer--\u003e\u003eMLFClient: \"200 OK\"\n    \n    User-\u003e\u003eMLFClient: \"mlflow.register_model()\"\n    MLFClient-\u003e\u003eMLFServer: \"POST /api/2.0/mlflow/registered-models/create\"\n    MLFServer-\u003e\u003ePostgreSQL: \"INSERT model registration\"\n    MLFServer-\u003e\u003eSHServer: \"POST /api/v1/stac/collections/ai-model/items\"\n    SHServer-\u003e\u003eGitLab: \"Create/update STAC metadata\"\n    GitLab--\u003e\u003eSHServer: \"Success\"\n    SHServer--\u003e\u003eMLFServer: \"STAC item created\"\n    MLFServer--\u003e\u003eMLFClient: \"200 OK\"\n```\n\n**Key Integration Points**:\n\n1. **Permission Check**: Every MLflow API request triggers a permission check with SharingHub, which validates against GitLab project access\n2. **Metadata Storage**: MLflow metadata (experiments, runs, metrics, parameters) is stored in PostgreSQL\n3. **Artifact Storage**: Model artifacts, plots, and files are stored in S3\n4. **Model Publication**: When a model is registered, MLflow automatically creates/updates a STAC item in SharingHub's catalog\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:52-56]()\n\n## Verification\n\nAfter deployment, verify that MLflow SharingHub is running correctly:\n\n### Check Pod Status\n\n```bash\nkubectl get pods -n sharinghub -l app.kubernetes.io/name=mlflow-sharinghub\n```\n\nExpected output:\n```\nNAME                                  READY   STATUS    RESTARTS   AGE\nmlflow-sharinghub-xxxxxxxxxx-xxxxx    1/1     Running   0          5m\n```\n\n### Check Service\n\n```bash\nkubectl get svc -n sharinghub mlflow-sharinghub\n```\n\nExpected output:\n```\nNAME                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE\nmlflow-sharinghub   ClusterIP   10.x.x.x        \u003cnone\u003e        5000/TCP   5m\n```\n\n### Check Ingress\n\n```bash\nkubectl get ingress -n sharinghub -l app.kubernetes.io/name=mlflow-sharinghub\n```\n\nVerify that the ingress has been assigned an address and the TLS secret is present.\n\n### Access the UI\n\nNavigate to `https://sharinghub.\u003cdomain_name\u003e/mlflow/` in your browser. You should see the MLflow UI.\n\n### Check PostgreSQL\n\n```bash\nkubectl get pods -n sharinghub -l app.kubernetes.io/name=postgresql\n```\n\nExpected output:\n```\nNAME                                    READY   STATUS    RESTARTS   AGE\nmlflow-sharinghub-postgresql-0          1/1     Running   0          5m\n```\n\n### Check Logs\n\nView the MLflow SharingHub logs:\n\n```bash\nkubectl logs -n sharinghub -l app.kubernetes.io/name=mlflow-sharinghub -f\n```\n\nLook for successful startup messages and no error messages related to SharingHub connectivity, PostgreSQL, or S3.\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:29-110]()\n\n## Secret Management Summary\n\nThe following table summarizes all secrets used by MLflow SharingHub:\n\n| Secret Name | Namespace | Keys | Purpose | Created By |\n|-------------|-----------|------|---------|------------|\n| `mlflow-sharinghub` | `sharinghub` | `secret-key` | Flask session security | Manual (kubectl) |\n| `mlflow-sharinghub-s3` | `sharinghub` | `access-key-id`, `secret-access-key` | S3 artifacts access | Manual (kubectl) |\n| `mlflow-sharinghub-postgres` | `sharinghub` | `password`, `postgres-password` | PostgreSQL database access | Helm chart (automatic) or Manual |\n| `sharinghub.\u003cdomain\u003e-tls` | `sharinghub` | `tls.crt`, `tls.key` | HTTPS/TLS certificate | cert-manager (automatic) |\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:11-25](), [docs/admin/deployment-guide/components/mlflow-sharinghub.md:87-90]()\n\n## Resource Requirements\n\nThe MLflow SharingHub deployment creates the following Kubernetes resources:\n\n| Resource Type | Name | Purpose |\n|---------------|------|---------|\n| Deployment | `mlflow-sharinghub` | Runs the MLflow server application |\n| Service | `mlflow-sharinghub` | Exposes MLflow server on port 5000 |\n| StatefulSet | `mlflow-sharinghub-postgresql` | Runs PostgreSQL database |\n| Service | `mlflow-sharinghub-postgresql` | Exposes PostgreSQL on port 5432 |\n| PersistentVolumeClaim | `data-mlflow-sharinghub-postgresql-0` | PostgreSQL data storage |\n| Ingress | `mlflow-sharinghub` | Routes external traffic to MLflow server |\n| Secret | `mlflow-sharinghub-postgres` | PostgreSQL credentials (if not pre-created) |\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:87-90]()\n\n## Next Steps\n\nAfter successfully deploying MLflow SharingHub:\n\n1. **Configure MLflow Clients**: Set the tracking URI in your ML development environment:\n   ```python\n   import mlflow\n   mlflow.set_tracking_uri(\"https://sharinghub.\u003cdomain_name\u003e/mlflow\")\n   ```\n\n2. **Create Experiments**: Create experiments in the MLflow UI or via the API\n\n3. **Link to GitLab Projects**: Ensure your MLflow experiments are associated with GitLab projects for proper permission management\n\n4. **Test Model Registration**: Register a test model and verify it appears in the SharingHub STAC catalog\n\n5. **Review Configuration**: For detailed configuration options and tuning, see [MLflow SharingHub Configuration](#6.2)\n\n6. **Review Workflows**: For practical examples of using MLflow SharingHub in model training workflows, see [Model Training Workflow](#4.1) and [Flood Detection Example](#4.3)\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:104]()\n\n## Troubleshooting\n\nCommon issues and solutions:\n\n| Issue | Possible Cause | Solution |\n|-------|---------------|----------|\n| Pod fails to start | Missing secrets | Verify `mlflow-sharinghub` and `mlflow-sharinghub-s3` secrets exist |\n| Cannot connect to SharingHub | Wrong `sharinghubUrl` | Check that SharingHub is deployed and URL is correct |\n| Artifact upload fails | S3 credentials invalid | Verify `mlflow-sharinghub-s3` secret has correct credentials |\n| Database connection error | PostgreSQL not ready | Check PostgreSQL pod status and logs |\n| TLS certificate not provisioned | cert-manager issue | Check cert-manager logs and ingress annotations |\n| Permission denied errors | SharingHub integration issue | Verify SharingHub can communicate with GitLab |\n\nFor more troubleshooting guidance, see [Operations and Maintenance](#8).\n\n**Sources**: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:1-110]()"])</script><script>self.__next_f.push([1,"28:T3992,"])</script><script>self.__next_f.push([1,"# Configuration Reference\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/configuration.md](docs/admin/configuration.md)\n\n\u003c/details\u003e\n\n\n\nThis page provides a comprehensive overview of configuration for the EOEPCA MLOps Building Block components. It explains the configuration architecture, sources, and integration points between GitLab, SharingHub, and MLflow SharingHub.\n\nFor detailed configuration options for specific components, see:\n- [SharingHub Configuration](#6.1) - Complete reference for SharingHub server settings, STAC API, categories, and integrations\n- [MLflow SharingHub Configuration](#6.2) - Configuration options for experiment tracking and model registry\n\nFor deployment procedures that use these configurations, see [Deployment Guide](#5).\n\n## Configuration Architecture\n\nThe MLOps Building Block uses a multi-layered configuration approach where each component has distinct configuration concerns, but they must be properly integrated to work together as a unified system.\n\n```mermaid\ngraph TB\n    subgraph \"Configuration Layers\"\n        HELM[\"Helm Values\u003cbr/\u003e(values.yaml)\"]\n        ENV[\"Environment Variables\"]\n        SECRETS[\"Kubernetes Secrets\"]\n        CONFIG[\"YAML Configuration\u003cbr/\u003e(embedded in values)\"]\n    end\n    \n    subgraph \"Component Configuration\"\n        GLCONFIG[\"GitLab Configuration\u003cbr/\u003egitlab-values.yaml\"]\n        SHCONFIG[\"SharingHub Configuration\u003cbr/\u003esharinghub-values.yaml\"]\n        MLFCONFIG[\"MLflow SharingHub Configuration\u003cbr/\u003emlflow-sharinghub-values.yaml\"]\n    end\n    \n    subgraph \"Configuration Content\"\n        INTEGRATION[\"Integration Settings\u003cbr/\u003eURLs, OAuth, Tokens\"]\n        STORAGE[\"Storage Settings\u003cbr/\u003eS3, PostgreSQL\"]\n        STAC[\"STAC Catalog\u003cbr/\u003eCategories, Extensions\"]\n        SECURITY[\"Security Settings\u003cbr/\u003eOIDC, Sessions, TLS\"]\n    end\n    \n    HELM --\u003e GLCONFIG\n    HELM --\u003e SHCONFIG\n    HELM --\u003e MLFCONFIG\n    \n    ENV --\u003e GLCONFIG\n    ENV --\u003e SHCONFIG\n    ENV --\u003e MLFCONFIG\n    \n    SECRETS --\u003e GLCONFIG\n    SECRETS --\u003e SHCONFIG\n    SECRETS --\u003e MLFCONFIG\n    \n    CONFIG --\u003e SHCONFIG\n    CONFIG --\u003e MLFCONFIG\n    \n    GLCONFIG --\u003e INTEGRATION\n    SHCONFIG --\u003e INTEGRATION\n    MLFCONFIG --\u003e INTEGRATION\n    \n    GLCONFIG --\u003e STORAGE\n    SHCONFIG --\u003e STORAGE\n    MLFCONFIG --\u003e STORAGE\n    \n    SHCONFIG --\u003e STAC\n    SHCONFIG --\u003e SECURITY\n    MLFCONFIG --\u003e SECURITY\n```\n\n**Configuration Hierarchy and Sources**\n\nSources: [docs/admin/configuration.md:1-281]()\n\n### Configuration Sources\n\nThe MLOps Building Block uses three primary configuration sources, each serving different purposes:\n\n| Source | Purpose | Usage | Security Level |\n|--------|---------|-------|----------------|\n| **Helm Values** | Deployment-time configuration | Define component behavior, resource limits, ingress rules | Public |\n| **YAML Config** | Application-level settings | Embedded in Helm values under `config` field | Public/Semi-sensitive |\n| **Environment Variables** | Runtime overrides | Override specific settings like `DEBUG`, `LOG_LEVEL` | Public |\n| **Kubernetes Secrets** | Sensitive credentials | OAuth secrets, database passwords, API tokens | Sensitive |\n\n```mermaid\ngraph LR\n    subgraph \"Configuration Priority\"\n        HIGH[\"1. Kubernetes Secrets\u003cbr/\u003e(Highest Priority)\"]\n        MED[\"2. Environment Variables\"]\n        LOW[\"3. YAML Config in Helm\"]\n        DEFAULT[\"4. Application Defaults\u003cbr/\u003e(Lowest Priority)\"]\n    end\n    \n    HIGH --\u003e APP[\"Running Application\"]\n    MED --\u003e APP\n    LOW --\u003e APP\n    DEFAULT --\u003e APP\n    \n    subgraph \"Secret Types\"\n        OAUTH[\"OAuth Secrets\u003cbr/\u003egitlab-oidc\u003cbr/\u003esharinghub-oidc\"]\n        DB[\"Database Credentials\u003cbr/\u003emlflow-sharinghub-postgres\"]\n        S3SEC[\"S3 Credentials\u003cbr/\u003esharinghub-s3\u003cbr/\u003emlflow-sharinghub-s3\"]\n        SESSION[\"Session Keys\u003cbr/\u003esharinghub-secret\u003cbr/\u003emlflow-sharinghub\"]\n    end\n    \n    OAUTH --\u003e HIGH\n    DB --\u003e HIGH\n    S3SEC --\u003e HIGH\n    SESSION --\u003e HIGH\n```\n\n**Configuration Source Priority and Secret Management**\n\nSources: [docs/admin/configuration.md:52-232]()\n\n## Component Configuration Overview\n\nEach component in the MLOps Building Block has distinct configuration requirements:\n\n| Component | Configuration Scope | Key Areas | Primary Method |\n|-----------|-------------------|-----------|----------------|\n| **GitLab** | Comprehensive | S3 storage, OIDC, LFS, backups, ingress | Helm values |\n| **SharingHub** | Extensive | Server settings, GitLab integration, STAC catalog, categories, tags, S3 store | YAML config in Helm values |\n| **MLflow SharingHub** | Lightweight | SharingHub URL, backend store, artifacts store | Helm values + secrets |\n\n### SharingHub as Central Configuration Hub\n\nSharingHub is the most heavily configured component because it acts as the integration layer between GitLab and MLflow SharingHub:\n\n```mermaid\ngraph TB\n    subgraph \"SharingHub Configuration Domains\"\n        SERVER[\"Server Settings\u003cbr/\u003eserver.debug\u003cbr/\u003eserver.log-level\u003cbr/\u003eserver.cache\"]\n        GITLAB[\"GitLab Integration\u003cbr/\u003egitlab.url\u003cbr/\u003egitlab.allow-public\u003cbr/\u003eOAuth client\"]\n        STACCONF[\"STAC API\u003cbr/\u003estac.root\u003cbr/\u003estac.categories\u003cbr/\u003estac.extensions\"]\n        MLFLOWCONF[\"MLflow Integration\u003cbr/\u003emlflow.type\u003cbr/\u003emlflow.url\"]\n        S3CONF[\"S3 Store\u003cbr/\u003es3.bucket\u003cbr/\u003es3.endpoint\u003cbr/\u003eservices.store\"]\n        TAGS[\"UI Tags\u003cbr/\u003etags.sections\u003cbr/\u003etags.gitlab\"]\n    end\n    \n    subgraph \"Configuration Usage\"\n        DISCOVERY[\"Project Discovery\u003cbr/\u003evia GitLab topics\"]\n        CATALOG[\"STAC Catalog\u003cbr/\u003eGeneration\"]\n        AUTH[\"Authentication\u003cbr/\u003e\u0026 Authorization\"]\n        STORAGE[\"Storage API\u003cbr/\u003eDVC support\"]\n    end\n    \n    GITLAB --\u003e DISCOVERY\n    GITLAB --\u003e AUTH\n    STACCONF --\u003e CATALOG\n    TAGS --\u003e CATALOG\n    MLFLOWCONF --\u003e CATALOG\n    S3CONF --\u003e STORAGE\n    SERVER --\u003e AUTH\n    SERVER --\u003e CATALOG\n    SERVER --\u003e STORAGE\n```\n\n**SharingHub Configuration Domains and Usage**\n\nSources: [docs/admin/configuration.md:7-280]()\n\n### Configuration File Structure\n\nThe SharingHub configuration is embedded in the Helm values as a YAML string under the `config` field:\n\n```yaml\n# In sharinghub-values.yaml\nconfig: |\n  server:\n    debug: false\n    log-level: INFO\n  gitlab:\n    url: https://gitlab.example.com\n    allow-public: true\n  stac:\n    root:\n      id: gitlab-cs\n      title: SharingHub STAC Catalog\n    categories:\n      - ai-model:\n          gitlab_topic: sharinghub:aimodel\n```\n\nThis structure allows the entire application configuration to be version-controlled and deployed atomically.\n\nSources: [docs/admin/configuration.md:9-15]()\n\n## Integration Configuration\n\nThe key to a functioning MLOps Building Block is proper configuration of integration points between components:\n\n```mermaid\ngraph TB\n    subgraph \"GitLab Configuration\"\n        GLURL[\"GitLab URL\"]\n        GLOAUTH[\"OAuth Application\u003cbr/\u003eclient-id, client-secret\"]\n        GLPUBLIC[\"Public Projects\u003cbr/\u003eallow-public: true/false\"]\n    end\n    \n    subgraph \"SharingHub Configuration\"\n        SHGLURL[\"gitlab.url\"]\n        SHGLOAUTH[\"OAuth client in secret\u003cbr/\u003esharinghub-oidc\"]\n        SHDEFTOKEN[\"Default Token\u003cbr/\u003e(optional)\"]\n        SHMLFURL[\"mlflow.url\"]\n        SHMLFTYPE[\"mlflow.type: mlflow-sharinghub\"]\n    end\n    \n    subgraph \"MLflow SharingHub Configuration\"\n        MLFSHURL[\"sharinghubUrl\"]\n        MLFSTACCOL[\"sharinghubStacCollection\u003cbr/\u003e(e.g., ai-model)\"]\n        MLFDEFTOKEN[\"sharinghubAuthDefaultToken\"]\n    end\n    \n    GLURL --\u003e SHGLURL\n    GLOAUTH --\u003e SHGLOAUTH\n    GLPUBLIC --\u003e SHDEFTOKEN\n    \n    SHGLOAUTH --\u003e AUTH[\"User Authentication\"]\n    SHDEFTOKEN --\u003e AUTH\n    \n    SHMLFURL --\u003e MLFSHURL\n    SHMLFTYPE --\u003e INTEGRATION[\"Integration Type\"]\n    \n    MLFSHURL --\u003e PERMCHECK[\"Permission Checking\"]\n    MLFSTACCOL --\u003e PERMCHECK\n    MLFDEFTOKEN --\u003e PERMCHECK\n```\n\n**Integration Configuration Dependencies**\n\nSources: [docs/admin/configuration.md:88-117](), [docs/admin/configuration.md:283-298]()\n\n### Critical Integration Points\n\n| Integration | Configuration Location | Purpose | Required Settings |\n|-------------|----------------------|---------|-------------------|\n| **GitLab  SharingHub** | SharingHub `gitlab` section | Project discovery, authentication | `gitlab.url`, OAuth client secret |\n| **SharingHub  MLflow** | SharingHub `mlflow` section | Model tracking integration | `mlflow.type`, `mlflow.url` |\n| **MLflow  SharingHub** | MLflow `sharinghubUrl` | Permission validation | `sharinghubUrl`, `sharinghubStacCollection` |\n| **User  GitLab** | GitLab OIDC provider | OIDC authentication | Keycloak client credentials |\n\n## Security and Secrets Management\n\nSensitive configuration values must be stored in Kubernetes secrets and mounted into the application containers:\n\n```mermaid\ngraph TB\n    subgraph \"Secret Creation\"\n        CMD1[\"kubectl create secret\u003cbr/\u003egitlab-oidc\"]\n        CMD2[\"kubectl create secret\u003cbr/\u003esharinghub-oidc\"]\n        CMD3[\"kubectl create secret\u003cbr/\u003esharinghub-s3\"]\n        CMD4[\"kubectl create secret\u003cbr/\u003emlflow-sharinghub\"]\n        CMD5[\"kubectl create secret\u003cbr/\u003emlflow-sharinghub-postgres\"]\n        CMD6[\"kubectl create secret\u003cbr/\u003emlflow-sharinghub-s3\"]\n    end\n    \n    subgraph \"Secret Contents\"\n        OAUTH_GL[\"client-id\u003cbr/\u003eclient-secret\"]\n        OAUTH_SH[\"client-id\u003cbr/\u003eclient-secret\u003cbr/\u003edefault-token (optional)\"]\n        S3_SH[\"access-key\u003cbr/\u003esecret-key\"]\n        MLF_SEC[\"secret-key\u003cbr/\u003ebackend-store-uri (optional)\"]\n        MLF_PG[\"password\u003cbr/\u003epostgres-password\"]\n        MLF_S3[\"access-key-id\u003cbr/\u003esecret-access-key\"]\n    end\n    \n    subgraph \"Mounted As\"\n        ENV_VARS[\"Environment Variables\"]\n        VOL_MOUNTS[\"Volume Mounts\"]\n    end\n    \n    CMD1 --\u003e OAUTH_GL\n    CMD2 --\u003e OAUTH_SH\n    CMD3 --\u003e S3_SH\n    CMD4 --\u003e MLF_SEC\n    CMD5 --\u003e MLF_PG\n    CMD6 --\u003e MLF_S3\n    \n    OAUTH_GL --\u003e ENV_VARS\n    OAUTH_SH --\u003e ENV_VARS\n    S3_SH --\u003e ENV_VARS\n    MLF_SEC --\u003e ENV_VARS\n    MLF_PG --\u003e ENV_VARS\n    MLF_S3 --\u003e ENV_VARS\n```\n\n**Secret Management Flow**\n\nSources: [docs/admin/configuration.md:109-117](), [docs/admin/configuration.md:229-232](), [docs/admin/configuration.md:310-347]()\n\n### Secret Types and Usage\n\n| Secret Name | Namespace | Contents | Used By | Purpose |\n|-------------|-----------|----------|---------|---------|\n| `gitlab-oidc` | `gitlab` | `client-id`, `client-secret` | GitLab | OIDC authentication with Keycloak |\n| `sharinghub-oidc` | `sharinghub` | `client-id`, `client-secret`, `default-token` | SharingHub | OAuth authentication with GitLab |\n| `sharinghub-secret` | `sharinghub` | `secret-key` | SharingHub | Session cookie signing |\n| `sharinghub-s3` | `sharinghub` | `access-key`, `secret-key` | SharingHub | S3 store API (DVC) |\n| `mlflow-sharinghub` | `sharinghub` | `secret-key`, `backend-store-uri` | MLflow SharingHub | Flask secret, database URI |\n| `mlflow-sharinghub-postgres` | `sharinghub` | `password`, `postgres-password` | PostgreSQL, MLflow | Database authentication |\n| `mlflow-sharinghub-s3` | `sharinghub` | `access-key-id`, `secret-access-key` | MLflow SharingHub | Artifact storage |\n\n## Configuration Validation and Troubleshooting\n\n### Common Configuration Issues\n\n```mermaid\ngraph TB\n    subgraph \"Authentication Issues\"\n        AUTH1[\"OAuth misconfigured\"]\n        AUTH2[\"Default token missing\"]\n        AUTH3[\"OIDC provider unreachable\"]\n    end\n    \n    subgraph \"Integration Issues\"\n        INT1[\"GitLab URL mismatch\"]\n        INT2[\"MLflow URL incorrect\"]\n        INT3[\"Wrong STAC collection\"]\n    end\n    \n    subgraph \"Storage Issues\"\n        STOR1[\"S3 credentials invalid\"]\n        STOR2[\"PostgreSQL connection failed\"]\n        STOR3[\"Bucket doesn't exist\"]\n    end\n    \n    subgraph \"Symptoms\"\n        SYMP1[\"Users can't login\"]\n        SYMP2[\"Projects not appearing\"]\n        SYMP3[\"MLflow permission denied\"]\n        SYMP4[\"DVC push/pull fails\"]\n        SYMP5[\"Artifacts not stored\"]\n    end\n    \n    AUTH1 --\u003e SYMP1\n    AUTH2 --\u003e SYMP2\n    AUTH3 --\u003e SYMP1\n    \n    INT1 --\u003e SYMP2\n    INT2 --\u003e SYMP3\n    INT3 --\u003e SYMP3\n    \n    STOR1 --\u003e SYMP4\n    STOR2 --\u003e SYMP5\n    STOR3 --\u003e SYMP4\n```\n\n**Common Configuration Issues and Symptoms**\n\nSources: [docs/admin/configuration.md:88-232]()\n\n### Configuration Verification Checklist\n\n| Check | Component | Verification Method | Expected Result |\n|-------|-----------|---------------------|-----------------|\n| **GitLab OAuth** | SharingHub | Access `/auth/gitlab` | Redirects to GitLab login |\n| **Default Token** | SharingHub | Access `/api/stac` unauthenticated | Returns public projects |\n| **STAC Catalog** | SharingHub | GET `/api/stac` | Returns root catalog with collections |\n| **MLflow Permission** | MLflow SharingHub | Create experiment in project | Success if user has access |\n| **S3 Store** | SharingHub | DVC push to project | Uploads to S3 bucket |\n| **PostgreSQL** | MLflow SharingHub | Check pod logs | No connection errors |\n\n## Configuration Updates and Changes\n\nWhen updating configuration, different methods require different procedures:\n\n| Configuration Type | Update Method | Restart Required | Downtime |\n|-------------------|---------------|------------------|----------|\n| **Helm Values** | Update ArgoCD Application | Yes | Brief |\n| **YAML Config** | Update ArgoCD Application | Yes | Brief |\n| **Secrets** | Update secret, restart pods | Yes | Brief |\n| **Environment Variables** | Update deployment, restart | Yes | Brief |\n| **Dynamic Settings** | API calls (if supported) | No | None |\n\nThe SharingHub server includes a caching system that improves performance but may delay configuration changes. Cache timeouts are configurable:\n\n- `checker.cache-timeout`: Cache for API checks (default: 30.0 seconds)\n- `s3.check-access.cache-timeout`: Cache for S3 permission checks (default: 30.0 seconds)\n- `stac.projects.cache-timeout`: Cache for STAC item generation (default: 30.0 seconds)\n\nFor immediate effect after configuration changes, either wait for cache expiration or restart the affected pods.\n\nSources: [docs/admin/configuration.md:64-86]()\n\n## Next Steps\n\nFor detailed configuration options and examples:\n\n- **[SharingHub Configuration](#6.1)** - Complete reference including server settings, GitLab integration, STAC catalog structure, categories, tags, S3 store, and alert messages\n- **[MLflow SharingHub Configuration](#6.2)** - Backend store options (SQLite, PostgreSQL), artifacts storage (local, S3), and SharingHub integration settings\n\nFor applying these configurations during deployment, see:\n\n- **[Deployment Guide](#5)** - Complete deployment procedures\n- **[SharingHub Deployment](#5.3)** - Specific deployment steps for SharingHub\n- **[MLflow SharingHub Deployment](#5.4)** - Specific deployment steps for MLflow SharingHub\n\nSources: [docs/admin/configuration.md:1-359]()"])</script><script>self.__next_f.push([1,"29:T6118,"])</script><script>self.__next_f.push([1,"# SharingHub Configuration\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/configuration.md](docs/admin/configuration.md)\n- [docs/admin/deployment-guide/components/sharinghub.md](docs/admin/deployment-guide/components/sharinghub.md)\n\n\u003c/details\u003e\n\n\n\nThis page provides a comprehensive reference for configuring SharingHub, the discovery and collaboration platform that serves as the central hub of the MLOps Building Block. Configuration covers server settings, GitLab integration, STAC API structure, category definitions, tags, and optional services like S3 storage.\n\nFor deployment instructions including how to apply these configurations, see [SharingHub Deployment](#5.3). For MLflow SharingHub configuration, see [MLflow SharingHub Configuration](#6.2).\n\n## Configuration Overview\n\nSharingHub is configured through a combination of Kubernetes secrets and YAML configuration embedded in Helm chart values. The configuration is structured into logical sections that control different aspects of the system.\n\n### Configuration Sources and Flow\n\n```mermaid\ngraph TB\n    subgraph \"Kubernetes Secrets\"\n        SECRET_SESSION[\"sharinghub Secret\u003cbr/\u003esession-secret-key\"]\n        SECRET_OIDC[\"sharinghub-oidc Secret\u003cbr/\u003eclient-id\u003cbr/\u003eclient-secret\u003cbr/\u003edefault-token (optional)\"]\n        SECRET_S3[\"sharinghub-s3 Secret\u003cbr/\u003eaccess-key\u003cbr/\u003esecret-key\"]\n    end\n    \n    subgraph \"ArgoCD Application Manifest\"\n        HELM_VALUES[\"spec.source.helm.valuesObject\u003cbr/\u003econfig: YAML string\u003cbr/\u003eimage\u003cbr/\u003eingress\"]\n    end\n    \n    subgraph \"SharingHub Server Runtime\"\n        ENV_VARS[\"Environment Variables\u003cbr/\u003eDEBUG\u003cbr/\u003eLOG_LEVEL\"]\n        CONFIG_YAML[\"Parsed Configuration\u003cbr/\u003eserver\u003cbr/\u003egitlab\u003cbr/\u003estac\u003cbr/\u003etags\u003cbr/\u003es3\u003cbr/\u003emlflow\u003cbr/\u003ealerts\"]\n    end\n    \n    subgraph \"Configuration Sections\"\n        SERVER[\"server:\u003cbr/\u003edebug, log-level\u003cbr/\u003eallowed-origins\u003cbr/\u003esession, cache\"]\n        GITLAB[\"gitlab:\u003cbr/\u003eurl, allow-public\u003cbr/\u003eignore.topics\"]\n        STAC[\"stac:\u003cbr/\u003eextensions, root\u003cbr/\u003ecategories, projects\"]\n        TAGS[\"tags:\u003cbr/\u003egitlab.minimum_count\u003cbr/\u003esections\"]\n        S3CONFIG[\"s3:\u003cbr/\u003ebucket, region\u003cbr/\u003eendpoint\"]\n        MLFLOW[\"mlflow:\u003cbr/\u003etype, url\"]\n        ALERTS[\"alerts:\u003cbr/\u003etimeout, type\u003cbr/\u003etitle, message\"]\n    end\n    \n    SECRET_SESSION --\u003e ENV_VARS\n    SECRET_OIDC --\u003e ENV_VARS\n    SECRET_S3 --\u003e ENV_VARS\n    \n    HELM_VALUES --\u003e CONFIG_YAML\n    ENV_VARS --\u003e CONFIG_YAML\n    \n    CONFIG_YAML --\u003e SERVER\n    CONFIG_YAML --\u003e GITLAB\n    CONFIG_YAML --\u003e STAC\n    CONFIG_YAML --\u003e TAGS\n    CONFIG_YAML --\u003e S3CONFIG\n    CONFIG_YAML --\u003e MLFLOW\n    CONFIG_YAML --\u003e ALERTS\n```\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:51-214](), [docs/admin/configuration.md:1-279]()\n\n### Configuration Structure\n\nThe primary configuration is defined as a YAML string in the Helm chart's `config` field. This YAML structure contains all server settings, GitLab integration, STAC catalog definition, and optional service configurations.\n\n| Configuration Method | Purpose | Example |\n|---------------------|---------|---------|\n| Kubernetes Secrets | Sensitive data (keys, tokens, passwords) | `sharinghub`, `sharinghub-oidc`, `sharinghub-s3` |\n| Environment Variables | Runtime behavior flags | `DEBUG`, `LOG_LEVEL` |\n| Helm Values `config` | Main YAML configuration | Server, GitLab, STAC, tags settings |\n| Helm Values (direct) | Kubernetes resource configuration | `image`, `ingress`, `resources` |\n\n**Sources:** [docs/admin/configuration.md:8-14](), [docs/admin/deployment-guide/components/sharinghub.md:68-207]()\n\n## Server Global Settings\n\n### Debug and Log Level\n\nControl server verbosity and logging behavior through the `server.debug` and `server.log-level` configuration keys, or via environment variables.\n\n```yaml\nserver:\n  debug: true\n  log-level: DEBUG\n```\n\n**Configuration Options:**\n- `server.debug`: Boolean, enables debug mode (default: `false`)\n- `server.log-level`: String, one of `CRITICAL`, `WARNING`, `INFO`, `DEBUG`\n- Environment variable `DEBUG`: Overrides `server.debug`\n- Environment variable `LOG_LEVEL`: Overrides `server.log-level`\n\nWhen `debug` is `true`, log level defaults to `DEBUG`, otherwise `INFO`.\n\n**Sources:** [docs/admin/configuration.md:20-37]()\n\n### Security and CORS\n\nConfigure Cross-Origin Resource Sharing (CORS) to allow requests from external origins.\n\n```yaml\nserver:\n  allowed-origins:\n    - https://eoepca.readthedocs.io\n```\n\n**Configuration Options:**\n- `server.allowed-origins`: List of URLs allowed to make cross-origin requests\n\n**Sources:** [docs/admin/configuration.md:39-47]()\n\n### Session Management\n\nSession configuration controls user authentication session behavior through cookies.\n\n```yaml\nserver:\n  session:\n    cookie: sharinghub-session\n    domain: develop.eoepca.org\n    max-age: 14400.0\n```\n\n**Configuration Options:**\n- `server.session.cookie`: Session cookie name (default: `sharinghub-session`)\n- `server.session.domain`: Cookie domain scope\n- `server.session.max-age`: Session duration in seconds (default: `14400.0` = 4 hours)\n\n**Required Secret:**\nA session secret key must be created before deployment:\n```bash\nkubectl create secret generic sharinghub \\\n  --from-literal session-secret-key=\"\u003cuuid\u003e\" \\\n  --namespace sharinghub\n```\n\n**Sources:** [docs/admin/configuration.md:49-61](), [docs/admin/deployment-guide/components/sharinghub.md:8-14]()\n\n### Cache System\n\nThe cache system improves performance by storing frequently accessed data temporarily.\n\n```yaml\nserver:\n  cache: true\n\nchecker:\n  cache-timeout: 30.0\n\ns3:\n  check-access:\n    cache-timeout: 30.0\n\nstac:\n  projects:\n    cache-timeout: 30.0\n```\n\n**Configuration Options:**\n- `server.cache`: Boolean, enables/disables caching globally (default: `true`)\n- `checker.cache-timeout`: Cache duration for Check API responses (seconds)\n- `s3.check-access.cache-timeout`: Cache duration for S3 permission checks (seconds)\n- `stac.projects.cache-timeout`: Cache duration for STAC item generation from projects (seconds)\n\nIt is recommended to keep caching enabled (`true`) for production deployments. Disable only for debugging purposes.\n\n**Sources:** [docs/admin/configuration.md:63-85]()\n\n## GitLab Integration\n\nGitLab is the foundation of SharingHub, providing project management, authentication, and data source for the STAC catalog.\n\n### Basic GitLab Configuration\n\n```yaml\ngitlab:\n  url: https://gitlab.example.com\n  allow-public: true\n  ignore:\n    topics:\n      - \"gitlab-ci\"\n```\n\n**Configuration Options:**\n- `gitlab.url`: Base URL of the GitLab instance\n- `gitlab.allow-public`: Boolean, whether GitLab allows public project visibility (default: `true`)\n- `gitlab.ignore.topics`: List of GitLab topics to exclude from tag listings\n\n**Sources:** [docs/admin/configuration.md:87-105]()\n\n### OAuth Client Configuration\n\nSharingHub authenticates users via GitLab's OAuth2/OpenID Connect. A GitLab application must be configured first.\n\n```mermaid\ngraph LR\n    USER[\"User Browser\"]\n    SHSERVER[\"SharingHub Server\u003cbr/\u003e/api/auth/login\"]\n    GLAUTH[\"GitLab OAuth Provider\u003cbr/\u003e/oauth/authorize\u003cbr/\u003e/oauth/token\"]\n    SECRET[\"sharinghub-oidc Secret\u003cbr/\u003eclient-id\u003cbr/\u003eclient-secret\"]\n    \n    USER --\u003e|\"1. Initiate login\"| SHSERVER\n    SHSERVER --\u003e|\"2. Read credentials\"| SECRET\n    SHSERVER --\u003e|\"3. Redirect to OAuth\"| GLAUTH\n    GLAUTH --\u003e|\"4. User authenticates\"| GLAUTH\n    GLAUTH --\u003e|\"5. Callback with code\"| SHSERVER\n    SHSERVER --\u003e|\"6. Exchange code for token\"| GLAUTH\n    GLAUTH --\u003e|\"7. Return access token\"| SHSERVER\n    SHSERVER --\u003e|\"8. Set session cookie\"| USER\n```\n\n**GitLab Application Setup:**\n\n1. Navigate to your GitLab instance and create an application with these callback URLs:\n   - `https://sharinghub.\u003cdomain-name\u003e/api/auth/login/callback`\n   - `http://localhost:8000/api/auth/login/callback` (development only)\n\n2. Note the Application ID and Secret provided by GitLab.\n\n3. Create the Kubernetes secret:\n```bash\nkubectl create secret generic sharinghub-oidc \\\n  --from-literal client-id=\"\u003capplication-id\u003e\" \\\n  --from-literal client-secret=\"\u003capplication-secret\u003e\" \\\n  --namespace sharinghub\n```\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:16-37](), [docs/admin/configuration.md:107-109]()\n\n### Default Token\n\nThe default token mechanism enables unauthenticated users to browse public projects. When configured, the server uses this token for requests from non-authenticated users.\n\n**Token Types:**\n- **Personal Access Token**: Requires `api` scope\n- **Group Access Token**: Requires `Reporter` role minimum, with `read_api` and `read_repository` scopes\n\n```bash\nkubectl create secret generic sharinghub-oidc \\\n  --from-literal default-token=\"\u003cdefault-token\u003e\" \\\n  --from-literal client-id=\"\u003cclient-id\u003e\" \\\n  --from-literal client-secret=\"\u003cclient-secret\u003e\" \\\n  --namespace sharinghub\n```\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:39-45](), [docs/admin/configuration.md:111-116]()\n\n## STAC API Configuration\n\nThe STAC API is the primary interface for discovering models and datasets. It is dynamically generated from GitLab projects based on configuration.\n\n### STAC Catalog Structure from Configuration\n\n```mermaid\ngraph TB\n    subgraph \"Configuration YAML\"\n        ROOT_CONFIG[\"stac.root:\u003cbr/\u003eid: gitlab-cs\u003cbr/\u003etitle: ...\"]\n        EXTENSIONS[\"stac.extensions:\u003cbr/\u003eeo, label, sci, ml-model\"]\n        CATEGORIES[\"stac.categories:\u003cbr/\u003e- ai-model\u003cbr/\u003e- dataset\u003cbr/\u003e- processor\"]\n    end\n    \n    subgraph \"Generated STAC Structure\"\n        ROOT_CATALOG[\"STAC Root Catalog\u003cbr/\u003eGET /\u003cbr/\u003etype: Catalog\"]\n        COLLECTION_AI[\"STAC Collection\u003cbr/\u003eGET /collections/ai-model\u003cbr/\u003etype: Collection\"]\n        COLLECTION_DS[\"STAC Collection\u003cbr/\u003eGET /collections/dataset\u003cbr/\u003etype: Collection\"]\n        ITEMS_AI[\"STAC Items\u003cbr/\u003eGET /collections/ai-model/items\u003cbr/\u003efiltered by gitlab_topic\"]\n        ITEMS_DS[\"STAC Items\u003cbr/\u003eGET /collections/dataset/items\u003cbr/\u003efiltered by gitlab_topic\"]\n    end\n    \n    subgraph \"GitLab Data Source\"\n        GL_PROJECTS[\"GitLab Projects API\u003cbr/\u003e/api/v4/projects\"]\n        TOPIC_AI[\"Projects with topic\u003cbr/\u003esharinghub:aimodel\"]\n        TOPIC_DS[\"Projects with topic\u003cbr/\u003esharinghub:dataset\"]\n    end\n    \n    ROOT_CONFIG --\u003e ROOT_CATALOG\n    EXTENSIONS --\u003e ROOT_CATALOG\n    CATEGORIES --\u003e COLLECTION_AI\n    CATEGORIES --\u003e COLLECTION_DS\n    \n    COLLECTION_AI --\u003e ITEMS_AI\n    COLLECTION_DS --\u003e ITEMS_DS\n    \n    ITEMS_AI --\u003e TOPIC_AI\n    ITEMS_DS --\u003e TOPIC_DS\n    \n    TOPIC_AI --\u003e GL_PROJECTS\n    TOPIC_DS --\u003e GL_PROJECTS\n```\n\n**Sources:** [docs/admin/configuration.md:118-178]()\n\n### Extensions Configuration\n\nSTAC extensions declare additional metadata schemas available in the catalog.\n\n```yaml\nstac:\n  extensions:\n    eo: https://stac-extensions.github.io/eo/v1.1.0/schema.json\n    label: https://stac-extensions.github.io/label/v1.0.1/schema.json\n    sci: https://stac-extensions.github.io/scientific/v1.0.0/schema.json\n    ml-model: https://stac-extensions.github.io/ml-model/v1.0.0/schema.json\n```\n\n**Configuration Options:**\n- `stac.extensions`: Dictionary mapping extension names to their JSON schema URLs\n\nThese extensions are included in the root catalog's `stac_extensions` array, allowing clients to discover and use them.\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:79-83](), [docs/admin/configuration.md:129-133]()\n\n### Root Catalog Configuration\n\nThe root catalog defines top-level metadata for the entire STAC catalog.\n\n```yaml\nstac:\n  root:\n    id: gitlab-cs\n    title: SharingHub brings your data and models closer.\n    description: Your platform for collaborating on ML and NLP projects store in [GitLab](https://gitlab.com) instance STAC catalog.\n    locales:\n      fr:\n        title: SharingHub rapproche vos donnes et vos modles.\n        description: Votre plateforme de collaboration sur les projets ML et NLP stocks dans le catalogue STAC de l'instance [GitLab](https://gitlab.com).\n```\n\n**Configuration Options:**\n- `stac.root.id`: Unique identifier for the root catalog\n- `stac.root.title`: Human-readable title\n- `stac.root.description`: Markdown-formatted description\n- `stac.root.locales`: Dictionary of locale codes to translated title/description\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:84-91](), [docs/admin/configuration.md:134-141]()\n\n### Categories Configuration\n\nCategories map to STAC collections and define how GitLab projects are organized and discovered.\n\n```yaml\nstac:\n  categories:\n    - ai-model:\n        title: \"AI Models\"\n        description: \"AI models are the core of our platform, go and browse them to discover our models.\"\n        gitlab_topic: sharinghub:aimodel\n        logo: https://data.web.\u003cdomain_name\u003e/sharinghub/ai-model.jpg\n        icon: https://img.icons8.com/material/24/artificial-intelligence.png\n        locales:\n          fr:\n            title: \"Modles IA\"\n            description: \"Les modles d'IA sont au cur de notre plateforme, allez les parcourir pour dcouvrir nos modles.\"\n        features:\n          map-viewer: enable\n          store-s3: enable\n          mlflow: enable\n    - dataset:\n        title: \"Datasets\"\n        description: \"Datasets are very important in the process of training an AI, discover those that we put at your disposal.\"\n        gitlab_topic: sharinghub:dataset\n        logo: https://data.web.\u003cdomain_name\u003e/sharinghub/datasets.jpg\n        icon: https://img.icons8.com/ios/50/data-backup.png\n        locales:\n          fr:\n            title: \"Jeux de donnes\"\n            description: \"Les jeux de donnes sont trs importants dans le processus de formation d'une IA, dcouvrez ceux que nous mettons  votre disposition.\"\n        features:\n          map-viewer: enable\n          store-s3: enable\n          mlflow: disable\n```\n\n**Category Structure:**\nEach category is defined as a dictionary entry with the category ID as the key.\n\n| Field | Type | Purpose |\n|-------|------|---------|\n| `title` | String | Display name for the category |\n| `description` | String | Human-readable description (Markdown supported) |\n| `gitlab_topic` | String | GitLab topic used to filter projects for this category |\n| `logo` | URL | Image URL for category logo |\n| `icon` | URL | Image URL for category icon |\n| `locales` | Dictionary | Translations for `title` and `description` |\n| `features` | Dictionary | Feature toggles for this category |\n\n**Features Configuration:**\n\n| Feature | Values | Purpose |\n|---------|--------|---------|\n| `map-viewer` | `enable`, `disable` | Display geographic map for assets |\n| `store-s3` | `enable`, `disable` | Enable S3 store API for DVC support |\n| `mlflow` | `enable`, `disable` | Enable MLflow SharingHub integration |\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:92-170](), [docs/admin/configuration.md:142-184]()\n\n### Project Cache Timeout\n\nControl how long STAC items generated from GitLab projects are cached.\n\n```yaml\nstac:\n  projects:\n    cache-timeout: 30\n```\n\n**Configuration Options:**\n- `stac.projects.cache-timeout`: Duration in seconds to cache STAC items (default: `30`)\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:77-78]()\n\n## Tags Configuration\n\nTags organize projects in the web UI's left-side panel, grouping related keywords into sections.\n\n```yaml\ntags:\n  gitlab:\n    minimum_count: 1\n  sections:\n    - name: \"Computer Vision\"\n      enabled_for:\n        - ai-model\n        - dataset\n      keywords:\n        - \"Image qualification\"\n        - \"Object detection\"\n        - \"Image segmentation\"\n        - \"Mask generation\"\n    - name: \"Multimodal\"\n      keywords:\n        - \"Feature Extraction\"\n        - \"Text-to-Image\"\n        - \"Image-to-3D\"\n        - \"Text-to-3D\"\n      enabled_for:\n        - ai-model\n        - dataset\n    - name: \"Tabular\"\n      keywords:\n        - \"Tabular Classification\"\n        - \"Tabular Regression\"\n      enabled_for:\n        - ai-model\n        - dataset\n```\n\n### Tags to Categories Mapping\n\n```mermaid\ngraph TB\n    subgraph \"Tag Sections Configuration\"\n        SECTION_CV[\"Section: Computer Vision\u003cbr/\u003eenabled_for: ai-model, dataset\"]\n        SECTION_MM[\"Section: Multimodal\u003cbr/\u003eenabled_for: ai-model, dataset\"]\n        SECTION_TAB[\"Section: Tabular\u003cbr/\u003eenabled_for: ai-model, dataset\"]\n    end\n    \n    subgraph \"Keywords (GitLab Topics)\"\n        KW_OD[\"Object detection\"]\n        KW_SEG[\"Image segmentation\"]\n        KW_T2I[\"Text-to-Image\"]\n        KW_TABCLS[\"Tabular Classification\"]\n    end\n    \n    subgraph \"Web UI Display\"\n        UI_AI[\"AI Models Category Page\u003cbr/\u003eLeft Panel Sections:\u003cbr/\u003e- Computer Vision\u003cbr/\u003e- Multimodal\u003cbr/\u003e- Tabular\"]\n        UI_DS[\"Dataset Category Page\u003cbr/\u003eLeft Panel Sections:\u003cbr/\u003e- Computer Vision\u003cbr/\u003e- Multimodal\u003cbr/\u003e- Tabular\"]\n    end\n    \n    subgraph \"GitLab Projects\"\n        PROJ1[\"flood-model\u003cbr/\u003eTopics: sharinghub:aimodel\u003cbr/\u003eImage segmentation\"]\n        PROJ2[\"sen1floods11-dataset\u003cbr/\u003eTopics: sharinghub:dataset\u003cbr/\u003eObject detection\"]\n    end\n    \n    SECTION_CV --\u003e KW_OD\n    SECTION_CV --\u003e KW_SEG\n    SECTION_MM --\u003e KW_T2I\n    SECTION_TAB --\u003e KW_TABCLS\n    \n    KW_SEG --\u003e PROJ1\n    KW_OD --\u003e PROJ2\n    \n    SECTION_CV --\u003e UI_AI\n    SECTION_CV --\u003e UI_DS\n    SECTION_MM --\u003e UI_AI\n    SECTION_TAB --\u003e UI_AI\n    \n    PROJ1 --\u003e UI_AI\n    PROJ2 --\u003e UI_DS\n```\n\n**Configuration Options:**\n- `tags.gitlab.minimum_count`: Minimum number of projects required for a GitLab topic to be listed (default: `1`)\n- `tags.sections`: List of tag section definitions\n  - `name`: Display name for the section\n  - `enabled_for`: List of category IDs where this section appears\n  - `keywords`: List of GitLab topics (tags) grouped under this section\n\nTags not listed in any section appear in an \"Other\" tab. Keywords correspond to GitLab topics assigned to projects.\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:122-150](), [docs/admin/configuration.md:234-263]()\n\n## MLflow Integration\n\nConfigure how SharingHub integrates with MLflow for experiment tracking and model registry.\n\n```yaml\nmlflow:\n  type: mlflow-sharinghub\n  url: https://sharinghub.example.com/mlflow\n```\n\n**Configuration Options:**\n\n| Type | Description | Recommendation |\n|------|-------------|----------------|\n| `mlflow-sharinghub` | Custom MLflow with SharingHub integration, per-project tracking URIs, permission checking | **Strongly Recommended** |\n| `mlflow` | Classic MLflow instance, no per-project features, no authentication | Not recommended |\n| `gitlab` | GitLab's ML tracking feature, MLflow-compatible | Experimental |\n\nThe `mlflow.url` field specifies the MLflow server endpoint. For `mlflow-sharinghub`, this is typically hosted under the SharingHub domain at the `/mlflow` path.\n\n**Sources:** [docs/admin/configuration.md:186-206]()\n\n## S3 Store Configuration\n\nThe S3 store is an optional API that enables DVC (Data Version Control) support for managing datasets.\n\n```yaml\nservices:\n  store:\n    url: https://sharinghub.example.com/api/store\n    mode: http\n\ns3:\n  enable: true\n  bucket: \u003cbucket\u003e\n  region: \u003cbucket-region\u003e\n  endpoint: https://\u003cs3-endpoint\u003e\n```\n\n**Configuration Options:**\n- `services.store.url`: Public URL for the store API\n- `services.store.mode`: Protocol mode (typically `http`)\n- `s3.enable`: Boolean, enables S3 store functionality\n- `s3.bucket`: S3 bucket name\n- `s3.region`: S3 bucket region\n- `s3.endpoint`: S3 service endpoint URL\n\n**Required Secret:**\nS3 credentials must be stored in a Kubernetes secret:\n```bash\nkubectl create secret generic sharinghub-s3 \\\n  --from-literal access-key=\"\u003caccess-key\u003e\" \\\n  --from-literal secret-key=\"\u003csecret-key\u003e\" \\\n  --namespace sharinghub\n```\n\n**Cache Configuration:**\n```yaml\ns3:\n  check-access:\n    cache-timeout: 30.0\n```\n- `s3.check-access.cache-timeout`: Cache duration for S3 permission checks in seconds\n\nThe S3 store must be explicitly enabled per-category via the `store-s3` feature flag.\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:197-206](), [docs/admin/configuration.md:208-232]()\n\n## Alert Messages\n\nConfigure welcome messages or announcements displayed to users.\n\n```yaml\nalerts:\n  timeout: 3\n  type: info\n  title: \"Welcome to SharingHub\"\n  message: \"To see all projects and unlock all features, please login...\"\n  locales:\n    fr:\n      title: \"Bienvenue sur le SharingHub\"\n      message: \"Pour voir tous les projets et dbloquer toutes les fonctionnalits, veuillez vous connecter...\"\n```\n\n**Configuration Options:**\n- `alerts.timeout`: Number of days before alert reappears (cookie-based detection)\n- `alerts.type`: Alert style, one of `info`, `danger`, `success`, `warning`, `primary`, `dark`, `secondary`\n- `alerts.title`: Alert heading text\n- `alerts.message`: Alert body text (HTML primitives like `\u003ca\u003e` tags are supported)\n- `alerts.locales`: Dictionary of locale codes to translated title/message\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:152-160](), [docs/admin/configuration.md:265-279]()\n\n## Complete Configuration Example\n\nBelow is a complete configuration reference showing all major sections integrated together:\n\n```yaml\n# Server Settings\nserver:\n  debug: false\n  log-level: INFO\n  cache: true\n  allowed-origins:\n    - https://eoepca.readthedocs.io\n  session:\n    cookie: sharinghub-session\n    domain: example.com\n    max-age: 14400.0\n\n# GitLab Integration\ngitlab:\n  url: https://gitlab.example.com\n  allow-public: true\n  ignore:\n    topics:\n      - \"gitlab-ci\"\n\n# Documentation Link\ndocs:\n  url: https://sharinghub.example.com/docs\n\n# STAC API Configuration\nstac:\n  projects:\n    cache-timeout: 30\n  extensions:\n    eo: https://stac-extensions.github.io/eo/v1.1.0/schema.json\n    label: https://stac-extensions.github.io/label/v1.0.1/schema.json\n    sci: https://stac-extensions.github.io/scientific/v1.0.0/schema.json\n    ml-model: https://stac-extensions.github.io/ml-model/v1.0.0/schema.json\n  root:\n    id: gitlab-cs\n    title: SharingHub brings your data and models closer.\n    description: Your platform for collaborating on ML and NLP projects stored in GitLab instance STAC catalog.\n    locales:\n      fr:\n        title: SharingHub rapproche vos donnes et vos modles.\n        description: Votre plateforme de collaboration sur les projets ML et NLP stocks dans le catalogue STAC.\n  categories:\n    - ai-model:\n        title: \"AI Models\"\n        description: \"AI models are the core of our platform.\"\n        gitlab_topic: sharinghub:aimodel\n        logo: https://example.com/images/ai-model.jpg\n        icon: https://img.icons8.com/material/24/artificial-intelligence.png\n        features:\n          map-viewer: enable\n          store-s3: enable\n          mlflow: enable\n    - dataset:\n        title: \"Datasets\"\n        description: \"Training datasets for AI development.\"\n        gitlab_topic: sharinghub:dataset\n        logo: https://example.com/images/datasets.jpg\n        icon: https://img.icons8.com/ios/50/data-backup.png\n        features:\n          map-viewer: enable\n          store-s3: enable\n          mlflow: disable\n\n# Tags Configuration\ntags:\n  gitlab:\n    minimum_count: 1\n  sections:\n    - name: \"Computer Vision\"\n      enabled_for:\n        - ai-model\n        - dataset\n      keywords:\n        - \"Image qualification\"\n        - \"Object detection\"\n        - \"Image segmentation\"\n    - name: \"Tabular\"\n      keywords:\n        - \"Tabular Classification\"\n        - \"Tabular Regression\"\n      enabled_for:\n        - ai-model\n        - dataset\n\n# MLflow Integration\nmlflow:\n  type: mlflow-sharinghub\n  url: https://sharinghub.example.com/mlflow\n\n# S3 Store (Optional)\nservices:\n  store:\n    url: https://sharinghub.example.com/api/store\n    mode: http\n\ns3:\n  enable: true\n  bucket: my-bucket\n  region: us-east-1\n  endpoint: https://s3.amazonaws.com\n  check-access:\n    cache-timeout: 30.0\n\n# Alert Messages\nalerts:\n  timeout: 3\n  type: info\n  title: \"Welcome to SharingHub\"\n  message: \"To see all projects and unlock all features, please login...\"\n  locales:\n    fr:\n      title: \"Bienvenue sur le SharingHub\"\n      message: \"Pour voir tous les projets, veuillez vous connecter...\"\n\n# Cache Settings\nchecker:\n  cache-timeout: 30.0\n```\n\nThis configuration is embedded in the ArgoCD Application manifest at [docs/admin/deployment-guide/components/sharinghub.md:68-69]() as a YAML string in the `spec.source.helm.valuesObject.config` field.\n\n**Sources:** [docs/admin/deployment-guide/components/sharinghub.md:51-214](), [docs/admin/configuration.md:1-279]()\n\n## Configuration Validation\n\nThe complete and up-to-date configuration reference, including all available options and their default values, is maintained in the SharingHub server repository at `CONFIGURATION.md`. Always refer to this authoritative source when configuring advanced options or troubleshooting configuration issues.\n\n**Sources:** [docs/admin/configuration.md:13-14]()"])</script><script>self.__next_f.push([1,"2a:T5976,"])</script><script>self.__next_f.push([1,"# MLflow SharingHub Configuration\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/configuration.md](docs/admin/configuration.md)\n- [docs/admin/deployment-guide/components/mlflow-sharinghub.md](docs/admin/deployment-guide/components/mlflow-sharinghub.md)\n\n\u003c/details\u003e\n\n\n\nThis document provides a comprehensive reference for configuring MLflow SharingHub, the experiment tracking and model registry component of the EOEPCA MLOps Building Block. MLflow SharingHub extends standard MLflow with SharingHub integration for permission management and STAC catalog synchronization.\n\nFor deployment instructions, see [MLflow SharingHub Deployment](#5.4). For SharingHub configuration options, see [SharingHub Configuration](#6.1).\n\n## Configuration Overview\n\nMLflow SharingHub configuration is divided into several key areas:\n\n| Configuration Area | Purpose | Required |\n|-------------------|---------|----------|\n| SharingHub Integration | Permission checking and STAC collection mapping | Yes |\n| Backend Store | Metadata storage (experiments, runs, models) | Yes |\n| Artifacts Store | Storage for model artifacts and files | Yes |\n| Security | Secret key for server security | Yes |\n| Ingress | External access and URL routing | Yes |\n| Pod Security | Filesystem permissions and security context | No |\n\n**Configuration Architecture**\n\n```mermaid\ngraph TB\n    subgraph \"Helm Values Configuration\"\n        HelmValues[\"mlflow-sharinghub.yaml\u003cbr/\u003eHelm Values\"]\n    end\n    \n    subgraph \"MLflow SharingHub Pod\"\n        Container[\"mlflow-sharinghub container\"]\n        EnvVars[\"Environment Variables\"]\n        Secrets[\"Mounted Secrets\"]\n    end\n    \n    subgraph \"Configuration Sources\"\n        SecretKey[\"mlflow-sharinghub secret\u003cbr/\u003esecret-key\"]\n        S3Secret[\"mlflow-sharinghub-s3 secret\u003cbr/\u003eaccess-key-id, secret-access-key\"]\n        PGSecret[\"mlflow-sharinghub-postgres secret\u003cbr/\u003epassword, postgres-password\"]\n    end\n    \n    subgraph \"Runtime Configuration\"\n        SHIntegration[\"sharinghubUrl\u003cbr/\u003esharinghubStacCollection\u003cbr/\u003esharinghubAuthDefaultToken\"]\n        BackendStore[\"Backend Store URI\u003cbr/\u003eSQLite or PostgreSQL\"]\n        ArtifactsStore[\"Artifacts Destination\u003cbr/\u003eFilesystem or S3\"]\n    end\n    \n    subgraph \"External Dependencies\"\n        SH[\"SharingHub API\u003cbr/\u003ePermission Checking\"]\n        PG[(\"PostgreSQL\u003cbr/\u003eBackend Store\")]\n        S3[\"S3 Bucket\u003cbr/\u003eArtifacts Store\"]\n    end\n    \n    HelmValues --\u003e Container\n    SecretKey --\u003e Secrets\n    S3Secret --\u003e Secrets\n    PGSecret --\u003e Secrets\n    Secrets --\u003e Container\n    \n    Container --\u003e EnvVars\n    EnvVars --\u003e SHIntegration\n    EnvVars --\u003e BackendStore\n    EnvVars --\u003e ArtifactsStore\n    \n    SHIntegration --\u003e SH\n    BackendStore --\u003e PG\n    ArtifactsStore --\u003e S3\n    \n    style HelmValues fill:#f9f9f9\n    style Container fill:#e1f5ff\n    style SHIntegration fill:#ffe1e1\n    style BackendStore fill:#e1ffe1\n    style ArtifactsStore fill:#fff4e1\n```\n\nSources: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:31-96](), [docs/admin/configuration.md:281-359]()\n\n## SharingHub Integration\n\nMLflow SharingHub integrates with SharingHub for permission checking and project-based experiment tracking. This integration enables per-project MLflow tracking URIs that are automatically validated against GitLab project permissions.\n\n### Core Integration Settings\n\nThe integration is configured through the `mlflowSharinghub` section:\n\n| Setting | Type | Description | Required | Default |\n|---------|------|-------------|----------|---------|\n| `sharinghubUrl` | string | URL of the SharingHub instance | Yes | - |\n| `sharinghubStacCollection` | string | STAC collection ID for AI models | Yes | - |\n| `sharinghubAuthDefaultToken` | boolean | Enable unauthenticated access via default token | No | `false` |\n\n**Configuration Example:**\n\n```yaml\nmlflowSharinghub:\n  sharinghubUrl: https://sharinghub.example.com\n  sharinghubStacCollection: ai-model\n  sharinghubAuthDefaultToken: false\n```\n\nSources: [docs/admin/configuration.md:283-297](), [docs/admin/deployment-guide/components/mlflow-sharinghub.md:52-56]()\n\n### Permission Check Flow\n\n```mermaid\ngraph LR\n    subgraph \"MLflow Client\"\n        Client[\"MLflow Client\u003cbr/\u003emlflow.log_metric\"]\n    end\n    \n    subgraph \"MLflow SharingHub Server\"\n        API[\"MLflow Tracking API\u003cbr/\u003e/api/2.0/mlflow/runs\"]\n        PermCheck[\"Permission Checker\u003cbr/\u003evalidates project access\"]\n        TrackingURI[\"Project URI Parser\u003cbr/\u003eextracts project_id\"]\n    end\n    \n    subgraph \"SharingHub API\"\n        CheckAPI[\"Check API\u003cbr/\u003e/api/check/\u003cproject_id\u003e\"]\n        GitLabValidator[\"GitLab Permission\u003cbr/\u003eValidator\"]\n    end\n    \n    subgraph \"GitLab\"\n        Project[\"GitLab Project\u003cbr/\u003eproject_id\"]\n        ProjectTopic[\"Project Topic\u003cbr/\u003esharinghub:aimodel\"]\n    end\n    \n    Client --\u003e|\"POST experiment_name=projects/123\"| API\n    API --\u003e TrackingURI\n    TrackingURI --\u003e PermCheck\n    PermCheck --\u003e|\"GET /api/check/123\"| CheckAPI\n    CheckAPI --\u003e GitLabValidator\n    GitLabValidator --\u003e Project\n    GitLabValidator --\u003e ProjectTopic\n    \n    ProjectTopic -.validates against.-\u003e SHCollection[\"sharinghubStacCollection\u003cbr/\u003eai-model\"]\n    \n    CheckAPI --\u003e|\"200 OK or 403 Forbidden\"| PermCheck\n    PermCheck --\u003e|\"Allow or Deny\"| API\n    API --\u003e|\"Response\"| Client\n    \n    style API fill:#ffe1e1\n    style PermCheck fill:#f9f9f9\n    style CheckAPI fill:#e1f5ff\n    style Project fill:#e1ffe1\n```\n\nSources: [docs/admin/configuration.md:295-297]()\n\n### STAC Collection Restriction\n\nThe `sharinghubStacCollection` setting restricts MLflow usage to projects registered in a specific STAC collection. This prevents MLflow from being used on unrelated projects:\n\n- **Value**: Must match a collection ID defined in SharingHub (e.g., `ai-model`)\n- **Purpose**: Only projects with the corresponding GitLab topic (e.g., `sharinghub:aimodel`) can use MLflow\n- **Validation**: Checked during every experiment creation and run logging operation\n\nSources: [docs/admin/configuration.md:296]()\n\n### Default Token Authentication\n\nWhen `sharinghubAuthDefaultToken` is enabled, MLflow SharingHub allows unauthenticated read-only access to projects visible through SharingHub's default token:\n\n```yaml\nmlflowSharinghub:\n  sharinghubAuthDefaultToken: false  # Set to true if SharingHub has default token\n```\n\n**Behavior:**\n\n| Setting | Unauthenticated Access | Authenticated Access |\n|---------|----------------------|----------------------|\n| `false` | Denied | Per-project permissions |\n| `true` | Read-only (default token projects) | Per-project permissions |\n\nSources: [docs/admin/configuration.md:297](), [docs/admin/deployment-guide/components/mlflow-sharinghub.md:56]()\n\n## Backend Store Configuration\n\nThe backend store holds MLflow metadata including experiments, runs, parameters, and metrics. Two storage backends are supported: SQLite (default) and PostgreSQL (recommended).\n\n### Backend Store Architecture\n\n```mermaid\ngraph TB\n    subgraph \"MLflow SharingHub Pod\"\n        Server[\"mlflow-sharinghub server\"]\n        BackendStore[\"Backend Store\u003cbr/\u003eClient\"]\n    end\n    \n    subgraph \"SQLite Backend (Default)\"\n        SQLiteFile[\"/home/mlflow/data/mlflow.db\u003cbr/\u003eSQLite File\"]\n        PVC1[\"PersistentVolumeClaim\u003cbr/\u003e10Gi storage\"]\n    end\n    \n    subgraph \"PostgreSQL Backend (Recommended)\"\n        PGPod[\"PostgreSQL Pod\u003cbr/\u003ebitnami/postgresql\"]\n        PGData[(\"Database: mlflow\u003cbr/\u003eTables: experiments, runs, metrics\")]\n        PVC2[\"PersistentVolumeClaim\u003cbr/\u003e8Gi storage\"]\n        PGSecret2[\"mlflow-sharinghub-postgres secret\u003cbr/\u003epassword, postgres-password\"]\n    end\n    \n    Server --\u003e BackendStore\n    \n    BackendStore --\u003e|\"Default:\u003cbr/\u003esqlite:////home/mlflow/data/mlflow.db\"| SQLiteFile\n    BackendStore --\u003e|\"postgresql://\u003cuser\u003e:\u003cpassword\u003e@\u003chost\u003e:5432/\u003cdb\u003e\"| PGPod\n    \n    SQLiteFile --\u003e PVC1\n    PGPod --\u003e PGData\n    PGData --\u003e PVC2\n    PGPod --\u003e PGSecret2\n    \n    style Server fill:#ffe1e1\n    style SQLiteFile fill:#fff4e1\n    style PGPod fill:#e1ffe1\n    style PGData fill:#e1f5ff\n```\n\nSources: [docs/admin/configuration.md:299-334]()\n\n### SQLite Backend (Default)\n\nThe default configuration uses SQLite with a persistent volume:\n\n```yaml\nmlflowSharinghub:\n  # No backendStoreUri specified = use default SQLite\n\npersistence:\n  enabled: true\n  size: 10Gi\n  storageClass: \"\"  # Use default storage class\n```\n\n**SQLite File Location:** `/home/mlflow/data/mlflow.db`\n\n**Advantages:**\n- Simple setup, no additional components\n- Suitable for development and testing\n\n**Limitations:**\n- Single-threaded access\n- Not suitable for production with multiple concurrent users\n- No native backup capabilities\n\nSources: [docs/admin/configuration.md:301]()\n\n### PostgreSQL Backend (Recommended)\n\nPostgreSQL is recommended for production deployments. Two configuration methods are available:\n\n#### Method 1: Chart Dependency (Recommended)\n\nDeploy PostgreSQL as a chart dependency:\n\n**Step 1:** Create the PostgreSQL secret:\n\n```bash\nkubectl create secret generic mlflow-sharinghub-postgres \\\n  --from-literal password=\"\u003cmlflow-user-password\u003e\" \\\n  --from-literal postgres-password=\"\u003croot-user-password\u003e\" \\\n  --namespace sharinghub\n```\n\n**Step 2:** Configure Helm values:\n\n```yaml\npostgresql:\n  enabled: true\n  auth:\n    username: mlflow\n    database: mlflow\n    existingSecret: mlflow-sharinghub-postgres\n  primary:\n    persistence:\n      enabled: true\n      size: 8Gi\n```\n\n**Connection String Generated:** `postgresql://mlflow:\u003cpassword\u003e@mlflow-sharinghub-postgresql:5432/mlflow`\n\nSources: [docs/admin/configuration.md:307-322](), [docs/admin/deployment-guide/components/mlflow-sharinghub.md:87-90]()\n\n#### Method 2: Existing PostgreSQL Instance\n\nConnect to an existing PostgreSQL instance:\n\n**Step 1:** Add `backend-store-uri` to the secret:\n\n```bash\n# Edit existing secret to add backend-store-uri key\nkubectl create secret generic mlflow-sharinghub \\\n  --from-literal secret-key=\"\u003crandom-secret-key\u003e\" \\\n  --from-literal backend-store-uri=\"postgresql://\u003cuser\u003e:\u003cpassword\u003e@\u003chost\u003e:5432/\u003cdatabase\u003e\" \\\n  --namespace sharinghub \\\n  --dry-run=client -o yaml | kubectl apply -f -\n```\n\n**Step 2:** Configure Helm values:\n\n```yaml\nmlflowSharinghub:\n  backendStoreUriSecret: true\n\npostgresql:\n  enabled: false\n```\n\nSources: [docs/admin/configuration.md:325-333]()\n\n### Backend Store Comparison\n\n| Feature | SQLite | PostgreSQL (Dependency) | PostgreSQL (Existing) |\n|---------|--------|------------------------|-----------------------|\n| Setup Complexity | Low | Medium | Low |\n| Concurrent Access | Limited | High | High |\n| Production Ready | No | Yes | Yes |\n| Backup Support | Manual file backup | PostgreSQL tools | PostgreSQL tools |\n| Resource Requirements | Minimal | +512Mi memory | None (external) |\n| Configuration | Default | `postgresql.enabled: true` | `backendStoreUriSecret: true` |\n\n## Artifacts Store Configuration\n\nThe artifacts store holds model files, training data, and other large objects logged during experiments. Two storage backends are supported: local filesystem (default) and S3 (recommended).\n\n### Artifacts Store Architecture\n\n```mermaid\ngraph TB\n    subgraph \"MLflow SharingHub Pod\"\n        Server[\"mlflow-sharinghub server\"]\n        ArtifactsClient[\"Artifacts Store\u003cbr/\u003eClient\"]\n    end\n    \n    subgraph \"Filesystem Backend (Default)\"\n        FSDir[\"/home/mlflow/data/mlartifacts\u003cbr/\u003eDirectory\"]\n        PVC3[\"PersistentVolumeClaim\u003cbr/\u003e100Gi storage\"]\n    end\n    \n    subgraph \"S3 Backend (Recommended)\"\n        S3Bucket[\"S3 Bucket\u003cbr/\u003es3://\u003cbucket\u003e/\"]\n        S3Provider[\"S3 Provider\u003cbr/\u003eAWS, MinIO, OVH, etc.\"]\n        S3Secret3[\"mlflow-sharinghub-s3 secret\u003cbr/\u003eaccess-key-id, secret-access-key\"]\n        S3Env[\"S3 Environment\u003cbr/\u003eAWS_ACCESS_KEY_ID\u003cbr/\u003eAWS_SECRET_ACCESS_KEY\u003cbr/\u003eMLFLOW_S3_ENDPOINT_URL\"]\n    end\n    \n    subgraph \"Artifact Structure\"\n        ExpDir[\"\u003cexperiment_id\u003e/\u003crun_id\u003e/artifacts/\u003cpath\u003e\"]\n        ModelDir[\"models/\u003cmodel_name\u003e/\u003cversion\u003e/\u003cfiles\u003e\"]\n    end\n    \n    Server --\u003e ArtifactsClient\n    \n    ArtifactsClient --\u003e|\"Default:\u003cbr/\u003e/home/mlflow/data/mlartifacts\"| FSDir\n    ArtifactsClient --\u003e|\"s3://\u003cbucket\u003e\"| S3Bucket\n    \n    FSDir --\u003e PVC3\n    S3Bucket --\u003e S3Provider\n    S3Secret3 --\u003e S3Env\n    S3Env --\u003e ArtifactsClient\n    \n    ArtifactsClient --\u003e ExpDir\n    ArtifactsClient --\u003e ModelDir\n    \n    style Server fill:#ffe1e1\n    style FSDir fill:#fff4e1\n    style S3Bucket fill:#e1f5ff\n    style S3Provider fill:#e1ffe1\n```\n\nSources: [docs/admin/configuration.md:336-358]()\n\n### Filesystem Backend (Default)\n\nThe default configuration uses a persistent volume for artifacts:\n\n```yaml\nmlflowSharinghub:\n  # No artifactsDestination specified = use default filesystem\n\npersistence:\n  enabled: true\n  size: 100Gi  # Large volume for artifacts\n  storageClass: \"\"\n```\n\n**Artifacts Directory:** `/home/mlflow/data/mlartifacts`\n\n**Advantages:**\n- Simple setup, no external dependencies\n- Direct filesystem access\n\n**Limitations:**\n- Limited scalability for large deployments\n- No built-in replication or backup\n- Requires large persistent volumes\n\nSources: [docs/admin/configuration.md:338]()\n\n### S3 Backend (Recommended)\n\nS3 storage is recommended for production deployments:\n\n**Step 1:** Create S3 bucket in your provider (AWS, MinIO, OVH, etc.)\n\n**Step 2:** Create the S3 credentials secret:\n\n```bash\nkubectl create secret generic mlflow-sharinghub-s3 \\\n  --from-literal access-key-id=\"\u003caccess-key\u003e\" \\\n  --from-literal secret-access-key=\"\u003csecret-key\u003e\" \\\n  --namespace sharinghub\n```\n\n**Step 3:** Configure Helm values:\n\n```yaml\nmlflowSharinghub:\n  artifactsDestination: s3://\u003cbucket-name\u003e\n\ns3:\n  enabled: true\n  endpointUrl: https://\u003cs3-endpoint\u003e  # e.g., s3.amazonaws.com, s3.eu-west-3.amazonaws.com\n```\n\n**Environment Variables Set:**\n- `AWS_ACCESS_KEY_ID`: From `mlflow-sharinghub-s3` secret\n- `AWS_SECRET_ACCESS_KEY`: From `mlflow-sharinghub-s3` secret\n- `MLFLOW_S3_ENDPOINT_URL`: From `s3.endpointUrl` configuration\n\nSources: [docs/admin/configuration.md:340-358](), [docs/admin/deployment-guide/components/mlflow-sharinghub.md:19-25](), [docs/admin/deployment-guide/components/mlflow-sharinghub.md:53](), [docs/admin/deployment-guide/components/mlflow-sharinghub.md:58-60]()\n\n### S3 Configuration Examples\n\n**AWS S3:**\n```yaml\ns3:\n  enabled: true\n  endpointUrl: https://s3.amazonaws.com  # or regional endpoint\n```\n\n**MinIO:**\n```yaml\ns3:\n  enabled: true\n  endpointUrl: https://minio.example.com\n```\n\n**OVH Object Storage:**\n```yaml\ns3:\n  enabled: true\n  endpointUrl: https://s3.gra.io.cloud.ovh.net\n```\n\n### Artifacts Store Comparison\n\n| Feature | Filesystem | S3 |\n|---------|-----------|-----|\n| Setup Complexity | Low | Medium |\n| Scalability | Limited by volume size | Unlimited |\n| Backup/Replication | Manual | Provider-managed |\n| Cost | Volume storage cost | Object storage cost |\n| Production Ready | No | Yes |\n| Multi-region | No | Yes (provider-dependent) |\n| Configuration | Default | `artifactsDestination: s3://\u003cbucket\u003e` |\n\n## Security Configuration\n\nMLflow SharingHub requires a secret key for session management and security features.\n\n### Secret Key\n\nThe secret key is used for:\n- Flask session security\n- Internal authentication tokens\n- CSRF protection\n\n**Create the secret:**\n\n```bash\n# Generate a random secret key (recommended: 64 characters)\nSECRET_KEY=$(openssl rand -hex 32)\n\nkubectl create secret generic mlflow-sharinghub \\\n  --from-literal secret-key=\"${SECRET_KEY}\" \\\n  --namespace sharinghub\n```\n\nThe secret is automatically mounted and used by the server. No additional configuration is needed in Helm values.\n\nSources: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:11-17]()\n\n### Pod Security Context\n\nConfigure filesystem permissions for the MLflow pod:\n\n```yaml\npodSecurityContext:\n  fsGroup: 999  # mlflow user group ID\n```\n\nThis ensures the pod can write to persistent volumes. The default user inside the container is `mlflow` (UID 999, GID 999).\n\nSources: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:65-66]()\n\n## Ingress and Networking\n\nMLflow SharingHub is typically deployed under a subpath of the SharingHub domain to simplify TLS certificate management.\n\n### Ingress Configuration\n\n```yaml\ningress:\n  enabled: true\n  className: nginx\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/proxy-body-size: 10g\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      proxy_set_header X-Script-Name /mlflow;\n      rewrite ^/mlflow/(.*)$ /$1 break;\n  hosts:\n    - host: sharinghub.\u003cdomain_name\u003e\n      paths:\n        - path: /mlflow/\n          pathType: ImplementationSpecific\n  tls:\n    - secretName: sharinghub.\u003cdomain_name\u003e-tls\n      hosts:\n        - sharinghub.\u003cdomain_name\u003e\n```\n\nSources: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:68-86]()\n\n### URL Routing Details\n\n**Ingress Path Rewriting:**\n\n```mermaid\ngraph LR\n    subgraph \"External Client\"\n        Browser[\"Browser or\u003cbr/\u003eMLflow Client\"]\n    end\n    \n    subgraph \"NGINX Ingress\"\n        Ingress[\"NGINX Ingress Controller\"]\n        Rewrite[\"URL Rewrite Rule\u003cbr/\u003e^/mlflow/(.*)$  /$1\"]\n        Header[\"X-Script-Name: /mlflow\"]\n    end\n    \n    subgraph \"MLflow SharingHub Pod\"\n        Flask[\"Flask Application\"]\n        API[\"MLflow API\u003cbr/\u003e/api/2.0/mlflow/...\"]\n        UI[\"MLflow UI\u003cbr/\u003e/static/...\"]\n    end\n    \n    Browser --\u003e|\"https://sharinghub.domain/mlflow/api/...\"| Ingress\n    Ingress --\u003e Rewrite\n    Ingress --\u003e Header\n    Rewrite --\u003e|\"Strip /mlflow prefix\"| Flask\n    Header --\u003e|\"Add header for path awareness\"| Flask\n    \n    Flask --\u003e API\n    Flask --\u003e UI\n    \n    style Ingress fill:#fff4e1\n    style Flask fill:#ffe1e1\n    style Rewrite fill:#f9f9f9\n```\n\nSources: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:75-77]()\n\n### Key Ingress Settings\n\n| Annotation | Value | Purpose |\n|-----------|-------|---------|\n| `cert-manager.io/cluster-issuer` | `letsencrypt-prod` | Automatic TLS certificate provisioning |\n| `nginx.ingress.kubernetes.io/ssl-redirect` | `\"true\"` | Force HTTPS |\n| `nginx.ingress.kubernetes.io/proxy-body-size` | `10g` | Allow large model uploads |\n| `proxy_set_header X-Script-Name` | `/mlflow` | Inform Flask of subpath mounting |\n| `rewrite` | `^/mlflow/(.*)$ /$1 break` | Strip `/mlflow` prefix before forwarding |\n\n**URL Examples:**\n\n| External URL | Internal URL | Purpose |\n|-------------|-------------|---------|\n| `https://sharinghub.domain/mlflow/` | `/` | MLflow UI home |\n| `https://sharinghub.domain/mlflow/api/2.0/mlflow/experiments/list` | `/api/2.0/mlflow/experiments/list` | API endpoint |\n| `https://sharinghub.domain/mlflow/static/css/app.css` | `/static/css/app.css` | Static assets |\n\nSources: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:68-86]()\n\n## Complete Configuration Example\n\nHere is a complete production-ready configuration combining all settings:\n\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: mlflow-sharinghub\n  namespace: argocd\nspec:\n  destination:\n    namespace: sharinghub\n    server: https://kubernetes.default.svc\n  project: default\n  source:\n    repoURL: https://github.com/csgroup-oss/mlflow-sharinghub.git\n    path: deploy/helm/mlflow-sharinghub\n    targetRevision: \"0.2.0\"\n    helm:\n      valuesObject:\n        # Container image\n        image:\n          repository: eoepca/mlflow-sharinghub\n          tag: latest\n          pullPolicy: IfNotPresent\n\n        # SharingHub integration\n        mlflowSharinghub:\n          sharinghubUrl: https://sharinghub.example.com\n          sharinghubStacCollection: ai-model\n          sharinghubAuthDefaultToken: false\n          artifactsDestination: s3://mlflow-artifacts\n\n        # S3 artifacts store\n        s3:\n          enabled: true\n          endpointUrl: https://s3.eu-west-3.amazonaws.com\n\n        # PostgreSQL backend store\n        postgresql:\n          enabled: true\n          auth:\n            username: mlflow\n            database: mlflow\n            existingSecret: mlflow-sharinghub-postgres\n          primary:\n            persistence:\n              enabled: true\n              size: 8Gi\n\n        # Disable filesystem persistence (using S3 + PostgreSQL)\n        persistence:\n          enabled: false\n\n        # Pod security\n        podSecurityContext:\n          fsGroup: 999\n\n        # Resource limits\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n\n        # Ingress configuration\n        ingress:\n          enabled: true\n          className: nginx\n          annotations:\n            cert-manager.io/cluster-issuer: letsencrypt-prod\n            nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n            nginx.ingress.kubernetes.io/proxy-body-size: 10g\n            nginx.ingress.kubernetes.io/configuration-snippet: |\n              proxy_set_header X-Script-Name /mlflow;\n              rewrite ^/mlflow/(.*)$ /$1 break;\n          hosts:\n            - host: sharinghub.example.com\n              paths:\n                - path: /mlflow/\n                  pathType: ImplementationSpecific\n          tls:\n            - secretName: sharinghub.example.com-tls\n              hosts:\n                - sharinghub.example.com\n\n  syncPolicy:\n    syncOptions:\n      - FailOnSharedResource=true\n      - CreateNamespace=true\n```\n\n**Required Secrets:**\n\n```bash\n# Secret key for security\nkubectl create secret generic mlflow-sharinghub \\\n  --from-literal secret-key=\"\u003c64-char-random-string\u003e\" \\\n  --namespace sharinghub\n\n# PostgreSQL credentials\nkubectl create secret generic mlflow-sharinghub-postgres \\\n  --from-literal password=\"\u003cmlflow-user-password\u003e\" \\\n  --from-literal postgres-password=\"\u003croot-password\u003e\" \\\n  --namespace sharinghub\n\n# S3 credentials\nkubectl create secret generic mlflow-sharinghub-s3 \\\n  --from-literal access-key-id=\"\u003caccess-key\u003e\" \\\n  --from-literal secret-access-key=\"\u003csecret-key\u003e\" \\\n  --namespace sharinghub\n```\n\nSources: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:29-110](), [docs/admin/configuration.md:281-359]()\n\n## Configuration Validation\n\nAfter applying the configuration, verify the deployment:\n\n**Check pod status:**\n```bash\nkubectl get pods -n sharinghub -l app.kubernetes.io/name=mlflow-sharinghub\n```\n\n**Check logs:**\n```bash\nkubectl logs -n sharinghub deployment/mlflow-sharinghub\n```\n\n**Expected log output:**\n- `INFO:werkzeug: * Running on http://0.0.0.0:5000/`\n- `INFO:mlflow_sharinghub.app:SharingHub integration enabled`\n- `INFO:mlflow_sharinghub.app:Backend store: postgresql://...`\n- `INFO:mlflow_sharinghub.app:Artifacts destination: s3://...`\n\n**Test access:**\n```bash\ncurl -k https://sharinghub.example.com/mlflow/health\n```\n\nExpected response: `{\"status\": \"healthy\"}`\n\nSources: [docs/admin/deployment-guide/components/mlflow-sharinghub.md:106-110]()"])</script><script>self.__next_f.push([1,"2b:T37ba,"])</script><script>self.__next_f.push([1,"# API Reference\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/api/endpoint-specification.md](docs/api/endpoint-specification.md)\n- [docs/api/usage.md](docs/api/usage.md)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis section documents the programmatic APIs exposed by the EOEPCA MLOps Building Block for discovering, accessing, and tracking machine learning models and datasets. The platform exposes two primary APIs:\n\n1. **SharingHub STAC API** - A standards-compliant SpatioTemporal Asset Catalog (STAC) API for discovering and downloading AI models and datasets\n2. **MLflow Tracking API** - A REST API for logging experiments, parameters, metrics, and registering models\n\nThis page provides an overview of both APIs, their authentication mechanisms, and the relationships between API endpoints and backend components. For detailed STAC API specifications and usage examples, see [STAC API Specification](#7.1) and [Using the STAC API](#7.2).\n\nFor information about configuring these APIs during deployment, see [SharingHub Configuration](#6.1) and [MLflow SharingHub Configuration](#6.2).\n\n## API Overview\n\nThe MLOps Building Block exposes APIs through two main services, each serving distinct purposes in the ML lifecycle:\n\n| API | Base Path | Purpose | Standard Compliance |\n|-----|-----------|---------|---------------------|\n| SharingHub STAC API | `/api/stac` | Catalog discovery and asset download | STAC 1.0.0 |\n| SharingHub Download API | `/api/download` | Direct file download from GitLab projects | Custom |\n| MLflow Tracking API | `/mlflow/api` | Experiment tracking and model registration | MLflow REST API |\n| MLflow Model Registry API | `/mlflow/api/2.0/mlflow` | Model lifecycle management | MLflow REST API |\n\nSources: [docs/api/usage.md:1-76](), [docs/api/endpoint-specification.md:1-9]()\n\n## API Architecture\n\nThe following diagram shows how the APIs map to backend services and their responsibilities:\n\n```mermaid\ngraph TB\n    subgraph \"External Clients\"\n        PythonClient[\"Python Client\u003cbr/\u003e(pystac, mlflow)\"]\n        WebBrowser[\"Web Browser\"]\n        CLITool[\"CLI Tool\u003cbr/\u003e(curl, wget)\"]\n    end\n    \n    subgraph \"API Gateway Layer\"\n        NginxIngress[\"NGINX Ingress\u003cbr/\u003eTLS Termination\"]\n    end\n    \n    subgraph \"SharingHub APIs\"\n        STACRoot[\"/api/stac\u003cbr/\u003eSTAC Root Catalog\"]\n        STACCollections[\"/api/stac/collections\u003cbr/\u003eSTAC Collections\"]\n        STACItems[\"/api/stac/collections/{collection}/items\u003cbr/\u003eSTAC Items\"]\n        DownloadAPI[\"/api/download/{project}/repository/{file}\u003cbr/\u003eFile Download\"]\n        OpenAPISpec[\"/openapi.json\u003cbr/\u003eOpenAPI Specification\"]\n    end\n    \n    subgraph \"MLflow APIs\"\n        TrackingAPI[\"/mlflow/api/2.0/mlflow/runs\u003cbr/\u003eExperiment Tracking\"]\n        RegistryAPI[\"/mlflow/api/2.0/mlflow/registered-models\u003cbr/\u003eModel Registry\"]\n        GetArtifact[\"/mlflow/get-artifact\u003cbr/\u003eArtifact Download\"]\n    end\n    \n    subgraph \"Backend Services\"\n        SharingHubService[\"SharingHub Service\u003cbr/\u003eFastAPI Application\"]\n        MLflowService[\"MLflow SharingHub Service\u003cbr/\u003eFlask Application\"]\n        GitLabAPI[\"GitLab REST API\u003cbr/\u003eProject Metadata\"]\n        PostgreSQL[\"PostgreSQL\u003cbr/\u003eMLflow Metadata\"]\n        S3Storage[\"S3 Object Storage\u003cbr/\u003eArtifacts \u0026 Models\"]\n    end\n    \n    PythonClient --\u003e|HTTPS| NginxIngress\n    WebBrowser --\u003e|HTTPS| NginxIngress\n    CLITool --\u003e|HTTPS| NginxIngress\n    \n    NginxIngress --\u003e STACRoot\n    NginxIngress --\u003e STACCollections\n    NginxIngress --\u003e STACItems\n    NginxIngress --\u003e DownloadAPI\n    NginxIngress --\u003e OpenAPISpec\n    NginxIngress --\u003e TrackingAPI\n    NginxIngress --\u003e RegistryAPI\n    NginxIngress --\u003e GetArtifact\n    \n    STACRoot --\u003e SharingHubService\n    STACCollections --\u003e SharingHubService\n    STACItems --\u003e SharingHubService\n    DownloadAPI --\u003e SharingHubService\n    OpenAPISpec --\u003e SharingHubService\n    \n    TrackingAPI --\u003e MLflowService\n    RegistryAPI --\u003e MLflowService\n    GetArtifact --\u003e MLflowService\n    \n    SharingHubService --\u003e|\"Query Projects\"| GitLabAPI\n    SharingHubService --\u003e|\"Proxy Downloads\"| GitLabAPI\n    \n    MLflowService --\u003e|\"Store Metadata\"| PostgreSQL\n    MLflowService --\u003e|\"Store/Retrieve Artifacts\"| S3Storage\n    MLflowService --\u003e|\"Check Permissions\"| SharingHubService\n```\n\nSources: [docs/api/usage.md:31](), [docs/api/endpoint-specification.md:1-9]()\n\n## Authentication and Authorization\n\nAll APIs use token-based authentication with GitLab access tokens. The authentication flow differs slightly between SharingHub and MLflow APIs:\n\n```mermaid\ngraph TB\n    subgraph \"Client Request\"\n        Client[\"API Client\"]\n        Token[\"GitLab Access Token\u003cbr/\u003eScope: read_api\"]\n    end\n    \n    subgraph \"SharingHub STAC API Authentication\"\n        STACRequest[\"GET /api/stac/collections/aimodel/items/project/model\"]\n        STACAuth[\"X-Gitlab-Token Header\"]\n        STACValidate[\"Validate Token with GitLab API\"]\n        STACCheck[\"Check Project Permissions\"]\n        STACResponse[\"Return STAC Item JSON\"]\n    end\n    \n    subgraph \"SharingHub Download API Authentication\"\n        DownloadRequest[\"GET /api/download/{project}/repository/{file}\"]\n        DownloadAuth[\"X-Gitlab-Token Header\"]\n        DownloadProxy[\"Proxy to GitLab with Token\"]\n        DownloadFile[\"Stream File Content\"]\n    end\n    \n    subgraph \"MLflow API Authentication\"\n        MLflowRequest[\"POST /mlflow/api/2.0/mlflow/runs/log-metric\"]\n        MLflowAuth[\"Authorization: Bearer token\"]\n        MLflowDelegate[\"Delegate to SharingHub\"]\n        MLflowPermCheck[\"Check Experiment Permissions\"]\n        MLflowResponse[\"Return Success/Error\"]\n    end\n    \n    Client --\u003e Token\n    Token --\u003e STACAuth\n    Token --\u003e DownloadAuth\n    Token --\u003e MLflowAuth\n    \n    STACAuth --\u003e STACRequest\n    STACRequest --\u003e STACValidate\n    STACValidate --\u003e STACCheck\n    STACCheck --\u003e STACResponse\n    \n    DownloadAuth --\u003e DownloadRequest\n    DownloadRequest --\u003e DownloadProxy\n    DownloadProxy --\u003e DownloadFile\n    \n    MLflowAuth --\u003e MLflowRequest\n    MLflowRequest --\u003e MLflowDelegate\n    MLflowDelegate --\u003e MLflowPermCheck\n    MLflowPermCheck --\u003e MLflowResponse\n```\n\nSources: [docs/api/usage.md:27-30](), [docs/api/usage.md:59]()\n\n### Authentication Methods\n\n| API | Header Name | Header Format | Token Scope |\n|-----|-------------|---------------|-------------|\n| STAC API | `X-Gitlab-Token` | `\u003caccess_token\u003e` | `read_api` |\n| Download API | `X-Gitlab-Token` | `\u003caccess_token\u003e` | `read_api` |\n| MLflow Tracking API | `Authorization` | `Bearer \u003caccess_token\u003e` | `api` or `read_api` |\n\n**Obtaining Access Tokens:**\n\n1. **Personal Access Token**: Generate from GitLab user settings (Settings  Access Tokens)\n2. **Project Access Token**: Generate from GitLab project settings (Settings  Access Tokens)\n3. **OAuth Token**: Obtain through OIDC flow if using SharingHub Web UI\n\nSources: [docs/api/usage.md:27](), [docs/api/usage.md:59]()\n\n## STAC API Endpoints\n\nThe SharingHub STAC API follows the STAC specification and provides hierarchical catalog access:\n\n### Core STAC Endpoints\n\n| Endpoint | Method | Description | Returns |\n|----------|--------|-------------|---------|\n| `/api/stac` | GET | Root catalog | STAC Catalog JSON |\n| `/api/stac/collections` | GET | List all collections | STAC Collection list |\n| `/api/stac/collections/{collection_id}` | GET | Get specific collection | STAC Collection JSON |\n| `/api/stac/collections/{collection_id}/items` | GET | List items in collection | STAC Item list |\n| `/api/stac/collections/{collection_id}/items/{item_id}` | GET | Get specific item | STAC Item JSON |\n\n**Collection IDs** correspond to SharingHub categories:\n- `aimodel` - AI model projects with topic `sharinghub:aimodel`\n- `dataset` - Dataset projects with topic `sharinghub:dataset`\n- `processor` - Processor projects with topic `sharinghub:processor`\n\n**Item IDs** follow the pattern: `{gitlab_namespace}/{project_name}`\n\nSources: [docs/api/usage.md:31](), [docs/api/endpoint-specification.md:5-9]()\n\n### Download Endpoints\n\n| Endpoint | Method | Description |\n|----------|--------|-------------|\n| `/api/download/{namespace}/{project}/repository/{file}?ref={branch}` | GET | Download file from GitLab project repository |\n| `/mlflow/get-artifact?path={artifact_path}\u0026run_uuid={run_id}` | GET | Download MLflow artifact from S3 |\n\nSources: [docs/api/usage.md:72]()\n\n## MLflow API Endpoints\n\nThe MLflow SharingHub exposes the standard MLflow REST API for experiment tracking and model registry operations:\n\n### Experiment Tracking Endpoints\n\n| Endpoint | Method | Description |\n|----------|--------|-------------|\n| `/mlflow/api/2.0/mlflow/runs/create` | POST | Create a new run |\n| `/mlflow/api/2.0/mlflow/runs/log-metric` | POST | Log metric for a run |\n| `/mlflow/api/2.0/mlflow/runs/log-parameter` | POST | Log parameter for a run |\n| `/mlflow/api/2.0/mlflow/runs/log-batch` | POST | Log metrics, params, and tags in batch |\n| `/mlflow/api/2.0/mlflow/runs/get` | GET | Get run details |\n\n### Model Registry Endpoints\n\n| Endpoint | Method | Description |\n|----------|--------|-------------|\n| `/mlflow/api/2.0/mlflow/registered-models/create` | POST | Register a new model |\n| `/mlflow/api/2.0/mlflow/model-versions/create` | POST | Create a new model version |\n| `/mlflow/api/2.0/mlflow/model-versions/get` | GET | Get model version details |\n| `/mlflow/api/2.0/mlflow/registered-models/search` | GET | Search registered models |\n\nFor complete MLflow API documentation, refer to the official MLflow REST API documentation at https://mlflow.org/docs/latest/rest-api.html.\n\nSources: [docs/api/endpoint-specification.md:1-9]()\n\n## API Response Formats\n\n### STAC Item Structure\n\nWhen requesting a STAC item, the response follows the STAC specification with MLOps-specific extensions:\n\n```mermaid\ngraph LR\n    subgraph \"STAC Item Response\"\n        ItemRoot[\"Item Root Object\"]\n        Properties[\"properties\"]\n        Assets[\"assets\"]\n        Links[\"links\"]\n        Extensions[\"stac_extensions\"]\n    end\n    \n    subgraph \"Properties Fields\"\n        Title[\"title\"]\n        Description[\"description\"]\n        DateTime[\"datetime\"]\n        GitLabTags[\"gitlab:tags\"]\n        GitLabTopics[\"gitlab:topics\"]\n    end\n    \n    subgraph \"Asset Types\"\n        DataAsset[\"data role\u003cbr/\u003eModel files, datasets\"]\n        MetadataAsset[\"metadata role\u003cbr/\u003eREADME, docs\"]\n        ThumbnailAsset[\"thumbnail role\u003cbr/\u003ePreview images\"]\n    end\n    \n    subgraph \"Extensions Applied\"\n        MLModelExt[\"ml-model\u003cbr/\u003eAI model metadata\"]\n        EOExt[\"eo\u003cbr/\u003eEarth Observation\"]\n        FileExt[\"file\u003cbr/\u003eFile info\"]\n    end\n    \n    ItemRoot --\u003e Properties\n    ItemRoot --\u003e Assets\n    ItemRoot --\u003e Links\n    ItemRoot --\u003e Extensions\n    \n    Properties --\u003e Title\n    Properties --\u003e Description\n    Properties --\u003e DateTime\n    Properties --\u003e GitLabTags\n    Properties --\u003e GitLabTopics\n    \n    Assets --\u003e DataAsset\n    Assets --\u003e MetadataAsset\n    Assets --\u003e ThumbnailAsset\n    \n    Extensions --\u003e MLModelExt\n    Extensions --\u003e EOExt\n    Extensions --\u003e FileExt\n```\n\n**Key Fields:**\n\n- `id`: GitLab project full path (e.g., `namespace/project-name`)\n- `type`: Always `\"Feature\"` for STAC items\n- `geometry`: null (not geospatial by default)\n- `bbox`: null (not geospatial by default)\n- `assets`: Dictionary of downloadable files with metadata\n- `links`: Relationships to parent collection, project URL, etc.\n\nSources: [docs/api/usage.md:35-38]()\n\n## OpenAPI Specification\n\nThe complete SharingHub API specification is available in OpenAPI 3.0 format:\n\n**Specification URL:** `https://{sharinghub-domain}/openapi.json`\n\nThe OpenAPI specification includes:\n- All endpoint paths and methods\n- Request/response schemas\n- Authentication requirements\n- Example requests and responses\n- Error codes and messages\n\nAn interactive Swagger UI is also available at the same domain for exploring the API interactively.\n\nSources: [docs/api/endpoint-specification.md:5-9]()\n\n## API Integration Example\n\nThe following diagram shows a typical API integration workflow for downloading a model:\n\n```mermaid\nsequenceDiagram\n    participant Client as \"Python Client\"\n    participant StacIO as \"pystac.StacIO\"\n    participant STACAPI as \"SharingHub STAC API\"\n    participant DownloadAPI as \"SharingHub Download API\"\n    participant GitLab as \"GitLab Repository\"\n    \n    Client-\u003e\u003eStacIO: \"Configure auth headers\"\n    Note over StacIO: headers = {\"X-Gitlab-Token\": \"token\"}\n    \n    Client-\u003e\u003eStacIO: \"Item.from_file(stac_url)\"\n    StacIO-\u003e\u003eSTACAPI: \"GET /api/stac/collections/aimodel/items/{item_id}\"\n    STACAPI-\u003e\u003eSTACAPI: \"Validate token with GitLab\"\n    STACAPI-\u003e\u003eSTACAPI: \"Check project permissions\"\n    STACAPI--\u003e\u003eStacIO: \"Return STAC Item JSON\"\n    StacIO--\u003e\u003eClient: \"pystac.Item object\"\n    \n    Client-\u003e\u003eClient: \"Extract assets with role='data'\"\n    \n    loop \"For each asset\"\n        Client-\u003e\u003eDownloadAPI: \"GET asset.href with auth headers\"\n        DownloadAPI-\u003e\u003eGitLab: \"Proxy request with token\"\n        GitLab--\u003e\u003eDownloadAPI: \"Stream file content\"\n        DownloadAPI--\u003e\u003eClient: \"Stream file content\"\n        Client-\u003e\u003eClient: \"Write to local file\"\n    end\n    \n    Client-\u003e\u003eClient: \"Complete\"\n```\n\nSources: [docs/api/usage.md:20-76]()\n\n## Error Handling\n\nBoth APIs return standard HTTP status codes with JSON error responses:\n\n| Status Code | Meaning | Common Causes |\n|-------------|---------|---------------|\n| 200 | Success | Request completed successfully |\n| 401 | Unauthorized | Invalid or missing authentication token |\n| 403 | Forbidden | Token valid but insufficient permissions |\n| 404 | Not Found | Collection, item, or resource does not exist |\n| 500 | Internal Server Error | Backend service failure |\n\n**Example Error Response:**\n```json\n{\n  \"detail\": \"Project not found or access denied\",\n  \"status_code\": 404\n}\n```\n\n## Next Steps\n\nFor detailed information about using these APIs:\n\n- See [STAC API Specification](#7.1) for complete endpoint documentation and schemas\n- See [Using the STAC API](#7.2) for practical examples and client library usage\n- See [SharingHub Configuration](#6.1) for API configuration options\n- See [Model Training Workflow](#4.1) for how APIs integrate into the ML lifecycle\n\nSources: [docs/api/usage.md:1-76](), [docs/api/endpoint-specification.md:1-9]()"])</script><script>self.__next_f.push([1,"2c:T44bd,"])</script><script>self.__next_f.push([1,"# STAC API Specification\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/api/endpoint-specification.md](docs/api/endpoint-specification.md)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis document provides the technical specification for the SharingHub STAC (SpatioTemporal Asset Catalog) API. The STAC API is the primary interface for programmatically discovering and accessing AI models, datasets, and processors registered in the MLOps platform. It implements the STAC specification standard to provide a standardized catalog interface for Earth Observation and machine learning assets.\n\nThis page covers the API specification, including endpoints, data models, extensions, and authentication mechanisms. For practical examples of using the STAC API with client libraries, see [Using the STAC API](#7.2). For broader context on the SharingHub component that exposes this API, see [SharingHub](#3.2).\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n## STAC Standard Overview\n\nThe STAC API exposed by SharingHub implements the STAC specification, which provides a common language to describe geospatial information and assets. In the MLOps context, STAC serves as a standardized discovery layer that:\n\n- Organizes assets into a hierarchical catalog structure (Catalog  Collections  Items)\n- Supports extensibility through STAC extensions (ml-model, eo, etc.)\n- Enables filtering and search capabilities\n- Provides standardized asset links for downloading models and datasets\n- Maintains compatibility with existing STAC client tools and libraries\n\nThe SharingHub implementation dynamically generates the STAC catalog from GitLab projects, using GitLab topics to determine collection membership and project metadata to populate STAC item properties.\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n## API Endpoint Structure\n\n### Core STAC Endpoints\n\nThe SharingHub STAC API is exposed at the base path `/stac` and implements the following standard STAC endpoints:\n\n**Diagram: STAC API Endpoint Hierarchy**\n\n```mermaid\ngraph TB\n    BASE[\"/stac\"]\n    ROOT[\"/stac/\"]\n    CATALOG[\"GET /stac/\u003cbr/\u003eRoot Catalog\"]\n    COLLECTIONS[\"GET /stac/collections\u003cbr/\u003eList all Collections\"]\n    COLLECTION[\"GET /stac/collections/{collection_id}\u003cbr/\u003eGet Collection by ID\"]\n    ITEMS[\"GET /stac/collections/{collection_id}/items\u003cbr/\u003eList Items in Collection\"]\n    ITEM[\"GET /stac/collections/{collection_id}/items/{item_id}\u003cbr/\u003eGet Item by ID\"]\n    OPENAPI[\"GET /openapi.json\u003cbr/\u003eOpenAPI Specification\"]\n    \n    BASE --\u003e CATALOG\n    BASE --\u003e COLLECTIONS\n    BASE --\u003e OPENAPI\n    COLLECTIONS --\u003e COLLECTION\n    COLLECTION --\u003e ITEMS\n    ITEMS --\u003e ITEM\n    \n    CATALOG -.returns.-\u003e ROOT_RESP[\"STAC Catalog Object\u003cbr/\u003eid: gitlab-cs\u003cbr/\u003elinks to collections\"]\n    COLLECTIONS -.returns.-\u003e COLL_LIST[\"Array of STAC Collection Objects\"]\n    COLLECTION -.returns.-\u003e COLL_OBJ[\"STAC Collection Object\u003cbr/\u003ewith extent, keywords\"]\n    ITEMS -.returns.-\u003e ITEMS_LIST[\"Array of STAC Item Objects\"]\n    ITEM -.returns.-\u003e ITEM_OBJ[\"STAC Item Object\u003cbr/\u003ewith assets, properties, extensions\"]\n```\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n### Endpoint Details\n\n| Endpoint | Method | Purpose | Response Type |\n|----------|--------|---------|---------------|\n| `/stac/` | GET | Retrieve root STAC catalog | STAC Catalog JSON |\n| `/stac/collections` | GET | List all available collections | Array of STAC Collections |\n| `/stac/collections/{collection_id}` | GET | Get specific collection details | STAC Collection JSON |\n| `/stac/collections/{collection_id}/items` | GET | List items in a collection | Array of STAC Items |\n| `/stac/collections/{collection_id}/items/{item_id}` | GET | Get specific item details | STAC Item JSON |\n| `/openapi.json` | GET | OpenAPI specification document | OpenAPI 3.0 JSON |\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n## Data Models\n\n### STAC Object Hierarchy\n\nThe STAC API organizes content in a three-tier hierarchy that maps directly to GitLab project organization:\n\n**Diagram: STAC Data Model Hierarchy and GitLab Mapping**\n\n```mermaid\ngraph TB\n    subgraph \"STAC Layer\"\n        CATALOG[\"STAC Catalog\u003cbr/\u003etype: Catalog\u003cbr/\u003eid: gitlab-cs\"]\n        COLLECTION1[\"STAC Collection\u003cbr/\u003etype: Collection\u003cbr/\u003eid: aimodel\u003cbr/\u003ekeywords: [AI, ML]\"]\n        COLLECTION2[\"STAC Collection\u003cbr/\u003etype: Collection\u003cbr/\u003eid: dataset\u003cbr/\u003ekeywords: [Data, EO]\"]\n        COLLECTION3[\"STAC Collection\u003cbr/\u003etype: Collection\u003cbr/\u003eid: processor\u003cbr/\u003ekeywords: [Processing]\"]\n        ITEM1[\"STAC Item\u003cbr/\u003etype: Feature\u003cbr/\u003eid: project-123\u003cbr/\u003eextensions: [ml-model]\"]\n        ITEM2[\"STAC Item\u003cbr/\u003etype: Feature\u003cbr/\u003eid: project-456\u003cbr/\u003eextensions: [eo]\"]\n        ITEM3[\"STAC Item\u003cbr/\u003etype: Feature\u003cbr/\u003eid: project-789\u003cbr/\u003eextensions: [ml-model]\"]\n    end\n    \n    subgraph \"GitLab Layer\"\n        GITLAB[\"GitLab Instance\"]\n        TOPIC1[\"Projects with\u003cbr/\u003esharinghub:aimodel topic\"]\n        TOPIC2[\"Projects with\u003cbr/\u003esharinghub:dataset topic\"]\n        TOPIC3[\"Projects with\u003cbr/\u003esharinghub:processor topic\"]\n        PROJECT1[\"GitLab Project\u003cbr/\u003eID: 123\u003cbr/\u003eflood-detection\"]\n        PROJECT2[\"GitLab Project\u003cbr/\u003eID: 456\u003cbr/\u003esen1floods11-dataset\"]\n        PROJECT3[\"GitLab Project\u003cbr/\u003eID: 789\u003cbr/\u003ewine-quality-model\"]\n    end\n    \n    CATALOG --\u003e COLLECTION1\n    CATALOG --\u003e COLLECTION2\n    CATALOG --\u003e COLLECTION3\n    \n    COLLECTION1 --\u003e ITEM1\n    COLLECTION1 --\u003e ITEM3\n    COLLECTION2 --\u003e ITEM2\n    COLLECTION3\n    \n    GITLAB --\u003e TOPIC1\n    GITLAB --\u003e TOPIC2\n    GITLAB --\u003e TOPIC3\n    \n    TOPIC1 --\u003e PROJECT1\n    TOPIC1 --\u003e PROJECT3\n    TOPIC2 --\u003e PROJECT2\n    \n    PROJECT1 -.mapped to.-\u003e ITEM1\n    PROJECT2 -.mapped to.-\u003e ITEM2\n    PROJECT3 -.mapped to.-\u003e ITEM3\n```\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n### STAC Catalog Object\n\nThe root catalog object represents the entire SharingHub catalog:\n\n```json\n{\n  \"type\": \"Catalog\",\n  \"id\": \"gitlab-cs\",\n  \"stac_version\": \"1.0.0\",\n  \"description\": \"STAC Catalog for GitLab projects\",\n  \"links\": [\n    {\n      \"rel\": \"self\",\n      \"href\": \"/stac/\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"rel\": \"root\",\n      \"href\": \"/stac/\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"rel\": \"child\",\n      \"href\": \"/stac/collections/aimodel\",\n      \"type\": \"application/json\"\n    }\n  ]\n}\n```\n\n**Key Properties:**\n- `id`: Fixed identifier `gitlab-cs`\n- `stac_version`: STAC specification version (1.0.0)\n- `links`: Array of link objects connecting to collections\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n### STAC Collection Object\n\nCollections represent categories of assets (AI models, datasets, processors):\n\n```json\n{\n  \"type\": \"Collection\",\n  \"id\": \"aimodel\",\n  \"stac_version\": \"1.0.0\",\n  \"title\": \"AI Model\",\n  \"description\": \"AI Models and Machine Learning assets\",\n  \"keywords\": [\"AI\", \"Machine Learning\", \"Model\"],\n  \"license\": \"various\",\n  \"extent\": {\n    \"spatial\": {\n      \"bbox\": [[-180, -90, 180, 90]]\n    },\n    \"temporal\": {\n      \"interval\": [[null, null]]\n    }\n  },\n  \"links\": [\n    {\n      \"rel\": \"self\",\n      \"href\": \"/stac/collections/aimodel\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"rel\": \"root\",\n      \"href\": \"/stac/\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"rel\": \"items\",\n      \"href\": \"/stac/collections/aimodel/items\",\n      \"type\": \"application/json\"\n    }\n  ]\n}\n```\n\n**Key Properties:**\n- `id`: Collection identifier mapped from GitLab topic (e.g., `aimodel`, `dataset`, `processor`)\n- `keywords`: Tags and categories for filtering\n- `extent`: Spatial and temporal extent of collection items\n- `links`: Navigation links to items and parent catalog\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n### STAC Item Object\n\nItems represent individual GitLab projects as discoverable assets:\n\n```json\n{\n  \"type\": \"Feature\",\n  \"stac_version\": \"1.0.0\",\n  \"id\": \"123\",\n  \"collection\": \"aimodel\",\n  \"geometry\": null,\n  \"bbox\": null,\n  \"properties\": {\n    \"datetime\": \"2024-01-15T10:30:00Z\",\n    \"title\": \"Flood Detection Model\",\n    \"description\": \"Deep learning model for flood detection\",\n    \"gitlab:project_id\": 123,\n    \"gitlab:namespace\": \"ml-models\",\n    \"gitlab:web_url\": \"https://gitlab.domain/ml-models/flood-detection\",\n    \"created\": \"2024-01-10T08:00:00Z\",\n    \"updated\": \"2024-01-15T10:30:00Z\"\n  },\n  \"assets\": {\n    \"model\": {\n      \"href\": \"https://sharinghub.domain/mlflow/models/flood-model.onnx\",\n      \"type\": \"application/octet-stream\",\n      \"roles\": [\"ml-model:checkpoint\"],\n      \"title\": \"ONNX Model File\"\n    },\n    \"thumbnail\": {\n      \"href\": \"https://gitlab.domain/ml-models/flood-detection/-/avatar\",\n      \"type\": \"image/png\",\n      \"roles\": [\"thumbnail\"]\n    }\n  },\n  \"links\": [\n    {\n      \"rel\": \"self\",\n      \"href\": \"/stac/collections/aimodel/items/123\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"rel\": \"parent\",\n      \"href\": \"/stac/collections/aimodel\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"rel\": \"collection\",\n      \"href\": \"/stac/collections/aimodel\",\n      \"type\": \"application/json\"\n    }\n  ],\n  \"stac_extensions\": [\n    \"https://stac-extensions.github.io/ml-model/v1.0.0/schema.json\"\n  ]\n}\n```\n\n**Key Properties:**\n- `id`: GitLab project ID as string\n- `collection`: Parent collection identifier\n- `properties`: Metadata extracted from GitLab project\n- `assets`: Downloadable files (models, datasets, documentation)\n- `stac_extensions`: Array of STAC extension URIs applied to this item\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n## STAC Extensions\n\nSharingHub implements STAC extensions to provide domain-specific metadata:\n\n**Diagram: STAC Extension Usage by Collection Type**\n\n```mermaid\ngraph LR\n    subgraph \"STAC Item Types\"\n        AIMODEL[\"AI Model Items\u003cbr/\u003ecollection: aimodel\"]\n        DATASET[\"Dataset Items\u003cbr/\u003ecollection: dataset\"]\n        PROCESSOR[\"Processor Items\u003cbr/\u003ecollection: processor\"]\n    end\n    \n    subgraph \"STAC Extensions\"\n        MLEXT[\"ml-model Extension\u003cbr/\u003ev1.0.0\"]\n        EOEXT[\"eo Extension\u003cbr/\u003ev1.1.0\"]\n        BASEEXT[\"Base STAC\u003cbr/\u003ev1.0.0\"]\n    end\n    \n    subgraph \"Extension Properties\"\n        MLPROPS[\"ml-model:architecture\u003cbr/\u003eml-model:learning_approach\u003cbr/\u003eml-model:prediction_type\"]\n        EOPROPS[\"eo:bands\u003cbr/\u003eeo:cloud_cover\u003cbr/\u003eeo:gsd\"]\n        BASEPROPS[\"datetime\u003cbr/\u003etitle\u003cbr/\u003edescription\"]\n    end\n    \n    AIMODEL --\u003e MLEXT\n    DATASET --\u003e EOEXT\n    PROCESSOR --\u003e BASEEXT\n    \n    MLEXT --\u003e MLPROPS\n    EOEXT --\u003e EOPROPS\n    BASEEXT --\u003e BASEPROPS\n```\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n### ml-model Extension\n\nApplied to AI model items (collection `aimodel`):\n\n| Property | Type | Description |\n|----------|------|-------------|\n| `ml-model:architecture` | string | Model architecture (e.g., \"resnet50\", \"unet\") |\n| `ml-model:learning_approach` | string | Learning type (\"supervised\", \"unsupervised\") |\n| `ml-model:prediction_type` | string | Task type (\"classification\", \"segmentation\") |\n| `ml-model:framework` | string | Framework used (e.g., \"pytorch\", \"tensorflow\") |\n| `ml-model:framework_version` | string | Framework version |\n| `ml-model:memory_size` | integer | Model memory footprint in bytes |\n\n### eo Extension\n\nApplied to Earth Observation dataset items (collection `dataset`):\n\n| Property | Type | Description |\n|----------|------|-------------|\n| `eo:bands` | array | Spectral bands included in dataset |\n| `eo:cloud_cover` | number | Cloud cover percentage (0-100) |\n| `eo:gsd` | number | Ground sample distance in meters |\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n## Authentication and Authorization\n\n### Authentication Flow\n\n**Diagram: STAC API Authentication Request Flow**\n\n```mermaid\nsequenceDiagram\n    participant Client\n    participant NGINX[\"NGINX Ingress\"]\n    participant SharingHub[\"SharingHub STAC API\"]\n    participant GitLab[\"GitLab API\"]\n    participant KeyCloak[\"KeyCloak OIDC Provider\"]\n    \n    Client-\u003e\u003eNGINX: GET /stac/collections/aimodel/items/123\u003cbr/\u003eAuthorization: Bearer \u003ctoken\u003e\n    NGINX-\u003e\u003eSharingHub: Forward request with token\n    \n    alt Token Provided\n        SharingHub-\u003e\u003eSharingHub: Validate Bearer token format\n        SharingHub-\u003e\u003eGitLab: GET /api/v4/projects/123\u003cbr/\u003eAuthorization: Bearer \u003ctoken\u003e\n        GitLab-\u003e\u003eKeyCloak: Validate OIDC token\n        KeyCloak--\u003e\u003eGitLab: Token valid/invalid\n        GitLab--\u003e\u003eSharingHub: Project details + access level\n        \n        alt User has access\n            SharingHub-\u003e\u003eSharingHub: Generate STAC Item with assets\n            SharingHub--\u003e\u003eClient: 200 OK + STAC Item JSON\n        else User lacks access\n            SharingHub--\u003e\u003eClient: 403 Forbidden\n        end\n    else No Token\n        SharingHub-\u003e\u003eGitLab: GET /api/v4/projects/123\u003cbr/\u003eUse default token (if configured)\n        GitLab--\u003e\u003eSharingHub: Project details (public only)\n        \n        alt Project is public\n            SharingHub--\u003e\u003eClient: 200 OK + STAC Item JSON\n        else Project is private\n            SharingHub--\u003e\u003eClient: 403 Forbidden\n        end\n    end\n```\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n### Authentication Methods\n\nThe STAC API supports two authentication modes:\n\n#### Bearer Token Authentication\n\nAuthenticated requests include a Bearer token in the Authorization header:\n\n```http\nGET /stac/collections/aimodel/items/123 HTTP/1.1\nHost: sharinghub.domain\nAuthorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\n```\n\nThe token is validated against GitLab's OIDC integration with KeyCloak. Users can only access STAC items corresponding to GitLab projects they have permission to view.\n\n#### Unauthenticated Access\n\nIf the `sharinghub-oidc` secret contains a `default-token`, unauthenticated requests are allowed for public projects:\n\n```http\nGET /stac/collections/aimodel/items HTTP/1.1\nHost: sharinghub.domain\n```\n\nThis enables public discovery while maintaining security for private projects. Private projects return `403 Forbidden` for unauthenticated requests.\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n### Permission Mapping\n\n| GitLab Permission Level | STAC API Access |\n|------------------------|-----------------|\n| Guest | Read-only access to STAC item metadata |\n| Reporter | Read-only access to STAC item metadata and assets |\n| Developer | Read-only access to STAC item metadata and assets |\n| Maintainer | Read-only access to STAC item metadata and assets |\n| Owner | Read-only access to STAC item metadata and assets |\n| No Access (Private) | 403 Forbidden |\n| Public Project | Read-only access (if default token configured) |\n\nThe STAC API is read-only; all write operations (creating projects, uploading models) occur through GitLab and MLflow interfaces.\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n## OpenAPI Specification\n\nThe complete OpenAPI 3.0 specification for the SharingHub STAC API is available at:\n\n```\nGET /openapi.json\n```\n\nThis machine-readable specification includes:\n\n- All endpoint definitions with request/response schemas\n- Authentication requirements (Bearer token)\n- Data model schemas for Catalog, Collection, Item objects\n- Extension schemas (ml-model, eo)\n- Example requests and responses\n- Error response formats\n\nThe specification can be consumed by:\n- **Swagger UI**: Interactive API documentation and testing interface (available at `https://sharinghub.develop.eoepca.org/openapi.json`)\n- **OpenAPI Generators**: Auto-generate client libraries in multiple languages\n- **API Testing Tools**: Postman, Insomnia, curl commands\n- **STAC Clients**: pystac-client and other STAC-compliant tools\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n## Error Responses\n\nThe STAC API returns standard HTTP status codes with JSON error bodies:\n\n```json\n{\n  \"code\": 404,\n  \"type\": \"ItemNotFound\",\n  \"description\": \"Item with id '999' not found in collection 'aimodel'\"\n}\n```\n\n**Common Error Codes:**\n\n| Status Code | Error Type | Description |\n|-------------|------------|-------------|\n| 400 | BadRequest | Invalid request parameters or malformed request |\n| 401 | Unauthorized | Missing or invalid Bearer token |\n| 403 | Forbidden | Valid token but insufficient permissions |\n| 404 | NotFound | Collection or item does not exist |\n| 500 | InternalServerError | Server-side error (check SharingHub logs) |\n| 502 | BadGateway | GitLab API unreachable |\n| 503 | ServiceUnavailable | SharingHub temporarily unavailable |\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()\n\n## Query Parameters\n\nThe STAC API supports standard query parameters for filtering and pagination:\n\n### Collection Items Endpoint\n\n```\nGET /stac/collections/{collection_id}/items?limit=10\u0026bbox=-180,-90,180,90\n```\n\n| Parameter | Type | Description | Example |\n|-----------|------|-------------|---------|\n| `limit` | integer | Maximum items to return (default: 100) | `limit=50` |\n| `bbox` | array | Bounding box filter [west, south, east, north] | `bbox=-10,40,10,50` |\n| `datetime` | string | Temporal filter (ISO 8601) | `datetime=2024-01-01/2024-12-31` |\n| `ids` | array | Filter by specific item IDs | `ids=123,456,789` |\n\n### Link Relation Types\n\nSTAC items and collections use standard link relation types:\n\n| Relation | Description |\n|----------|-------------|\n| `self` | Canonical URL for this resource |\n| `root` | Link to root catalog |\n| `parent` | Link to parent collection (for items) |\n| `child` | Link to child collection (for catalogs) |\n| `item` | Link to item (for collections) |\n| `collection` | Link to parent collection (for items) |\n\n**Sources:** [docs/api/endpoint-specification.md:1-9]()"])</script><script>self.__next_f.push([1,"2d:T45a7,"])</script><script>self.__next_f.push([1,"# Using the STAC API\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/api/usage.md](docs/api/usage.md)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis document provides a practical guide for programmatically accessing models and datasets through the SharingHub STAC API. It covers authentication methods, catalog navigation, item retrieval, and asset downloading using standard STAC clients.\n\nFor the formal API specification and endpoint definitions, see [STAC API Specification](#7.1). For information about configuring the STAC catalog and collections on the server side, see [SharingHub Configuration](#6.1).\n\n**Sources:** [docs/api/usage.md:1-76]()\n\n---\n\n## Overview\n\nThe STAC API is the primary programmatic interface for discovering and retrieving AI models and datasets from SharingHub. It implements the SpatioTemporal Asset Catalog (STAC) specification, providing a standardized way to query and access geospatial and ML assets stored in GitLab projects.\n\n### STAC API Architecture\n\n```mermaid\ngraph TB\n    Client[\"STAC Client\u003cbr/\u003e(pystac, requests)\"]\n    StacIO[\"StacIO\u003cbr/\u003eHTTP client with auth headers\"]\n    \n    subgraph \"SharingHub Server\"\n        StacEndpoint[\"/api/stac/*\u003cbr/\u003eSTAC API Endpoints\"]\n        GitLabProxy[\"GitLab Metadata\u003cbr/\u003eExtractor\"]\n        AssetProxy[\"/api/download/*\u003cbr/\u003eAsset Download Proxy\"]\n    end\n    \n    subgraph \"GitLab\"\n        Projects[\"GitLab Projects\u003cbr/\u003ewith sharinghub: topics\"]\n        Repos[\"Git Repositories\u003cbr/\u003emodel files, datasets\"]\n    end\n    \n    Client --\u003e|\"GET /api/stac/collections\"| StacEndpoint\n    Client --\u003e|\"pystac.Item.from_file()\"| StacIO\n    StacIO --\u003e|\"X-Gitlab-Token header\"| StacEndpoint\n    \n    StacEndpoint --\u003e|\"Query projects by topic\"| GitLabProxy\n    GitLabProxy --\u003e|\"GitLab API\"| Projects\n    \n    Client --\u003e|\"GET asset.href\"| AssetProxy\n    AssetProxy --\u003e|\"Proxy with auth\"| Repos\n    \n    StacEndpoint -.-\u003e|\"Generate STAC JSON\"| Client\n```\n\n**Diagram: STAC API request flow from client to GitLab backend**\n\nThe STAC API acts as a dynamic catalog generator that queries GitLab projects and transforms them into STAC-compliant JSON responses. All authentication is handled via GitLab access tokens passed in request headers.\n\n**Sources:** [docs/api/usage.md:1-10]()\n\n---\n\n## Prerequisites and Setup\n\n### Required Dependencies\n\nTo use the STAC API from Python, install the following packages:\n\n```bash\npip install requests pystac\n```\n\n- **`pystac`**: Python library for working with STAC catalogs, collections, and items\n- **`requests`**: HTTP library for downloading assets\n\n### Authentication Requirements\n\nAll STAC API requests require authentication using a GitLab access token with `read_api` scope. The token must be passed in the `X-Gitlab-Token` HTTP header.\n\n| Authentication Method | Header Name | Value Format | Scope Required |\n|----------------------|-------------|--------------|----------------|\n| Personal Access Token | `X-Gitlab-Token` | `\u003cyour_personal_access_token\u003e` | `read_api` |\n| Project Access Token | `X-Gitlab-Token` | `\u003cproject_access_token\u003e` | `read_api` |\n| CI/CD Job Token | `X-Gitlab-Token` | `$CI_JOB_TOKEN` | `read_api` (automatic) |\n\n**Sources:** [docs/api/usage.md:12-16](), [docs/api/usage.md:27](), [docs/api/usage.md:59]()\n\n---\n\n## STAC Catalog Structure\n\n### URL Pattern Mapping\n\nThe SharingHub STAC API follows a hierarchical structure that maps to GitLab concepts:\n\n```mermaid\ngraph LR\n    Root[\"/api/stac\u003cbr/\u003eRoot Catalog\u003cbr/\u003eid: gitlab-cs\"]\n    Collections[\"/api/stac/collections\u003cbr/\u003eSTAC Collections\u003cbr/\u003e(Categories)\"]\n    Items[\"/api/stac/collections/{collection}/items\u003cbr/\u003eSTAC Items\u003cbr/\u003e(GitLab Projects)\"]\n    Item[\"/api/stac/collections/{collection}/items/{namespace}/{project}\u003cbr/\u003eSingle STAC Item\"]\n    \n    Root --\u003e Collections\n    Collections --\u003e Items\n    Items --\u003e Item\n    \n    Collections -.-\u003e|\"Collection: aimodel\u003cbr/\u003esharinghub:aimodel topic\"| GitLabProjects1[\"GitLab Projects\u003cbr/\u003ewith aimodel topic\"]\n    Collections -.-\u003e|\"Collection: dataset\u003cbr/\u003esharinghub:dataset topic\"| GitLabProjects2[\"GitLab Projects\u003cbr/\u003ewith dataset topic\"]\n    Collections -.-\u003e|\"Collection: processor\u003cbr/\u003esharinghub:processor topic\"| GitLabProjects3[\"GitLab Projects\u003cbr/\u003ewith processor topic\"]\n    \n    Item -.-\u003e|\"Item ID: namespace/project\"| SingleProject[\"Specific GitLab Project\"]\n```\n\n**Diagram: STAC API URL hierarchy and GitLab topic mapping**\n\n| STAC Concept | URL Path | GitLab Mapping |\n|--------------|----------|----------------|\n| Root Catalog | `/api/stac` | All SharingHub categories |\n| Collection | `/api/stac/collections/{collection}` | Projects with `sharinghub:{collection}` topic |\n| Items List | `/api/stac/collections/{collection}/items` | All projects in collection |\n| Single Item | `/api/stac/collections/{collection}/items/{namespace}/{project}` | Specific GitLab project |\n\n**Sources:** [docs/api/usage.md:31]()\n\n---\n\n## Configuring the STAC Client\n\n### Basic pystac Setup\n\nThe `pystac` library uses a `StacIO` object to handle HTTP requests. Configure it with authentication headers before making requests:\n\n```python\nfrom pystac import Item, StacIO\n\n# Configure authentication headers\nAUTH_HEADERS = {\"X-Gitlab-Token\": \"\u003cyour_access_token\u003e\"}\n\n# Create StacIO instance with auth\nstac_io = StacIO.default()\nstac_io.headers = AUTH_HEADERS\n```\n\nThe `StacIO.default()` method returns the default HTTP client implementation. Setting the `headers` attribute ensures all subsequent requests include the authentication token.\n\n**Sources:** [docs/api/usage.md:27-30]()\n\n### Authentication Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant PystacClient as \"pystac.Item\"\n    participant StacIO\n    participant SharingHubAPI as \"SharingHub\u003cbr/\u003e/api/stac\"\n    participant GitLabAPI as \"GitLab API\"\n    \n    User-\u003e\u003ePystacClient: Item.from_file(url, stac_io)\n    PystacClient-\u003e\u003eStacIO: GET url\n    StacIO-\u003e\u003eSharingHubAPI: GET /api/stac/...\u003cbr/\u003eX-Gitlab-Token: \u003ctoken\u003e\n    SharingHubAPI-\u003e\u003eGitLabAPI: Validate token \u0026 permissions\n    GitLabAPI--\u003e\u003eSharingHubAPI: Project metadata\n    SharingHubAPI--\u003e\u003eStacIO: STAC Item JSON\n    StacIO--\u003e\u003ePystacClient: Parsed Item\n    PystacClient--\u003e\u003eUser: pystac.Item object\n```\n\n**Diagram: Authentication and request flow using pystac client**\n\n**Sources:** [docs/api/usage.md:29-30](), [docs/api/usage.md:35]()\n\n---\n\n## Retrieving STAC Items\n\n### Loading a Single Item\n\nTo retrieve a specific AI model or dataset, use the `Item.from_file()` method with the full STAC item URL:\n\n```python\nfrom pystac import Item, StacIO\n\n# Configure authentication\nAUTH_HEADERS = {\"X-Gitlab-Token\": \"\u003cyour_access_token\u003e\"}\nstac_io = StacIO.default()\nstac_io.headers = AUTH_HEADERS\n\n# Construct STAC item URL\nSTAC_API_URL = \"https://sharinghub.develop.eoepca.org/api/stac/collections/dataset/items/sharinghub-test/wine-dataset\"\n\n# Load the STAC item\nitem = Item.from_file(STAC_API_URL, stac_io=stac_io)\n```\n\n### STAC Item Properties\n\nA retrieved `pystac.Item` contains:\n\n| Property | Description | Access Method |\n|----------|-------------|---------------|\n| `id` | Unique identifier (namespace/project) | `item.id` |\n| `properties` | Metadata dictionary | `item.properties` |\n| `assets` | Dictionary of downloadable assets | `item.get_assets()` |\n| `links` | Related resources | `item.links` |\n| `geometry` | Spatial extent (if applicable) | `item.geometry` |\n| `bbox` | Bounding box | `item.bbox` |\n\n**Sources:** [docs/api/usage.md:31](), [docs/api/usage.md:35-38]()\n\n---\n\n## Downloading Assets\n\n### Understanding Asset Roles\n\nSTAC items contain multiple assets, each with a specific role. Filter assets by their role to download only the files you need:\n\n```mermaid\ngraph TB\n    StacItem[\"pystac.Item\u003cbr/\u003eSTAC Item Object\"]\n    \n    Assets[\"item.get_assets()\u003cbr/\u003eAll Assets Dictionary\"]\n    \n    DataAssets[\"Assets with role='data'\u003cbr/\u003eTraining datasets, model files\"]\n    MetadataAssets[\"Assets with role='metadata'\u003cbr/\u003eREADME, documentation\"]\n    OtherAssets[\"Other roles\u003cbr/\u003ethumbnails, previews\"]\n    \n    StacItem --\u003e Assets\n    Assets --\u003e DataAssets\n    Assets --\u003e MetadataAssets\n    Assets --\u003e OtherAssets\n    \n    DataAssets --\u003e|\"asset.href\"| DownloadURL[\"Download URL\u003cbr/\u003e/api/download/{ns}/{proj}/...\"]\n```\n\n**Diagram: STAC asset structure and filtering by role**\n\n### Asset Download Pattern\n\nThe recommended pattern for downloading assets:\n\n```python\n# Get only data assets (exclude metadata, thumbnails, etc.)\nitem_assets = [\n    (name, asset) for name, asset in item.get_assets().items() \n    if asset.has_role(\"data\")\n]\n\n# Download each asset\nfor name, asset in item_assets:\n    print(f\"Downloading: {asset.href}\")\n    response = requests.get(asset.href, headers=AUTH_HEADERS)\n    response.raise_for_status()\n    \n    with open(name, \"wb\") as f:\n        f.write(response.content)\n```\n\n### Asset URL Structure\n\nAsset URLs follow this pattern:\n\n```\nhttps://{sharinghub-domain}/api/download/{namespace}/{project}/repository/{file_path}?ref={branch}\n```\n\n| Component | Description | Example |\n|-----------|-------------|---------|\n| `{namespace}` | GitLab group/user | `sharinghub-test` |\n| `{project}` | GitLab project name | `wine-dataset` |\n| `{file_path}` | Path to file in repository | `wine-quality.csv` |\n| `{branch}` | Git branch name | `main` |\n\n**Sources:** [docs/api/usage.md:36-38](), [docs/api/usage.md:44-54](), [docs/api/usage.md:72]()\n\n---\n\n## Complete Download Example\n\n### Full Script\n\nThe following complete example demonstrates downloading a dataset from SharingHub:\n\n[docs/api/usage.md:20-57]()\n\n### Script Workflow\n\n```mermaid\ngraph TD\n    Start[\"Start Script\"]\n    ConfigAuth[\"Configure AUTH_HEADERS\u003cbr/\u003ewith X-Gitlab-Token\"]\n    ConfigStacIO[\"Create StacIO instance\u003cbr/\u003estac_io.headers = AUTH_HEADERS\"]\n    LoadItem[\"Load STAC Item\u003cbr/\u003eItem.from_file(url, stac_io)\"]\n    FilterAssets[\"Filter assets by role='data'\u003cbr/\u003eitem.get_assets()\"]\n    CreatePath[\"Create download directory\u003cbr/\u003e{item_name}-{timestamp}\"]\n    \n    LoopStart{\"For each asset\"}\n    DownloadAsset[\"requests.get(asset.href, headers)\"]\n    WriteFile[\"Write file to disk\u003cbr/\u003efile_path.open('wb')\"]\n    \n    Start --\u003e ConfigAuth\n    ConfigAuth --\u003e ConfigStacIO\n    ConfigStacIO --\u003e LoadItem\n    LoadItem --\u003e FilterAssets\n    FilterAssets --\u003e CreatePath\n    CreatePath --\u003e LoopStart\n    LoopStart --\u003e|\"Next asset\"| DownloadAsset\n    DownloadAsset --\u003e WriteFile\n    WriteFile --\u003e LoopStart\n    LoopStart --\u003e|\"Done\"| End[\"Complete\"]\n```\n\n**Diagram: Download script execution flow**\n\n### Key Implementation Details\n\n1. **Authentication Configuration** ([docs/api/usage.md:27]()): Set `X-Gitlab-Token` header with a token having `read_api` scope\n2. **StacIO Setup** ([docs/api/usage.md:29-30]()): Configure the StacIO client to include auth headers in all requests\n3. **Item Loading** ([docs/api/usage.md:35]()): Use `Item.from_file()` to parse the STAC JSON response\n4. **Asset Filtering** ([docs/api/usage.md:36-38]()): Extract only assets with `role=\"data\"` to avoid downloading metadata files\n5. **Directory Creation** ([docs/api/usage.md:40-42]()): Create timestamped directory based on item ID\n6. **Asset Download** ([docs/api/usage.md:44-54]()): Download each asset using `requests.get()` with authentication headers\n\n### Expected Output\n\nWhen executed successfully, the script produces output similar to:\n\n[docs/api/usage.md:67-75]()\n\n**Sources:** [docs/api/usage.md:20-75]()\n\n---\n\n## Common Use Cases\n\n### Use Case 1: Downloading AI Models\n\nTo download a trained AI model in ONNX format from the `aimodel` collection:\n\n```python\nfrom pystac import Item, StacIO\nimport requests\n\nAUTH_HEADERS = {\"X-Gitlab-Token\": \"\u003ctoken\u003e\"}\nstac_io = StacIO.default()\nstac_io.headers = AUTH_HEADERS\n\n# AI model STAC item URL\nmodel_url = \"https://sharinghub.domain/api/stac/collections/aimodel/items/{namespace}/{model-project}\"\n\n# Load model item\nmodel_item = Item.from_file(model_url, stac_io=stac_io)\n\n# Download ONNX model files\nfor name, asset in model_item.get_assets().items():\n    if asset.has_role(\"data\") and name.endswith(\".onnx\"):\n        response = requests.get(asset.href, headers=AUTH_HEADERS)\n        with open(name, \"wb\") as f:\n            f.write(response.content)\n```\n\n### Use Case 2: Batch Dataset Discovery\n\nTo list all available datasets in a collection:\n\n```python\nfrom pystac import Catalog, StacIO\n\nAUTH_HEADERS = {\"X-Gitlab-Token\": \"\u003ctoken\u003e\"}\nstac_io = StacIO.default()\nstac_io.headers = AUTH_HEADERS\n\n# Load dataset collection\ncollection_url = \"https://sharinghub.domain/api/stac/collections/dataset\"\ncatalog = Catalog.from_file(collection_url, stac_io=stac_io)\n\n# List all items (datasets)\nfor item in catalog.get_items():\n    print(f\"Dataset: {item.id}\")\n    print(f\"  Description: {item.properties.get('description', 'N/A')}\")\n    print(f\"  Assets: {list(item.get_assets().keys())}\")\n```\n\n### Use Case 3: CI/CD Integration\n\nWhen running in a GitLab CI/CD pipeline, use the automatic job token:\n\n```python\nimport os\nfrom pystac import Item, StacIO\n\n# Use CI job token for authentication\nAUTH_HEADERS = {\"X-Gitlab-Token\": os.environ[\"CI_JOB_TOKEN\"]}\nstac_io = StacIO.default()\nstac_io.headers = AUTH_HEADERS\n\n# Access STAC API\nitem_url = \"https://sharinghub.domain/api/stac/collections/aimodel/items/project/model\"\nitem = Item.from_file(item_url, stac_io=stac_io)\n```\n\nThis approach eliminates the need to manage separate access tokens in CI/CD environments.\n\n**Sources:** [docs/api/usage.md:27](), [docs/api/usage.md:59]()\n\n---\n\n## Error Handling\n\n### Common Error Scenarios\n\n| Error Type | HTTP Status | Cause | Solution |\n|------------|-------------|-------|----------|\n| Authentication Failed | 401 | Invalid or missing token | Verify `X-Gitlab-Token` header and token scope |\n| Forbidden | 403 | No access to project | Ensure token owner has project access |\n| Not Found | 404 | Invalid URL or project doesn't exist | Check project namespace and name |\n| Rate Limit | 429 | Too many requests | Implement exponential backoff |\n\n### Example Error Handling\n\n```python\nimport requests\nfrom pystac import Item, StacIO\n\nAUTH_HEADERS = {\"X-Gitlab-Token\": \"\u003ctoken\u003e\"}\nstac_io = StacIO.default()\nstac_io.headers = AUTH_HEADERS\n\ntry:\n    item = Item.from_file(STAC_API_URL, stac_io=stac_io)\nexcept requests.HTTPError as e:\n    if e.response.status_code == 401:\n        print(\"Authentication failed. Check your access token.\")\n    elif e.response.status_code == 403:\n        print(\"Access denied. Verify project permissions.\")\n    elif e.response.status_code == 404:\n        print(\"Item not found. Check the URL and project path.\")\n    else:\n        print(f\"HTTP error: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n```\n\n**Sources:** [docs/api/usage.md:50]()\n\n---\n\n## Best Practices\n\n### Performance Optimization\n\n1. **Reuse StacIO instances**: Create a single `StacIO` object and reuse it for multiple requests to avoid repeated configuration\n2. **Filter assets before downloading**: Use `asset.has_role(\"data\")` to avoid downloading unnecessary metadata files\n3. **Implement retry logic**: Add exponential backoff for transient network errors\n4. **Stream large files**: For large assets, use `requests.get(..., stream=True)` and write in chunks\n\n### Security Considerations\n\n1. **Never commit tokens**: Store access tokens in environment variables or secret management systems\n2. **Use minimal scope**: Request only `read_api` scope for read-only operations\n3. **Rotate tokens regularly**: Periodically regenerate access tokens\n4. **Use HTTPS**: Always connect to SharingHub over HTTPS to protect tokens in transit\n\n### Code Organization\n\n```python\nfrom pathlib import Path\nfrom typing import List, Tuple\nfrom pystac import Item, Asset, StacIO\nimport requests\n\nclass STACDownloader:\n    \"\"\"Helper class for downloading STAC assets.\"\"\"\n    \n    def __init__(self, auth_token: str, base_url: str):\n        self.auth_headers = {\"X-Gitlab-Token\": auth_token}\n        self.stac_io = StacIO.default()\n        self.stac_io.headers = self.auth_headers\n        self.base_url = base_url\n    \n    def load_item(self, collection: str, namespace: str, project: str) -\u003e Item:\n        \"\"\"Load a STAC item from the API.\"\"\"\n        url = f\"{self.base_url}/api/stac/collections/{collection}/items/{namespace}/{project}\"\n        return Item.from_file(url, stac_io=self.stac_io)\n    \n    def download_assets(self, item: Item, output_dir: Path, roles: List[str] = [\"data\"]) -\u003e None:\n        \"\"\"Download item assets with specified roles.\"\"\"\n        output_dir.mkdir(parents=True, exist_ok=True)\n        \n        for name, asset in item.get_assets().items():\n            if any(asset.has_role(role) for role in roles):\n                file_path = output_dir / name\n                response = requests.get(asset.href, headers=self.auth_headers)\n                response.raise_for_status()\n                \n                with file_path.open(\"wb\") as f:\n                    f.write(response.content)\n```\n\n**Sources:** [docs/api/usage.md:20-57]()\n\n---\n\n## Summary\n\nThe SharingHub STAC API provides standardized programmatic access to AI models and datasets stored in GitLab. Key points:\n\n- **Authentication**: All requests require a GitLab access token with `read_api` scope passed via `X-Gitlab-Token` header\n- **Client Library**: Use `pystac` for parsing STAC responses and `requests` for downloading assets\n- **URL Structure**: Follow the pattern `/api/stac/collections/{collection}/items/{namespace}/{project}`\n- **Asset Filtering**: Filter by `role=\"data\"` to download only relevant files\n- **Error Handling**: Implement proper exception handling for authentication, permission, and network errors\n\nFor server-side STAC configuration, see [SharingHub Configuration](#6.1). For API endpoint specifications, see [STAC API Specification](#7.1).\n\n**Sources:** [docs/api/usage.md:1-76]()"])</script><script>self.__next_f.push([1,"2e:T7865,"])</script><script>self.__next_f.push([1,"# Operations and Maintenance\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/maintenance.md](docs/admin/maintenance.md)\n\n\u003c/details\u003e\n\n\n\nThis document provides operational guidelines for managing, monitoring, and maintaining a production deployment of the EOEPCA MLOps Building Block. It covers routine operational tasks, system health monitoring, backup and recovery procedures, and troubleshooting guidance for the three core components (GitLab, SharingHub, MLflow SharingHub) and their supporting infrastructure.\n\nFor detailed maintenance guidelines including version pinning and component upgrade procedures, see [Maintenance Guidelines](#8.1). For initial deployment instructions, see [Deployment Guide](#5).\n\n## Operational Architecture\n\nThe MLOps Building Block consists of multiple interconnected services deployed on Kubernetes, each requiring specific operational considerations.\n\n```mermaid\ngraph TB\n    subgraph \"Operational Monitoring Points\"\n        ARGOCD[\"ArgoCD\u003cbr/\u003eDeployment Status\"]\n        \n        subgraph \"gitlab namespace\"\n            GLHEALTH[\"GitLab Health\u003cbr/\u003e/-/health\u003cbr/\u003e/-/liveness\u003cbr/\u003e/-/readiness\"]\n            GLBACKUP[\"GitLab Backups\u003cbr/\u003ebackup-utility cron\u003cbr/\u003eS3 backup storage\"]\n            GLDB[(\"GitLab PostgreSQL\u003cbr/\u003eDatabase\")]\n            GLREDIS[(\"GitLab Redis\u003cbr/\u003eCache\")]\n        end\n        \n        subgraph \"sharinghub namespace\"\n            SHHEALTH[\"SharingHub Health\u003cbr/\u003e/health endpoint\u003cbr/\u003ePod status\"]\n            SHCACHE[\"STAC Catalog Cache\u003cbr/\u003eRedis optional\"]\n        end\n        \n        subgraph \"mlflow namespace\"\n            MLFHEALTH[\"MLflow Health\u003cbr/\u003e/health endpoint\u003cbr/\u003eTracking server status\"]\n            MLFDB[(\"MLflow PostgreSQL\u003cbr/\u003eExperiments \u0026 Metadata\")]\n            MLFS3[\"MLflow Artifacts\u003cbr/\u003eS3 bucket\"]\n        end\n        \n        subgraph \"Shared Infrastructure\"\n            CERTEXP[\"cert-manager\u003cbr/\u003eCertificate expiry\u003cbr/\u003eRenewal status\"]\n            INGRESS[\"NGINX Ingress\u003cbr/\u003eTraffic metrics\u003cbr/\u003eError rates\"]\n            S3HEALTH[\"S3 Storage\u003cbr/\u003eBucket access\u003cbr/\u003eStorage quotas\"]\n        end\n    end\n    \n    ARGOCD -.monitors.-\u003e GLHEALTH\n    ARGOCD -.monitors.-\u003e SHHEALTH\n    ARGOCD -.monitors.-\u003e MLFHEALTH\n    \n    GLHEALTH --\u003e GLDB\n    GLHEALTH --\u003e GLREDIS\n    GLBACKUP --\u003e S3HEALTH\n    \n    SHHEALTH --\u003e SHCACHE\n    \n    MLFHEALTH --\u003e MLFDB\n    MLFHEALTH --\u003e MLFS3\n    MLFS3 --\u003e S3HEALTH\n    \n    CERTEXP --\u003e INGRESS\n```\n\n**Monitoring and Health Check Architecture**: This diagram shows the key operational monitoring points across the platform. Each component exposes health endpoints for liveness and readiness checks. ArgoCD provides deployment-level monitoring, while individual components require service-specific health checks.\n\nSources: High-level architecture diagrams\n\n## Component Health Monitoring\n\n### GitLab Health Checks\n\nGitLab provides multiple health check endpoints for operational monitoring:\n\n| Endpoint | Purpose | Expected Response |\n|----------|---------|-------------------|\n| `/-/health` | Basic health check | HTTP 200 OK |\n| `/-/liveness` | Kubernetes liveness probe | HTTP 200 if application is alive |\n| `/-/readiness` | Kubernetes readiness probe | HTTP 200 if ready to serve traffic |\n| `/-/metrics` | Prometheus metrics | Detailed metrics in Prometheus format |\n\nMonitor GitLab pod status:\n```bash\nkubectl -n gitlab get pods\nkubectl -n gitlab describe pod \u003cpod-name\u003e\nkubectl -n gitlab logs \u003cpod-name\u003e -c \u003ccontainer-name\u003e\n```\n\nKey containers to monitor:\n- `webservice`: Main GitLab Rails application\n- `sidekiq`: Background job processor\n- `gitlab-shell`: Git SSH operations\n- `kas`: Kubernetes Agent Server\n\n### SharingHub Health Checks\n\nSharingHub exposes health endpoints for operational monitoring. Monitor the application status:\n\n```bash\nkubectl -n sharinghub get pods\nkubectl -n sharinghub logs \u003csharinghub-pod\u003e\n```\n\nKey operational metrics:\n- STAC catalog generation time from GitLab projects\n- API response times for catalog queries\n- GitLab API rate limiting status\n- OAuth token refresh status\n\n### MLflow SharingHub Health Checks\n\nMLflow SharingHub provides health endpoints for tracking server status:\n\n```bash\nkubectl -n mlflow get pods\nkubectl -n mlflow logs \u003cmlflow-sharinghub-pod\u003e\n```\n\nMonitor:\n- Database connection pool status\n- S3 artifact store connectivity\n- SharingHub permission check latency\n- Experiment logging throughput\n\nSources: High-level architecture diagrams, deployment architecture\n\n## Backup and Disaster Recovery\n\n```mermaid\ngraph LR\n    subgraph \"Backup Sources\"\n        GLDB[(\"GitLab PostgreSQL\u003cbr/\u003eUsers, projects,\u003cbr/\u003emetadata\")]\n        GLREPOS[\"GitLab Repositories\u003cbr/\u003eGit data\"]\n        GLREGISTRY[\"GitLab Container\u003cbr/\u003eRegistry images\"]\n        MLFDB[(\"MLflow PostgreSQL\u003cbr/\u003eExperiments,\u003cbr/\u003eruns, metrics\")]\n        MLFS3[\"MLflow S3 Artifacts\u003cbr/\u003eModels, datasets\"]\n    end\n    \n    subgraph \"Backup Storage\"\n        S3BACKUP[\"S3 Backup Bucket\u003cbr/\u003egitlab-backup-\u003cbr/\u003eprefix\"]\n        LOCALBACKUP[\"Local Storage\u003cbr/\u003eOptional\"]\n    end\n    \n    subgraph \"Backup Processes\"\n        GLBACKUP[\"gitlab-backup-utility\u003cbr/\u003eCronJob\u003cbr/\u003eschedule: daily\"]\n        MLFBACKUP[\"mlflow-db-backup\u003cbr/\u003eManual/CronJob\"]\n        PGDUMP[\"pg_dump\u003cbr/\u003ePostgreSQL backup\"]\n    end\n    \n    GLDB --\u003e PGDUMP\n    GLREPOS --\u003e GLBACKUP\n    GLREGISTRY --\u003e GLBACKUP\n    PGDUMP --\u003e GLBACKUP\n    GLBACKUP --\u003e S3BACKUP\n    GLBACKUP -.optional.-\u003e LOCALBACKUP\n    \n    MLFDB --\u003e MLFBACKUP\n    MLFBACKUP --\u003e S3BACKUP\n    MLFS3 -.already in S3.-\u003e S3BACKUP\n```\n\n**Backup and Recovery Architecture**: GitLab uses a scheduled backup utility that stores backups in S3. MLflow's PostgreSQL database requires separate backup procedures. Artifacts stored in S3 can be replicated using S3 bucket replication policies.\n\n### GitLab Backup Configuration\n\nGitLab backups are managed through the `backup-utility` component deployed as a CronJob:\n\n```bash\n# Check backup CronJob status\nkubectl -n gitlab get cronjob backup-utility\n\n# View recent backup jobs\nkubectl -n gitlab get jobs --selector=app=backup-utility\n\n# Manual backup trigger\nkubectl -n gitlab create job --from=cronjob/backup-utility backup-manual-$(date +%Y%m%d-%H%M%S)\n```\n\nGitLab backups include:\n- Database (PostgreSQL)\n- Git repositories\n- Wiki data\n- CI/CD artifacts (if not using object storage)\n- LFS objects (if not using object storage)\n- Container Registry images (if not using object storage)\n\n**Backup restoration** requires GitLab pods to be stopped and the backup file restored using the `gitlab-backup` utility.\n\n### MLflow Database Backup\n\nMLflow experiment metadata is stored in PostgreSQL and should be backed up regularly:\n\n```bash\n# Create MLflow database backup\nkubectl -n mlflow exec -it \u003cpostgresql-pod\u003e -- \\\n  pg_dump -U mlflow -d mlflow \u003e mlflow-backup-$(date +%Y%m%d).sql\n\n# Restore MLflow database\nkubectl -n mlflow exec -i \u003cpostgresql-pod\u003e -- \\\n  psql -U mlflow -d mlflow \u003c mlflow-backup-20240101.sql\n```\n\nMLflow artifacts stored in S3 can be protected using:\n- S3 versioning enabled on the artifacts bucket\n- S3 cross-region replication for disaster recovery\n- S3 lifecycle policies for long-term archival\n\n### SharingHub State Management\n\nSharingHub is stateless and does not require backups. Its STAC catalog is dynamically generated from GitLab projects. However, configuration should be preserved:\n\n```bash\n# Export SharingHub ConfigMap\nkubectl -n sharinghub get configmap sharinghub-config -o yaml \u003e sharinghub-config-backup.yaml\n\n# Export SharingHub Secrets (encrypted)\nkubectl -n sharinghub get secret sharinghub-oidc -o yaml \u003e sharinghub-oidc-backup.yaml\n```\n\nSources: High-level architecture diagrams, [docs/admin/maintenance.md:1-12]()\n\n## Version Management and Upgrades\n\n```mermaid\ngraph TB\n    subgraph \"Version Strategy\"\n        PINNING[\"Version Pinning Strategy\u003cbr/\u003ePin to specific versions\u003cbr/\u003eAvoid 'latest' tags\"]\n        TRACKING[\"Version Tracking\u003cbr/\u003eMonitor upstream releases\u003cbr/\u003eSecurity advisories\"]\n        TESTING[\"Upgrade Testing\u003cbr/\u003eTest in staging environment\u003cbr/\u003eValidate integrations\"]\n    end\n    \n    subgraph \"Component Upgrade Paths\"\n        GITLAB[\"GitLab Upgrade\u003cbr/\u003ehelm values update\u003cbr/\u003eRun migrations\u003cbr/\u003eVerify health checks\"]\n        SHARINGHUB[\"SharingHub Upgrade\u003cbr/\u003eUpdate image tag\u003cbr/\u003eRolling deployment\u003cbr/\u003eCatalog regeneration\"]\n        MLFLOW[\"MLflow Upgrade\u003cbr/\u003eDatabase migrations\u003cbr/\u003eArtifact compatibility\u003cbr/\u003eAPI version check\"]\n    end\n    \n    subgraph \"ArgoCD GitOps Flow\"\n        GITUPDATE[\"Update Helm Chart\u003cbr/\u003evalues.yaml in Git\"]\n        ARGODETECT[\"ArgoCD Detects\u003cbr/\u003eConfiguration Drift\"]\n        ARGOSYNC[\"ArgoCD Sync\u003cbr/\u003eApplies Changes\"]\n        ROLLBACK[\"Rollback Available\u003cbr/\u003eArgoCD history\"]\n    end\n    \n    PINNING --\u003e TRACKING\n    TRACKING --\u003e TESTING\n    TESTING --\u003e GITLAB\n    TESTING --\u003e SHARINGHUB\n    TESTING --\u003e MLFLOW\n    \n    GITLAB --\u003e GITUPDATE\n    SHARINGHUB --\u003e GITUPDATE\n    MLFLOW --\u003e GITUPDATE\n    \n    GITUPDATE --\u003e ARGODETECT\n    ARGODETECT --\u003e ARGOSYNC\n    ARGOSYNC -.if needed.-\u003e ROLLBACK\n```\n\n**Upgrade Workflow**: Version upgrades follow a GitOps pattern managed by ArgoCD. Configuration changes are committed to Git, detected by ArgoCD, and applied to the cluster. Rollbacks are available through ArgoCD's version history.\n\n### Version Pinning Best Practices\n\nThe platform uses Helm charts with image tags that should be pinned to specific versions:\n\n```yaml\n# Example: GitLab version pinning\ngitlab:\n  image:\n    tag: \"16.10.0-ce.0\"  # Specific version, not \"latest\"\n\n# Example: SharingHub version pinning\nsharinghub:\n  image:\n    repository: eoepca/sharinghub\n    tag: \"1.2.0\"  # Specific version\n\n# Example: MLflow version pinning\nmlflow:\n  image:\n    repository: eoepca/mlflow-sharinghub\n    tag: \"2.10.0\"  # Specific version\n```\n\n**Rationale**: Pinning versions provides:\n- Predictable deployments\n- Controlled upgrade timing\n- Easier rollback procedures\n- Reduced risk of breaking changes\n\nHowever, stale versions create security vulnerabilities. Regular upgrade planning is essential.\n\n### Component-Specific Upgrade Considerations\n\n**GitLab Upgrades**:\n- Follow GitLab's upgrade path (cannot skip major versions)\n- Database migrations run automatically during upgrade\n- Check for breaking changes in release notes\n- Backup before upgrading\n- Monitor for [deprecated features](https://docs.gitlab.com/ee/update/deprecations.html)\n\n**SharingHub Upgrades**:\n- Stateless application, upgrades are typically safe\n- Verify STAC API compatibility if clients depend on specific versions\n- Test GitLab API integration after upgrade\n- Catalog regeneration may be needed after schema changes\n\n**MLflow Upgrades**:\n- Database schema migrations may be required\n- Check MLflow client compatibility\n- Verify artifact storage format compatibility\n- Test model registry API if external systems integrate with it\n\nSources: [docs/admin/maintenance.md:1-12]()\n\n## Certificate Management\n\n```mermaid\ngraph LR\n    subgraph \"Certificate Lifecycle\"\n        CREATION[\"Certificate Creation\u003cbr/\u003ecert-manager\u003cbr/\u003eClusterIssuer\"]\n        MONITORING[\"Certificate Monitoring\u003cbr/\u003eCheck expiry dates\u003cbr/\u003ekubectl get certificates\"]\n        RENEWAL[\"Automatic Renewal\u003cbr/\u003ecert-manager renews\u003cbr/\u003e30 days before expiry\"]\n        ALERT[\"Expiry Alerts\u003cbr/\u003eMonitor cert-manager logs\u003cbr/\u003eSet up alerting\"]\n    end\n    \n    subgraph \"Certificate Consumers\"\n        GLTLS[\"GitLab TLS\u003cbr/\u003egitlab.domain-tls\u003cbr/\u003eSecret\"]\n        SHTLS[\"SharingHub TLS\u003cbr/\u003esharinghub.domain-tls\u003cbr/\u003eSecret\"]\n        MLFTLS[\"MLflow TLS\u003cbr/\u003eUses SharingHub cert\u003cbr/\u003eSame domain\"]\n    end\n    \n    CREATION --\u003e MONITORING\n    MONITORING --\u003e RENEWAL\n    RENEWAL --\u003e ALERT\n    \n    CREATION -.creates.-\u003e GLTLS\n    CREATION -.creates.-\u003e SHTLS\n    CREATION -.creates.-\u003e MLFTLS\n    \n    RENEWAL -.updates.-\u003e GLTLS\n    RENEWAL -.updates.-\u003e SHTLS\n    RENEWAL -.updates.-\u003e MLFTLS\n```\n\n**Certificate Management Lifecycle**: cert-manager automates TLS certificate provisioning and renewal using Let's Encrypt. Certificates are stored as Kubernetes Secrets and automatically renewed 30 days before expiration.\n\n### Certificate Operations\n\n**Check certificate status**:\n```bash\n# List all certificates\nkubectl get certificates --all-namespaces\n\n# Check specific certificate details\nkubectl -n gitlab describe certificate gitlab-tls\n\n# View certificate expiry\nkubectl -n gitlab get secret gitlab-tls -o jsonpath='{.data.tls\\.crt}' | \\\n  base64 -d | openssl x509 -noout -enddate\n```\n\n**Manual certificate renewal** (if automatic renewal fails):\n```bash\n# Delete certificate to trigger recreation\nkubectl -n gitlab delete certificate gitlab-tls\n\n# cert-manager will automatically recreate it\nkubectl -n gitlab get certificate gitlab-tls -w\n```\n\n**Troubleshoot certificate issues**:\n```bash\n# Check cert-manager logs\nkubectl -n cert-manager logs -l app=cert-manager\n\n# Check certificate request status\nkubectl -n gitlab get certificaterequest\n\n# Check ACME challenge status\nkubectl -n gitlab get challenge\n```\n\nSources: High-level architecture diagrams, security and authentication architecture\n\n## Troubleshooting Guide\n\n### Common Issues and Resolutions\n\n```mermaid\ngraph TB\n    subgraph \"GitLab Issues\"\n        GL_POD[\"Pod CrashLoopBackOff\u003cbr/\u003eCheck logs for errors\u003cbr/\u003eVerify DB connection\"]\n        GL_DB[\"Database Connection Errors\u003cbr/\u003eCheck PostgreSQL status\u003cbr/\u003eVerify credentials in Secret\"]\n        GL_S3[\"S3 Access Errors\u003cbr/\u003eVerify bucket exists\u003cbr/\u003eCheck IAM permissions\"]\n        GL_OAUTH[\"OIDC Login Failures\u003cbr/\u003eCheck Keycloak connectivity\u003cbr/\u003eVerify client secret\"]\n    end\n    \n    subgraph \"SharingHub Issues\"\n        SH_CATALOG[\"Empty STAC Catalog\u003cbr/\u003eCheck GitLab API access\u003cbr/\u003eVerify topic filtering\"]\n        SH_PERM[\"Permission Denied\u003cbr/\u003eCheck OAuth token\u003cbr/\u003eVerify GitLab project access\"]\n        SH_SLOW[\"Slow Catalog Generation\u003cbr/\u003eEnable Redis cache\u003cbr/\u003eOptimize GitLab queries\"]\n    end\n    \n    subgraph \"MLflow Issues\"\n        MLF_TRACK[\"Experiment Logging Fails\u003cbr/\u003eCheck SharingHub permission API\u003cbr/\u003eVerify project exists in GitLab\"]\n        MLF_ART[\"Artifact Upload Fails\u003cbr/\u003eCheck S3 credentials\u003cbr/\u003eVerify bucket access\"]\n        MLF_DB[\"Database Migration Errors\u003cbr/\u003eCheck PostgreSQL version\u003cbr/\u003eRun migrations manually\"]\n    end\n    \n    subgraph \"Infrastructure Issues\"\n        INGRESS_ERR[\"502/503 Errors\u003cbr/\u003eCheck backend pod status\u003cbr/\u003eVerify service endpoints\"]\n        CERT_ERR[\"Certificate Errors\u003cbr/\u003eCheck cert-manager status\u003cbr/\u003eVerify DNS propagation\"]\n        DNS_ERR[\"DNS Resolution Failures\u003cbr/\u003eCheck ingress hostname\u003cbr/\u003eVerify external DNS\"]\n    end\n```\n\n**Common Troubleshooting Scenarios**: This diagram categorizes typical issues by component and suggests diagnostic steps for resolution.\n\n### GitLab Troubleshooting\n\n**Pod restart loops**:\n```bash\n# Check pod status and events\nkubectl -n gitlab get pods\nkubectl -n gitlab describe pod gitlab-webservice-xxx\n\n# View recent logs\nkubectl -n gitlab logs gitlab-webservice-xxx --tail=100\n\n# Common causes:\n# - Database migration failures\n# - Secret misconfiguration\n# - Resource constraints (OOM)\n# - Health check failures\n```\n\n**Database connection issues**:\n```bash\n# Verify PostgreSQL is running\nkubectl -n gitlab get pods -l app=postgresql\n\n# Test database connection\nkubectl -n gitlab exec -it gitlab-webservice-xxx -- \\\n  gitlab-rake gitlab:db:configure:connection\n\n# Check database credentials\nkubectl -n gitlab get secret gitlab-postgresql-secret -o yaml\n```\n\n**S3 backup failures**:\n```bash\n# Check backup job logs\nkubectl -n gitlab logs job/backup-utility-xxx\n\n# Verify S3 configuration\nkubectl -n gitlab get configmap gitlab-backup-config -o yaml\n\n# Test S3 connectivity\nkubectl -n gitlab exec -it gitlab-webservice-xxx -- \\\n  aws s3 ls s3://your-backup-bucket/ --region us-east-1\n```\n\n### SharingHub Troubleshooting\n\n**STAC catalog not updating**:\n```bash\n# Check SharingHub logs for GitLab API errors\nkubectl -n sharinghub logs -l app=sharinghub\n\n# Verify GitLab API connectivity\nkubectl -n sharinghub exec -it sharinghub-xxx -- \\\n  curl -H \"Authorization: Bearer $TOKEN\" https://gitlab.domain/api/v4/projects\n\n# Check if projects have required topics\n# SharingHub filters projects by topics like \"sharinghub:aimodel\"\n```\n\n**Performance issues with large catalogs**:\n- Enable Redis caching for STAC catalog responses\n- Implement pagination in STAC API queries\n- Optimize GitLab API query filters\n- Consider catalog pre-generation with scheduled jobs\n\n### MLflow SharingHub Troubleshooting\n\n**Permission check failures**:\n```bash\n# Check MLflow logs for SharingHub API errors\nkubectl -n mlflow logs -l app=mlflow-sharinghub\n\n# Verify SharingHub connectivity\nkubectl -n mlflow exec -it mlflow-xxx -- \\\n  curl http://sharinghub.sharinghub:5000/health\n\n# Check SharingHub configuration in MLflow\nkubectl -n mlflow get configmap mlflow-config -o yaml\n```\n\n**Artifact storage failures**:\n```bash\n# Check S3 artifact store configuration\nkubectl -n mlflow logs -l app=mlflow-sharinghub | grep -i s3\n\n# Verify S3 credentials\nkubectl -n mlflow get secret mlflow-s3-secret -o yaml\n\n# Test S3 connectivity from MLflow pod\nkubectl -n mlflow exec -it mlflow-xxx -- \\\n  aws s3 ls s3://mlflow-artifacts/ --region us-east-1\n```\n\n**Database migration issues**:\n```bash\n# Check current database schema version\nkubectl -n mlflow exec -it mlflow-postgresql-xxx -- \\\n  psql -U mlflow -d mlflow -c \"SELECT * FROM alembic_version;\"\n\n# Run migrations manually if needed\nkubectl -n mlflow exec -it mlflow-xxx -- \\\n  mlflow db upgrade \u003cdatabase-uri\u003e\n```\n\nSources: High-level architecture diagrams, deployment architecture\n\n## Resource Management\n\n### Resource Limits and Requests\n\nEach component should have appropriate resource limits configured to prevent resource exhaustion:\n\n| Component | Typical CPU Request | Typical Memory Request | Typical CPU Limit | Typical Memory Limit |\n|-----------|---------------------|------------------------|-------------------|----------------------|\n| GitLab webservice | 200m | 2Gi | 1000m | 4Gi |\n| GitLab sidekiq | 100m | 1Gi | 500m | 2Gi |\n| GitLab PostgreSQL | 200m | 512Mi | 1000m | 2Gi |\n| SharingHub | 100m | 256Mi | 500m | 1Gi |\n| MLflow SharingHub | 100m | 512Mi | 500m | 2Gi |\n| MLflow PostgreSQL | 100m | 256Mi | 500m | 1Gi |\n\n**Monitoring resource usage**:\n```bash\n# Check pod resource usage\nkubectl top pods -n gitlab\nkubectl top pods -n sharinghub\nkubectl top pods -n mlflow\n\n# View resource requests/limits\nkubectl -n gitlab describe pod gitlab-webservice-xxx | grep -A 10 \"Limits:\"\n\n# Check node resource allocation\nkubectl top nodes\n```\n\n### Storage Management\n\n**GitLab storage monitoring**:\n```bash\n# Check PVC usage\nkubectl -n gitlab get pvc\n\n# View detailed storage usage\nkubectl -n gitlab exec -it gitlab-webservice-xxx -- df -h\n\n# GitLab repositories disk usage\nkubectl -n gitlab exec -it gitlab-webservice-xxx -- \\\n  du -sh /var/opt/gitlab/git-data/repositories\n```\n\n**S3 storage monitoring**:\n- Monitor bucket sizes through cloud provider console\n- Set up billing alerts for storage costs\n- Implement lifecycle policies for artifact retention\n- Archive or delete old experiment artifacts\n\n**Database storage growth**:\n```bash\n# Check PostgreSQL database sizes\nkubectl -n gitlab exec -it gitlab-postgresql-xxx -- \\\n  psql -U postgres -c \"SELECT pg_database.datname, pg_size_pretty(pg_database_size(pg_database.datname)) FROM pg_database;\"\n\n# Check table sizes in MLflow database\nkubectl -n mlflow exec -it mlflow-postgresql-xxx -- \\\n  psql -U mlflow -d mlflow -c \"SELECT schemaname, tablename, pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) FROM pg_tables ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC LIMIT 10;\"\n```\n\nSources: Deployment architecture, high-level architecture diagrams\n\n## Log Management\n\n### Centralized Logging\n\n**Access component logs**:\n```bash\n# GitLab logs\nkubectl -n gitlab logs -l app=webservice --tail=100\nkubectl -n gitlab logs -l app=sidekiq --tail=100\n\n# SharingHub logs\nkubectl -n sharinghub logs -l app=sharinghub --tail=100\n\n# MLflow logs\nkubectl -n mlflow logs -l app=mlflow-sharinghub --tail=100\n\n# Stream logs in real-time\nkubectl -n gitlab logs -f gitlab-webservice-xxx\n```\n\n**Log aggregation recommendations**:\n- Deploy Elasticsearch, Fluentd, Kibana (EFK) stack for centralized logging\n- Use Loki with Grafana for lightweight log aggregation\n- Configure log retention policies to manage storage\n- Set up log-based alerts for critical errors\n\n### Important Log Patterns to Monitor\n\n**GitLab critical errors**:\n- Database connection failures: `PG::ConnectionBad`\n- Redis connection issues: `Redis::CannotConnectError`\n- OIDC authentication failures: `OAuth::Unauthorized`\n- Backup failures in backup-utility logs\n\n**SharingHub critical errors**:\n- GitLab API authentication failures: `401 Unauthorized`\n- STAC catalog generation errors\n- OAuth token expiration warnings\n\n**MLflow critical errors**:\n- SharingHub permission check failures\n- S3 artifact upload failures: `botocore.exceptions`\n- Database connection issues: `sqlalchemy.exc.OperationalError`\n- Experiment logging failures\n\nSources: High-level architecture diagrams, component integration and data flow\n\n## Security Operations\n\n### Secret Rotation\n\nKubernetes Secrets should be rotated periodically for security:\n\n```bash\n# List all secrets by namespace\nkubectl -n gitlab get secrets\nkubectl -n sharinghub get secrets\nkubectl -n mlflow get secrets\n\n# Rotate OIDC client secrets (requires Keycloak admin access)\n# 1. Generate new client secret in Keycloak\n# 2. Update Kubernetes Secret\nkubectl -n gitlab edit secret gitlab-oidc\n\n# 3. Restart affected pods\nkubectl -n gitlab rollout restart deployment gitlab-webservice\n```\n\n**Critical secrets to manage**:\n- `gitlab-oidc`: GitLab OIDC client credentials\n- `sharinghub-oidc`: SharingHub OAuth credentials\n- `mlflow-sharinghub`: MLflow secret key\n- Database passwords (PostgreSQL secrets)\n- S3 access credentials\n\n### Security Scanning\n\n**Container image vulnerability scanning**:\n- Scan images before deployment using tools like Trivy or Clair\n- Monitor for CVEs in base images\n- Subscribe to security advisories for GitLab, MLflow, and other components\n\n**Network policy enforcement**:\n```bash\n# View existing network policies\nkubectl -n gitlab get networkpolicies\nkubectl -n sharinghub get networkpolicies\nkubectl -n mlflow get networkpolicies\n\n# Verify pod-to-pod communication rules\n# Ensure only necessary services can communicate\n```\n\n### Access Control Auditing\n\n**GitLab audit events**:\n- Monitor admin access through GitLab UI: Admin Area \u003e Monitoring \u003e Audit Events\n- Review user login patterns\n- Check for unauthorized project access attempts\n\n**Kubernetes RBAC auditing**:\n```bash\n# Review service account permissions\nkubectl -n gitlab get serviceaccounts\nkubectl -n gitlab describe serviceaccount gitlab-webservice\n\n# Check role bindings\nkubectl -n gitlab get rolebindings\nkubectl get clusterrolebindings | grep gitlab\n```\n\nSources: Security and authentication architecture, [docs/admin/maintenance.md:1-12]()\n\n## Disaster Recovery Procedures\n\n### Recovery Time Objectives (RTO) and Recovery Point Objectives (RPO)\n\n| Component | Typical RPO | Typical RTO | Recovery Complexity |\n|-----------|-------------|-------------|---------------------|\n| GitLab | Last backup (daily) | 2-4 hours | High (requires backup restore) |\n| GitLab PostgreSQL | Last backup (daily) | 1-2 hours | Medium |\n| SharingHub | N/A (stateless) | 15 minutes | Low (redeploy pod) |\n| MLflow PostgreSQL | Last backup (daily) | 1 hour | Medium |\n| MLflow S3 Artifacts | Continuous (S3 versioning) | Immediate | Low (S3 native recovery) |\n\n### GitLab Disaster Recovery\n\n**Full GitLab restoration from backup**:\n```bash\n# 1. Stop GitLab pods\nkubectl -n gitlab scale deployment gitlab-webservice --replicas=0\nkubectl -n gitlab scale deployment gitlab-sidekiq --replicas=0\n\n# 2. Download backup from S3\naws s3 cp s3://gitlab-backup-bucket/gitlab-backup-20240101.tar.gz .\n\n# 3. Copy backup to GitLab pod volume\nkubectl -n gitlab cp gitlab-backup-20240101.tar.gz gitlab-toolbox-pod:/var/opt/gitlab/backups/\n\n# 4. Run restore command\nkubectl -n gitlab exec -it gitlab-toolbox-pod -- \\\n  gitlab-backup restore BACKUP=20240101 force=yes\n\n# 5. Reconfigure and restart\nkubectl -n gitlab exec -it gitlab-toolbox-pod -- gitlab-ctl reconfigure\nkubectl -n gitlab scale deployment gitlab-webservice --replicas=2\nkubectl -n gitlab scale deployment gitlab-sidekiq --replicas=1\n\n# 6. Verify restoration\nkubectl -n gitlab exec -it gitlab-webservice-xxx -- \\\n  gitlab-rake gitlab:check\n```\n\n### Database Point-in-Time Recovery\n\n**PostgreSQL PITR** (if continuous archiving is enabled):\n```bash\n# 1. Stop affected service\nkubectl -n mlflow scale deployment mlflow-sharinghub --replicas=0\n\n# 2. Restore PostgreSQL from backup with PITR\nkubectl -n mlflow exec -it mlflow-postgresql-xxx -- \\\n  pg_restore --recovery-target-time=\"2024-01-01 12:00:00\" ...\n\n# 3. Restart service\nkubectl -n mlflow scale deployment mlflow-sharinghub --replicas=1\n```\n\n### S3 Artifact Recovery\n\nIf S3 versioning is enabled:\n```bash\n# List object versions\naws s3api list-object-versions --bucket mlflow-artifacts --prefix \u003cmodel-path\u003e\n\n# Restore previous version\naws s3api get-object \\\n  --bucket mlflow-artifacts \\\n  --key \u003cmodel-path\u003e/model.onnx \\\n  --version-id \u003cversion-id\u003e \\\n  model.onnx.restored\n```\n\nSources: Backup and disaster recovery considerations from deployment architecture, [docs/admin/maintenance.md:1-12]()\n\n## Maintenance Windows and Downtime Management\n\n### Planned Maintenance Procedures\n\nFor maintenance operations requiring downtime:\n\n1. **Schedule maintenance window**: Communicate with users in advance\n2. **Enable maintenance mode** (if supported):\n   ```bash\n   # GitLab maintenance mode\n   kubectl -n gitlab exec -it gitlab-webservice-xxx -- \\\n     gitlab-ctl deploy-page up\n   ```\n3. **Create pre-maintenance backup**\n4. **Perform maintenance operations**\n5. **Verify system health** after maintenance\n6. **Disable maintenance mode**:\n   ```bash\n   kubectl -n gitlab exec -it gitlab-webservice-xxx -- \\\n     gitlab-ctl deploy-page down\n   ```\n\n### Zero-Downtime Updates\n\nFor updates not requiring downtime:\n\n**Rolling updates** (default Kubernetes behavior):\n```bash\n# Update image tag in ArgoCD Git repository\n# ArgoCD will perform rolling update automatically\n\n# Monitor rollout progress\nkubectl -n sharinghub rollout status deployment sharinghub\n\n# Verify no disruption\nkubectl -n sharinghub get pods -w\n```\n\n**Blue-green deployments** (for critical updates):\n- Deploy new version alongside existing version\n- Validate new version functionality\n- Switch traffic using service selector\n- Monitor for issues before removing old version\n\nSources: [docs/admin/maintenance.md:1-12](), deployment architecture\n\n## Performance Tuning\n\n### GitLab Performance Optimization\n\n**Database query optimization**:\n- Monitor slow queries in PostgreSQL logs\n- Enable PostgreSQL query statistics\n- Consider read replicas for heavy read workloads\n\n**Sidekiq job processing**:\n```bash\n# View Sidekiq queue status\nkubectl -n gitlab exec -it gitlab-webservice-xxx -- \\\n  gitlab-rake gitlab:sidekiq:all_queues_size\n\n# Check for stuck jobs\nkubectl -n gitlab exec -it gitlab-webservice-xxx -- \\\n  gitlab-rake gitlab:sidekiq:stuck_jobs\n```\n\n**Redis optimization**:\n- Monitor Redis memory usage\n- Enable Redis persistence for job queue reliability\n- Consider Redis Cluster for horizontal scaling\n\n### SharingHub Performance Optimization\n\n**STAC catalog caching**:\n- Enable Redis cache for catalog responses\n- Configure appropriate cache TTL based on project update frequency\n- Implement cache invalidation on GitLab webhook events\n\n**GitLab API rate limiting**:\n- Monitor GitLab API rate limit headers in SharingHub logs\n- Implement request batching for multiple project queries\n- Use GraphQL API instead of REST where possible for efficiency\n\n### MLflow Performance Optimization\n\n**Database connection pooling**:\n- Configure appropriate connection pool size based on concurrent tracking clients\n- Monitor connection pool utilization\n- Adjust pool timeout settings for long-running operations\n\n**S3 artifact upload optimization**:\n- Enable multipart uploads for large artifacts\n- Configure appropriate part size for network conditions\n- Use S3 Transfer Acceleration for geographically distributed users\n\nSources: Component integration and data flow, high-level architecture diagrams\n\n## Compliance and Auditing\n\n### Audit Logging\n\n**Enable comprehensive audit logging**:\n\nGitLab audit events track:\n- User authentication and authorization events\n- Project access changes\n- Repository operations (push, merge)\n- Admin configuration changes\n\nSharingHub audit considerations:\n- Log STAC API access patterns\n- Track model and dataset download events\n- Monitor OAuth token usage\n\nMLflow audit logging:\n- Experiment creation and modification events\n- Model registration and stage transitions\n- Artifact access patterns\n\n### Data Retention Policies\n\n**Configure retention policies** for:\n\n- **GitLab logs**: Rotate logs older than 30 days\n- **MLflow experiments**: Archive inactive experiments older than 90 days\n- **S3 artifacts**: Apply lifecycle policies to transition old artifacts to glacier storage\n- **Database backups**: Retain daily backups for 30 days, weekly backups for 90 days\n- **Audit logs**: Retain audit logs for compliance period (often 1-7 years depending on requirements)\n\n### Compliance Reporting\n\nGenerate compliance reports:\n```bash\n# GitLab user activity report\nkubectl -n gitlab exec -it gitlab-webservice-xxx -- \\\n  gitlab-rake gitlab:audit:list_users\n\n# Export audit events for compliance review\n# Use GitLab API to fetch audit events programmatically\n```\n\nSources: Security and authentication architecture, user interaction patterns\n\n## Related Documentation\n\nFor additional operational information:\n\n- **Initial deployment**: See [Deployment Guide](#5) for setting up the platform\n- **Detailed maintenance procedures**: See [Maintenance Guidelines](#8.1) for version pinning and upgrade procedures\n- **Configuration changes**: See [Configuration Reference](#6) for detailed configuration options\n- **API operations**: See [API Reference](#7) for programmatic access and automation\n\n---\n\n**Summary**: This Operations and Maintenance guide covers routine operational tasks, monitoring, backup and recovery, troubleshooting, and security operations for the EOEPCA MLOps Building Block. Regular maintenance, proactive monitoring, and adherence to best practices ensure a stable, secure, and performant platform for ML model development and deployment.\n\nSources: [docs/admin/maintenance.md:1-12](), high-level architecture diagrams, deployment architecture, security and authentication architecture"])</script><script>self.__next_f.push([1,"2f:T651d,"])</script><script>self.__next_f.push([1,"# Maintenance Guidelines\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [docs/admin/maintenance.md](docs/admin/maintenance.md)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis document provides best practices and procedures for maintaining the MLOps Building Block in production environments. It covers version management strategies, component upgrade procedures, dependency management, backup strategies, and security patching workflows to ensure system stability and security.\n\nFor deployment instructions, see [Deployment Guide](#5). For troubleshooting procedures, consult the Operations and Maintenance section [#8](#8). For configuration options during upgrades, see [Configuration Reference](#6).\n\n**Sources:** [docs/admin/maintenance.md:1-12]()\n\n---\n\n## Version Management Strategy\n\n### Version Pinning Philosophy\n\nThe MLOps Building Block consists of three main components that evolve independently: GitLab, SharingHub, and MLflow SharingHub. Each component should have its version explicitly pinned to ensure predictable behavior and controlled upgrades.\n\n```mermaid\ngraph TB\n    subgraph \"Version Management Strategy\"\n        AVOID[\"Avoid 'latest' tag\"]\n        PIN[\"Pin to specific versions\"]\n        MONITOR[\"Monitor upstream releases\"]\n        UPDATE[\"Schedule regular updates\"]\n    end\n    \n    subgraph \"GitLab Component\"\n        GLCHART[\"Helm Chart: gitlab/gitlab\"]\n        GLVERSION[\"Chart Version: 7.x.x\"]\n        GLIMAGE[\"Image Tag: 16.x.x-ce.0\"]\n    end\n    \n    subgraph \"SharingHub Component\"\n        SHCHART[\"Helm Chart: csgroup-oss/sharinghub\"]\n        SHVERSION[\"Chart Version: 1.x.x\"]\n        SHIMAGE[\"Image Tag: specific SHA or semver\"]\n    end\n    \n    subgraph \"MLflow SharingHub Component\"\n        MLFCHART[\"Helm Chart: csgroup-oss/mlflow-sharinghub\"]\n        MLFVERSION[\"Chart Version: 1.x.x\"]\n        MLFIMAGE[\"Image Tag: specific SHA or semver\"]\n    end\n    \n    AVOID --\u003e PIN\n    PIN --\u003e MONITOR\n    MONITOR --\u003e UPDATE\n    \n    UPDATE --\u003e GLCHART\n    UPDATE --\u003e SHCHART\n    UPDATE --\u003e MLFCHART\n    \n    GLCHART --\u003e GLVERSION\n    GLVERSION --\u003e GLIMAGE\n    \n    SHCHART --\u003e SHVERSION\n    SHVERSION --\u003e SHIMAGE\n    \n    MLFCHART --\u003e MLFVERSION\n    MLFVERSION --\u003e MLFIMAGE\n```\n\n**Version Pinning Best Practices:**\n\n| Practice | Rationale | Implementation |\n|----------|-----------|----------------|\n| **Avoid `latest` tags** | Unpredictable behavior, unreproducible deployments | Specify exact chart versions and image tags in ArgoCD Applications |\n| **Pin Helm chart versions** | Control when breaking changes are introduced | Use `targetRevision: x.y.z` in ArgoCD Application specs |\n| **Pin container image tags** | Ensure consistent image behavior across pods | Use `image.tag: x.y.z` in Helm values files |\n| **Document version matrix** | Track compatible versions across components | Maintain a compatibility matrix in deployment documentation |\n| **Regular updates (not stale)** | Security patches, dependency freshness | Schedule quarterly upgrade reviews |\n\n**Sources:** [docs/admin/maintenance.md:3-11]()\n\n---\n\n## Component Upgrade Procedures\n\n### GitLab Upgrades\n\nGitLab follows a strict upgrade path and may require sequential upgrades rather than skipping versions. Always consult the official GitLab upgrade path documentation before upgrading.\n\n```mermaid\nsequenceDiagram\n    participant Operator\n    participant ArgoCD\n    participant GitLabChart\n    participant GitLabPods\n    participant PostgreSQL\n    participant S3\n    \n    Operator-\u003e\u003eOperator: Check GitLab upgrade path\n    Operator-\u003e\u003eOperator: Review release notes for breaking changes\n    Operator-\u003e\u003eOperator: Create backup of PostgreSQL\n    Operator-\u003e\u003eS3: Verify backup availability\n    \n    Operator-\u003e\u003eArgoCD: Update targetRevision in Application\n    ArgoCD-\u003e\u003eGitLabChart: Sync new chart version\n    GitLabChart-\u003e\u003eGitLabPods: Update deployment\n    \n    GitLabPods-\u003e\u003ePostgreSQL: Run migrations\n    \n    alt Migration succeeds\n        GitLabPods-\u003e\u003eGitLabPods: Start new version\n        GitLabPods-\u003e\u003eOperator: Ready\n    else Migration fails\n        Operator-\u003e\u003eArgoCD: Rollback to previous version\n        ArgoCD-\u003e\u003eGitLabChart: Restore previous chart\n    end\n    \n    Operator-\u003e\u003eGitLabPods: Verify health checks\n    Operator-\u003e\u003eOperator: Test critical functionality\n```\n\n**GitLab Upgrade Checklist:**\n\n1. **Pre-upgrade:**\n   - Review GitLab upgrade path: https://docs.gitlab.com/ee/update/index.html\n   - Check for required intermediate versions\n   - Review breaking changes in release notes\n   - Backup PostgreSQL database (gitlab namespace)\n   - Verify S3 backup retention policy\n   - Document current versions of all sub-components\n\n2. **Upgrade execution:**\n   - Update `targetRevision` in ArgoCD Application for gitlab namespace\n   - Monitor ArgoCD sync status\n   - Watch pod rollout: `kubectl get pods -n gitlab -w`\n   - Check migration logs: `kubectl logs -n gitlab -l app=migrations`\n\n3. **Post-upgrade:**\n   - Verify GitLab web UI accessibility\n   - Test OAuth/OIDC authentication flow with Keycloak\n   - Verify GitLab Runner functionality if configured\n   - Test Git operations (clone, push, pull)\n   - Confirm webhook delivery to SharingHub\n   - Check sidekiq job processing: `kubectl logs -n gitlab -l app=sidekiq`\n\n**Sources:** [docs/admin/maintenance.md:3-11]()\n\n---\n\n### SharingHub Upgrades\n\nSharingHub upgrades are generally straightforward but require attention to STAC catalog schema changes and GitLab API compatibility.\n\n```mermaid\ngraph TB\n    subgraph \"Pre-Upgrade\"\n        CHECK_SCHEMA[\"Check STAC schema changes\"]\n        CHECK_GITLAB[\"Verify GitLab API compatibility\"]\n        BACKUP_CONFIG[\"Backup Helm values\"]\n    end\n    \n    subgraph \"Upgrade\"\n        UPDATE_CHART[\"Update chart version in ArgoCD\"]\n        SYNC[\"ArgoCD syncs new chart\"]\n        DEPLOY[\"New pod deployment\"]\n    end\n    \n    subgraph \"Post-Upgrade\"\n        VERIFY_API[\"Test STAC API endpoints\"]\n        VERIFY_CATALOG[\"Verify catalog regeneration\"]\n        CHECK_LINKS[\"Test MLflow integration\"]\n    end\n    \n    CHECK_SCHEMA --\u003e CHECK_GITLAB\n    CHECK_GITLAB --\u003e BACKUP_CONFIG\n    BACKUP_CONFIG --\u003e UPDATE_CHART\n    UPDATE_CHART --\u003e SYNC\n    SYNC --\u003e DEPLOY\n    DEPLOY --\u003e VERIFY_API\n    VERIFY_API --\u003e VERIFY_CATALOG\n    VERIFY_CATALOG --\u003e CHECK_LINKS\n```\n\n**SharingHub Upgrade Checklist:**\n\n1. **Pre-upgrade:**\n   - Review SharingHub release notes for API changes\n   - Check STAC extensions compatibility (ml-model, eo)\n   - Backup current Helm values: `helm get values -n sharinghub sharinghub \u003e sharinghub-values-backup.yaml`\n   - Verify GitLab webhook configuration remains compatible\n\n2. **Upgrade execution:**\n   - Update chart version in ArgoCD Application for sharinghub namespace\n   - Monitor pod startup: `kubectl logs -n sharinghub -l app=sharinghub -f`\n   - Wait for catalog regeneration to complete\n\n3. **Post-upgrade:**\n   - Test STAC API root: `curl https://sharinghub.domain/api/catalog/`\n   - Verify collections are populated: `curl https://sharinghub.domain/api/catalog/collections`\n   - Test item retrieval for each category (aimodel, dataset, processor)\n   - Verify OAuth flow with GitLab\n   - Confirm S3 asset links are accessible\n   - Test MLflow permission check integration\n\n**Sources:** [docs/admin/maintenance.md:3-11]()\n\n---\n\n### MLflow SharingHub Upgrades\n\nMLflow SharingHub upgrades require coordination between MLflow core version, PostgreSQL schema, and SharingHub API integration.\n\n```mermaid\ngraph LR\n    subgraph \"Dependencies\"\n        MLFLOW_CORE[\"MLflow Core Version\"]\n        POSTGRES_SCHEMA[\"PostgreSQL Schema\"]\n        SHARINGHUB_API[\"SharingHub Permission API\"]\n    end\n    \n    subgraph \"Upgrade Process\"\n        BACKUP_DB[\"Backup PostgreSQL\"]\n        UPDATE_CHART[\"Update Helm chart\"]\n        RUN_MIGRATION[\"Run DB migrations\"]\n        TEST_TRACKING[\"Test tracking API\"]\n        TEST_REGISTRY[\"Test model registry\"]\n        TEST_PERMS[\"Test permission checks\"]\n    end\n    \n    MLFLOW_CORE --\u003e BACKUP_DB\n    POSTGRES_SCHEMA --\u003e BACKUP_DB\n    SHARINGHUB_API --\u003e BACKUP_DB\n    \n    BACKUP_DB --\u003e UPDATE_CHART\n    UPDATE_CHART --\u003e RUN_MIGRATION\n    RUN_MIGRATION --\u003e TEST_TRACKING\n    TEST_TRACKING --\u003e TEST_REGISTRY\n    TEST_REGISTRY --\u003e TEST_PERMS\n```\n\n**MLflow SharingHub Upgrade Checklist:**\n\n1. **Pre-upgrade:**\n   - Check MLflow core version compatibility with MLflow SharingHub fork\n   - Backup PostgreSQL database (mlflow namespace)\n   - Review MLflow database migration scripts\n   - Test SharingHub permission API availability\n   - Document registered models for post-upgrade verification\n\n2. **Upgrade execution:**\n   - Update chart version in ArgoCD Application for mlflow namespace\n   - Monitor database migration: `kubectl logs -n mlflow -l app=mlflow-sharinghub`\n   - Wait for pod to reach Ready state\n   - Verify artifacts storage connectivity to S3\n\n3. **Post-upgrade:**\n   - Test MLflow Tracking API: `mlflow runs list --experiment-id 0`\n   - Verify model registry access: `mlflow models list`\n   - Test experiment logging with client\n   - Confirm permission check integration with SharingHub\n   - Verify STAC auto-linking for newly registered models\n   - Test artifact download from S3 backend\n\n**Sources:** [docs/admin/maintenance.md:3-11]()\n\n---\n\n## Dependency Management\n\n### External Service Dependencies\n\nThe MLOps Building Block relies on several external services that must be maintained independently:\n\n```mermaid\ngraph TB\n    subgraph \"Core Components\"\n        GITLAB[\"GitLab\"]\n        SHARINGHUB[\"SharingHub\"]\n        MLFLOW[\"MLflow SharingHub\"]\n    end\n    \n    subgraph \"Infrastructure Dependencies\"\n        POSTGRES_GL[\"PostgreSQL for GitLab\"]\n        POSTGRES_MLF[\"PostgreSQL for MLflow\"]\n        REDIS[\"Redis for GitLab\"]\n        S3[\"S3 Object Storage\"]\n    end\n    \n    subgraph \"Platform Services\"\n        KEYCLOAK[\"Keycloak Identity Provider\"]\n        CERTMGR[\"cert-manager\"]\n        NGINX[\"NGINX Ingress Controller\"]\n        ARGOCD[\"ArgoCD\"]\n    end\n    \n    GITLAB --\u003e POSTGRES_GL\n    GITLAB --\u003e REDIS\n    GITLAB --\u003e S3\n    GITLAB --\u003e KEYCLOAK\n    \n    MLFLOW --\u003e POSTGRES_MLF\n    MLFLOW --\u003e S3\n    \n    SHARINGHUB --\u003e GITLAB\n    SHARINGHUB --\u003e S3\n    \n    MLFLOW --\u003e SHARINGHUB\n    \n    GITLAB --\u003e CERTMGR\n    SHARINGHUB --\u003e CERTMGR\n    MLFLOW --\u003e CERTMGR\n    \n    GITLAB --\u003e NGINX\n    SHARINGHUB --\u003e NGINX\n    MLFLOW --\u003e NGINX\n    \n    ARGOCD --\u003e GITLAB\n    ARGOCD --\u003e SHARINGHUB\n    ARGOCD --\u003e MLFLOW\n```\n\n**Dependency Update Strategy:**\n\n| Dependency | Update Frequency | Update Strategy | Compatibility Check |\n|------------|-----------------|-----------------|---------------------|\n| **PostgreSQL** | Quarterly | In-place upgrade with backup | Test with representative data |\n| **Redis** | Semi-annually | Rolling update | Monitor GitLab sidekiq jobs |\n| **S3 Provider** | As needed | Provider-managed | Verify API compatibility |\n| **Keycloak** | Quarterly | Following EOEPCA guidelines | Test OIDC flows |\n| **cert-manager** | Monthly | Helm upgrade | Verify certificate renewal |\n| **NGINX Ingress** | Quarterly | Helm upgrade | Test routing rules |\n| **ArgoCD** | Quarterly | Helm upgrade | Verify GitOps sync |\n\n**Sources:** [docs/admin/maintenance.md:3-11]()\n\n---\n\n## Backup and Recovery\n\n### Backup Strategy\n\nA comprehensive backup strategy ensures data resilience across all components:\n\n```mermaid\ngraph TB\n    subgraph \"GitLab Backup\"\n        GL_PG[\"PostgreSQL Database\u003cbr/\u003eRepositories metadata, users, issues\"]\n        GL_REDIS[\"Redis\u003cbr/\u003eSession data, cache\"]\n        GL_FILES[\"File Storage\u003cbr/\u003eRepositories, LFS, artifacts\"]\n        GL_SECRETS[\"Kubernetes Secrets\u003cbr/\u003eOIDC credentials, certificates\"]\n    end\n    \n    subgraph \"MLflow Backup\"\n        MLF_PG[\"PostgreSQL Database\u003cbr/\u003eExperiments, runs, models metadata\"]\n        MLF_S3[\"S3 Artifacts\u003cbr/\u003eModel binaries, metrics, plots\"]\n    end\n    \n    subgraph \"SharingHub Backup\"\n        SH_CONFIG[\"Configuration\u003cbr/\u003eHelm values, categories, tags\"]\n        SH_SECRETS[\"Kubernetes Secrets\u003cbr/\u003eOAuth tokens\"]\n    end\n    \n    subgraph \"Backup Storage\"\n        S3_BACKUP[\"S3 Backup Bucket\"]\n        VELERO[\"Velero Snapshots\u003cbr/\u003eOptional Kubernetes backup\"]\n    end\n    \n    GL_PG --\u003e S3_BACKUP\n    GL_FILES --\u003e S3_BACKUP\n    MLF_PG --\u003e S3_BACKUP\n    MLF_S3 --\u003e S3_BACKUP\n    SH_CONFIG --\u003e S3_BACKUP\n    \n    GL_SECRETS --\u003e VELERO\n    SH_SECRETS --\u003e VELERO\n```\n\n**Backup Procedures by Component:**\n\n### GitLab Backup\n\nGitLab requires comprehensive backup of multiple data stores:\n\n| Data Store | Backup Method | Frequency | Retention |\n|------------|---------------|-----------|-----------|\n| PostgreSQL | `pg_dump` or GitLab backup utility | Daily | 30 days |\n| Git repositories | Included in GitLab backup task | Daily | 30 days |\n| LFS objects | S3 native backup or GitLab task | Daily | 30 days |\n| Container registry | Registry storage backup | Weekly | 14 days |\n| CI/CD artifacts | S3 native backup | Weekly | 14 days |\n| Secrets | Sealed Secrets or Velero | Before upgrades | Indefinite |\n\n**GitLab Backup Command:**\n```bash\n# Trigger GitLab backup task\nkubectl exec -n gitlab deployment/gitlab-toolbox -- backup-utility --skip registry\n\n# Verify backup in S3\naws s3 ls s3://gitlab-backups-bucket/\n```\n\n### MLflow PostgreSQL Backup\n\n```bash\n# Create PostgreSQL backup\nkubectl exec -n mlflow postgresql-0 -- pg_dump -U mlflow mlflow \u003e mlflow-backup-$(date +%Y%m%d).sql\n\n# Upload to S3\naws s3 cp mlflow-backup-$(date +%Y%m%d).sql s3://mlflow-backups-bucket/\n```\n\n### Configuration Backup\n\n```bash\n# Export Helm values for all components\nhelm get values -n gitlab gitlab \u003e gitlab-values-backup.yaml\nhelm get values -n sharinghub sharinghub \u003e sharinghub-values-backup.yaml\nhelm get values -n mlflow mlflow-sharinghub \u003e mlflow-values-backup.yaml\n\n# Backup Kubernetes secrets\nkubectl get secret -n gitlab gitlab-oidc -o yaml \u003e gitlab-oidc-secret-backup.yaml\nkubectl get secret -n sharinghub sharinghub-oidc -o yaml \u003e sharinghub-oidc-secret-backup.yaml\n```\n\n**Sources:** [docs/admin/maintenance.md:3-11]()\n\n---\n\n## Security Patching\n\n### CVE Monitoring and Response\n\nSecurity vulnerabilities must be addressed promptly to maintain system integrity:\n\n```mermaid\ngraph TB\n    subgraph \"Monitoring\"\n        CVE_SCAN[\"Container Image Scanning\u003cbr/\u003eTrivy, Grype\"]\n        DEP_SCAN[\"Dependency Scanning\u003cbr/\u003eDependabot, Renovate\"]\n        VENDOR_ALERT[\"Vendor Security Advisories\u003cbr/\u003eGitLab, MLflow\"]\n    end\n    \n    subgraph \"Assessment\"\n        SEVERITY[\"Assess Severity\u003cbr/\u003eCritical, High, Medium, Low\"]\n        IMPACT[\"Determine Impact\u003cbr/\u003eAffected components\"]\n        EXPLOIT[\"Check Exploitability\u003cbr/\u003ePublic exploits available\"]\n    end\n    \n    subgraph \"Response\"\n        CRITICAL_PATH[\"Critical: Immediate patch\u003cbr/\u003ewithin 24 hours\"]\n        HIGH_PATH[\"High: Patch within 7 days\"]\n        MEDIUM_PATH[\"Medium: Next scheduled update\"]\n    end\n    \n    subgraph \"Testing\"\n        DEV_TEST[\"Test in development\"]\n        STAGE_TEST[\"Test in staging\"]\n        PROD_DEPLOY[\"Deploy to production\"]\n    end\n    \n    CVE_SCAN --\u003e SEVERITY\n    DEP_SCAN --\u003e SEVERITY\n    VENDOR_ALERT --\u003e SEVERITY\n    \n    SEVERITY --\u003e IMPACT\n    IMPACT --\u003e EXPLOIT\n    \n    EXPLOIT --\u003e CRITICAL_PATH\n    EXPLOIT --\u003e HIGH_PATH\n    EXPLOIT --\u003e MEDIUM_PATH\n    \n    CRITICAL_PATH --\u003e DEV_TEST\n    HIGH_PATH --\u003e DEV_TEST\n    MEDIUM_PATH --\u003e DEV_TEST\n    \n    DEV_TEST --\u003e STAGE_TEST\n    STAGE_TEST --\u003e PROD_DEPLOY\n```\n\n**Security Update Response Times:**\n\n| Severity | Response Time | Update Strategy | Testing Required |\n|----------|---------------|-----------------|------------------|\n| **Critical** | 24 hours | Emergency patch, may skip staging | Minimal smoke tests |\n| **High** | 7 days | Scheduled patch with full testing | Full regression suite |\n| **Medium** | 30 days | Include in next planned update | Standard testing |\n| **Low** | 90 days | Include in quarterly maintenance | Standard testing |\n\n**Security Patching Workflow:**\n\n1. **Identify vulnerabilities:**\n   - Scan container images: `trivy image \u003cimage-name\u003e:\u003ctag\u003e`\n   - Review vendor security advisories\n   - Monitor GitLab security releases: https://about.gitlab.com/releases/categories/releases/\n   - Check MLflow security announcements\n\n2. **Assess and prioritize:**\n   - Determine if vulnerability affects running components\n   - Check if exploit code is publicly available\n   - Evaluate potential business impact\n   - Assign severity level\n\n3. **Apply patches:**\n   - For container images: Update to patched version\n   - For dependencies: Update Helm chart versions\n   - For GitLab: Follow emergency update procedure if critical\n   - For SharingHub/MLflow: Coordinate with upstream maintainers\n\n4. **Verify patches:**\n   - Re-scan images after update\n   - Verify vulnerability no longer present\n   - Test affected functionality\n   - Document remediation\n\n**Sources:** [docs/admin/maintenance.md:8-11]()\n\n---\n\n## Health Monitoring\n\n### Component Health Checks\n\nImplement continuous health monitoring to detect issues early:\n\n| Component | Health Check | Endpoint/Command | Expected Result |\n|-----------|--------------|------------------|-----------------|\n| **GitLab** | HTTP readiness probe | `GET https://gitlab.domain/-/health` | 200 OK |\n| **GitLab** | PostgreSQL connectivity | `kubectl exec -n gitlab gitlab-postgresql-0 -- pg_isready` | accepting connections |\n| **SharingHub** | STAC API availability | `GET https://sharinghub.domain/api/catalog/` | Valid STAC catalog JSON |\n| **MLflow** | Tracking API | `GET https://sharinghub.domain/mlflow/api/2.0/mlflow/experiments/list` | Valid experiments list |\n| **MLflow** | PostgreSQL connectivity | `kubectl exec -n mlflow postgresql-0 -- pg_isready` | accepting connections |\n| **cert-manager** | Certificate status | `kubectl get certificates -A` | Ready=True |\n| **Ingress** | Ingress controller | `kubectl get pods -n ingress-nginx` | Running |\n\n**Monitoring Stack Integration:**\n\n```mermaid\ngraph LR\n    subgraph \"Data Sources\"\n        GITLAB_METRICS[\"GitLab /metrics\u003cbr/\u003ePrometheus format\"]\n        MLFLOW_LOGS[\"MLflow application logs\"]\n        SH_LOGS[\"SharingHub logs\"]\n        K8S_METRICS[\"Kubernetes metrics\"]\n    end\n    \n    subgraph \"Monitoring Stack\"\n        PROMETHEUS[\"Prometheus\u003cbr/\u003eMetrics collection\"]\n        LOKI[\"Loki\u003cbr/\u003eLog aggregation\"]\n        GRAFANA[\"Grafana\u003cbr/\u003eVisualization\"]\n    end\n    \n    subgraph \"Alerting\"\n        ALERT_RULES[\"Alert Rules\u003cbr/\u003eThresholds \u0026 conditions\"]\n        ALERT_MGR[\"Alertmanager\u003cbr/\u003eNotification routing\"]\n        ONCALL[\"On-call Engineers\"]\n    end\n    \n    GITLAB_METRICS --\u003e PROMETHEUS\n    K8S_METRICS --\u003e PROMETHEUS\n    MLFLOW_LOGS --\u003e LOKI\n    SH_LOGS --\u003e LOKI\n    \n    PROMETHEUS --\u003e GRAFANA\n    LOKI --\u003e GRAFANA\n    \n    PROMETHEUS --\u003e ALERT_RULES\n    ALERT_RULES --\u003e ALERT_MGR\n    ALERT_MGR --\u003e ONCALL\n```\n\n**Key Metrics to Monitor:**\n\n- **GitLab:**\n  - Request rate and latency\n  - Git operation duration\n  - Sidekiq queue depth\n  - PostgreSQL connection pool utilization\n  - Redis memory usage\n\n- **SharingHub:**\n  - STAC API request rate\n  - Catalog regeneration time\n  - GitLab API call rate and errors\n  - OAuth token refresh success rate\n\n- **MLflow SharingHub:**\n  - Experiment logging rate\n  - Model registry operations\n  - Artifact upload/download throughput\n  - PostgreSQL query performance\n  - S3 API latency\n\n**Sources:** [docs/admin/maintenance.md:3-11]()\n\n---\n\n## Configuration Management\n\n### GitOps with ArgoCD\n\nArgoCD maintains desired state and prevents configuration drift:\n\n```mermaid\ngraph TB\n    subgraph \"Git Repository\"\n        MANIFESTS[\"ArgoCD Application Manifests\"]\n        VALUES[\"Helm Values Files\"]\n        SECRETS[\"Sealed Secrets\"]\n    end\n    \n    subgraph \"ArgoCD Control Loop\"\n        COMPARE[\"Compare Desired vs Actual State\"]\n        DETECT_DRIFT[\"Detect Configuration Drift\"]\n        SYNC[\"Auto-sync or Manual Sync\"]\n    end\n    \n    subgraph \"Kubernetes Cluster\"\n        GITLAB_NS[\"gitlab namespace\"]\n        SH_NS[\"sharinghub namespace\"]\n        MLF_NS[\"mlflow namespace\"]\n    end\n    \n    MANIFESTS --\u003e COMPARE\n    VALUES --\u003e COMPARE\n    SECRETS --\u003e COMPARE\n    \n    COMPARE --\u003e DETECT_DRIFT\n    DETECT_DRIFT --\u003e|Drift detected| SYNC\n    SYNC --\u003e GITLAB_NS\n    SYNC --\u003e SH_NS\n    SYNC --\u003e MLF_NS\n    \n    GITLAB_NS -.reports actual state.-\u003e COMPARE\n    SH_NS -.reports actual state.-\u003e COMPARE\n    MLF_NS -.reports actual state.-\u003e COMPARE\n```\n\n**Configuration Drift Prevention:**\n\n1. **Enable ArgoCD auto-sync:**\n   - Configure Applications with `syncPolicy.automated.prune: true`\n   - Set `syncPolicy.automated.selfHeal: true` for automatic drift correction\n   - Use `syncPolicy.retry` for transient failures\n\n2. **Restrict manual changes:**\n   - Enforce that all changes go through Git\n   - Monitor for out-of-band kubectl modifications\n   - Alert on manual changes to managed resources\n\n3. **Secret rotation:**\n   - Use Sealed Secrets or External Secrets Operator\n   - Rotate OAuth client secrets quarterly\n   - Update database passwords annually\n   - Refresh TLS certificates automatically via cert-manager\n\n4. **Version control:**\n   - Tag releases in Git repository\n   - Maintain separate branches for environments (dev, staging, prod)\n   - Require pull request reviews for production changes\n\n**ArgoCD Application Structure:**\n\n```\nargocd-apps/\n gitlab-application.yaml          # ArgoCD Application for GitLab\n sharinghub-application.yaml      # ArgoCD Application for SharingHub\n mlflow-application.yaml          # ArgoCD Application for MLflow\n values/\n     gitlab-values.yaml           # GitLab Helm values\n     sharinghub-values.yaml       # SharingHub Helm values\n     mlflow-values.yaml           # MLflow Helm values\n```\n\n**Example ArgoCD Application with version pinning:**\n\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: sharinghub\n  namespace: argocd\nspec:\n  project: mlops\n  source:\n    repoURL: https://csgroup-oss.github.io/helm-charts\n    chart: sharinghub\n    targetRevision: 1.2.3  # Pinned version\n    helm:\n      valueFiles:\n        - values/sharinghub-values.yaml\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: sharinghub\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n    syncOptions:\n      - CreateNamespace=true\n```\n\n**Sources:** [docs/admin/maintenance.md:3-11]()\n\n---\n\n## Upgrade Testing Procedure\n\nBefore applying upgrades to production, follow this comprehensive testing workflow:\n\n```mermaid\ngraph TB\n    subgraph \"Development Environment\"\n        DEV_DEPLOY[\"Deploy upgrade to dev\"]\n        DEV_TEST[\"Run automated tests\"]\n        DEV_VERIFY[\"Manual verification\"]\n    end\n    \n    subgraph \"Staging Environment\"\n        STAGE_DEPLOY[\"Deploy to staging\"]\n        STAGE_LOAD[\"Load testing\"]\n        STAGE_INTEGRATION[\"Integration testing\"]\n        STAGE_SIGN_OFF[\"Stakeholder sign-off\"]\n    end\n    \n    subgraph \"Production Environment\"\n        PROD_BACKUP[\"Create backups\"]\n        PROD_DEPLOY[\"Deploy to production\"]\n        PROD_MONITOR[\"Monitor metrics\"]\n        PROD_VERIFY[\"Smoke tests\"]\n    end\n    \n    subgraph \"Rollback Decision\"\n        SUCCESS[\"Upgrade successful\"]\n        ROLLBACK[\"Rollback required\"]\n    end\n    \n    DEV_DEPLOY --\u003e DEV_TEST\n    DEV_TEST --\u003e DEV_VERIFY\n    DEV_VERIFY --\u003e STAGE_DEPLOY\n    \n    STAGE_DEPLOY --\u003e STAGE_LOAD\n    STAGE_LOAD --\u003e STAGE_INTEGRATION\n    STAGE_INTEGRATION --\u003e STAGE_SIGN_OFF\n    \n    STAGE_SIGN_OFF --\u003e PROD_BACKUP\n    PROD_BACKUP --\u003e PROD_DEPLOY\n    PROD_DEPLOY --\u003e PROD_MONITOR\n    PROD_MONITOR --\u003e PROD_VERIFY\n    \n    PROD_VERIFY --\u003e SUCCESS\n    PROD_VERIFY --\u003e ROLLBACK\n    \n    ROLLBACK --\u003e PROD_BACKUP\n```\n\n**Testing Checklist:**\n\n### Development Environment Tests\n\n- [ ] GitLab web UI accessible\n- [ ] User authentication via Keycloak OIDC\n- [ ] Git operations (clone, push, pull)\n- [ ] Project creation and topic management\n- [ ] SharingHub STAC catalog generation\n- [ ] MLflow experiment tracking\n- [ ] Model registration and STAC linking\n- [ ] S3 artifact storage and retrieval\n\n### Staging Environment Tests\n\n- [ ] Load testing with realistic data volumes\n- [ ] Concurrent user simulation\n- [ ] End-to-end workflow testing (project  train  register  discover)\n- [ ] API performance benchmarks\n- [ ] Database migration validation\n- [ ] Backup and restore procedure\n- [ ] Security scan (vulnerability assessment)\n\n### Production Deployment\n\n- [ ] Maintenance window scheduled and communicated\n- [ ] All backups completed and verified\n- [ ] Rollback procedure documented and ready\n- [ ] Monitoring dashboards prepared\n- [ ] On-call engineers available\n- [ ] Execute deployment during off-peak hours\n\n### Post-Deployment Verification\n\n- [ ] All pods running and ready\n- [ ] Health check endpoints responding\n- [ ] Critical user journeys functional\n- [ ] No increase in error rates\n- [ ] Response times within acceptable range\n- [ ] No alerts triggered\n\n**Sources:** [docs/admin/maintenance.md:3-11]()\n\n---\n\n## Summary\n\nMaintaining the MLOps Building Block requires a disciplined approach to version management, regular upgrades, comprehensive backups, and security vigilance. Key takeaways:\n\n1. **Always pin versions** - Avoid `latest` tags but keep components reasonably up-to-date\n2. **Plan upgrades carefully** - Test in non-production environments first\n3. **Maintain comprehensive backups** - Especially PostgreSQL databases and configuration\n4. **Prioritize security patches** - Respond to critical vulnerabilities within 24 hours\n5. **Monitor continuously** - Use health checks and metrics to detect issues early\n6. **Use GitOps** - Let ArgoCD prevent configuration drift and maintain desired state\n\nRegular maintenance ensures the MLOps platform remains secure, stable, and capable of supporting your organization's machine learning workflows.\n\n**Sources:** [docs/admin/maintenance.md:1-12]()"])</script><script>self.__next_f.push([1,"30:T37c6,"])</script><script>self.__next_f.push([1,"# Documentation System\n\n\u003cdetails\u003e\n\u003csummary\u003eRelevant source files\u003c/summary\u003e\n\nThe following files were used as context for generating this wiki page:\n\n- [.gitignore](.gitignore)\n- [.readthedocs.yaml](.readthedocs.yaml)\n- [docs/design/scenarios/flood-example.md](docs/design/scenarios/flood-example.md)\n- [docs/design/scenarios/model-training.md](docs/design/scenarios/model-training.md)\n- [mkdocs.yml](mkdocs.yml)\n- [requirements.txt](requirements.txt)\n\n\u003c/details\u003e\n\n\n\n## Purpose and Scope\n\nThis page describes the documentation build system used for the EOEPCA MLOps Building Block. It covers the MkDocs-based documentation infrastructure, configuration, theme customization, plugin ecosystem, and deployment to ReadTheDocs. \n\nFor information about the actual MLOps platform architecture and components, see [Architecture](#2). For deployment procedures, see [Deployment Guide](#5).\n\n---\n\n## Documentation Build Architecture\n\nThe documentation system uses **MkDocs** with the **Material for MkDocs** theme to generate static HTML documentation from Markdown source files. The documentation is hosted on **ReadTheDocs** and automatically built on each commit to the repository.\n\n```mermaid\ngraph TB\n    subgraph \"Source Files\"\n        MD[\"Markdown Files\u003cbr/\u003edocs/**/*.md\"]\n        CONFIG[\"mkdocs.yml\u003cbr/\u003eConfiguration\"]\n        CSS[\"css/eoepca.css\u003cbr/\u003eCustom Styles\"]\n        IMG[\"img/\u003cbr/\u003eStatic Assets\"]\n    end\n    \n    subgraph \"Build System\"\n        MKDOCS[\"MkDocs 1.6.1\u003cbr/\u003eStatic Site Generator\"]\n        THEME[\"Material Theme 9.6.8\u003cbr/\u003eUI Framework\"]\n        PLUGINS[\"MkDocs Plugins\"]\n        EXTS[\"Markdown Extensions\"]\n    end\n    \n    subgraph \"Python Dependencies\"\n        REQ[\"requirements.txt\"]\n        AUTOREFS[\"mkdocs-autorefs 1.4.1\"]\n        GLIGHTBOX[\"mkdocs-glightbox 0.4.0\"]\n        SWAGGER[\"mkdocs-swagger-ui-tag 0.6.11\"]\n        PUBLISHER[\"mkdocs-publisher 1.4.6\"]\n    end\n    \n    subgraph \"Build Environments\"\n        LOCAL[\"Local Build\u003cbr/\u003emkdocs serve\"]\n        RTD[\"ReadTheDocs Build\u003cbr/\u003eubuntu-22.04 + Python 3.12\"]\n    end\n    \n    subgraph \"Output\"\n        SITE[\"Static HTML Site\u003cbr/\u003esite/\"]\n        DEPLOY[\"ReadTheDocs Hosting\u003cbr/\u003eeoepca.readthedocs.io/projects/mlops/\"]\n    end\n    \n    MD --\u003e MKDOCS\n    CONFIG --\u003e MKDOCS\n    CSS --\u003e MKDOCS\n    IMG --\u003e MKDOCS\n    \n    REQ --\u003e MKDOCS\n    REQ --\u003e AUTOREFS\n    REQ --\u003e GLIGHTBOX\n    REQ --\u003e SWAGGER\n    REQ --\u003e PUBLISHER\n    \n    MKDOCS --\u003e THEME\n    MKDOCS --\u003e PLUGINS\n    MKDOCS --\u003e EXTS\n    \n    AUTOREFS --\u003e PLUGINS\n    GLIGHTBOX --\u003e PLUGINS\n    SWAGGER --\u003e PLUGINS\n    \n    THEME --\u003e SITE\n    PLUGINS --\u003e SITE\n    EXTS --\u003e SITE\n    \n    MKDOCS --\u003e LOCAL\n    MKDOCS --\u003e RTD\n    \n    LOCAL --\u003e SITE\n    RTD --\u003e DEPLOY\n```\n\n**Diagram: Documentation Build Pipeline**\n\nThe build process transforms Markdown source files into a fully-featured static website with navigation, search, syntax highlighting, and API documentation rendering.\n\n**Sources:** [mkdocs.yml:1-125](), [requirements.txt:1-7](), [.readthedocs.yaml:1-20]()\n\n---\n\n## MkDocs Configuration\n\nThe documentation system is configured through the `mkdocs.yml` file, which defines site metadata, navigation structure, theme settings, plugins, and Markdown extensions.\n\n### Site Metadata\n\nThe site metadata defines the documentation identity and repository links:\n\n| Configuration Key | Value | Purpose |\n|------------------|-------|---------|\n| `site_name` | EOEPCA MLOps Building Block | Documentation site title |\n| `site_url` | https://eoepca.readthedocs.io/projects/mlops/en/latest/ | Canonical URL |\n| `repo_url` | https://github.com/EOEPCA/document-mlops/ | Source repository link |\n| `edit_uri` | edit/main/docs/ | Path for \"Edit this page\" links |\n\n**Sources:** [mkdocs.yml:1-4]()\n\n### Navigation Structure\n\nThe navigation hierarchy is defined in the `nav` section, organizing content into logical sections:\n\n```mermaid\ngraph TB\n    ROOT[\"EOEPCA Documentation\u003cbr/\u003e(External Link)\"]\n    MLOPS[\"MLOps Section\"]\n    \n    INDEX[\"index.md\u003cbr/\u003eOverview\"]\n    \n    DESIGN[\"Design\"]\n    ARCH[\"design/architecture.md\"]\n    REQ[\"design/requirements.md\"]\n    UC[\"design/use-cases.md\"]\n    SCENARIOS[\"Scenarios\"]\n    MT[\"design/scenarios/model-training.md\"]\n    FE[\"design/scenarios/flood-example.md\"]\n    \n    ADMIN[\"Administration\"]\n    DEPLOY[\"Deployment Guide\"]\n    DEPINTRO[\"admin/deployment-guide/intro.md\"]\n    COMPONENTS[\"Components\"]\n    GL[\"admin/deployment-guide/components/gitlab.md\"]\n    SH[\"admin/deployment-guide/components/sharinghub.md\"]\n    MLF[\"admin/deployment-guide/components/mlflow-sharinghub.md\"]\n    CONFIG[\"admin/configuration.md\"]\n    MAINT[\"admin/maintenance.md\"]\n    \n    USAGE[\"Usage\"]\n    TUT[\"usage/tutorials.md\"]\n    HOWTO[\"How-to\"]\n    DSWH[\"usage/howto/dataset_with_workspace.md\"]\n    \n    API[\"API\"]\n    SPEC[\"api/endpoint-specification.md\"]\n    APIUSE[\"api/usage.md\"]\n    \n    ROOT --\u003e MLOPS\n    MLOPS --\u003e INDEX\n    MLOPS --\u003e DESIGN\n    DESIGN --\u003e ARCH\n    DESIGN --\u003e REQ\n    DESIGN --\u003e UC\n    DESIGN --\u003e SCENARIOS\n    SCENARIOS --\u003e MT\n    SCENARIOS --\u003e FE\n    \n    MLOPS --\u003e ADMIN\n    ADMIN --\u003e DEPLOY\n    DEPLOY --\u003e DEPINTRO\n    DEPLOY --\u003e COMPONENTS\n    COMPONENTS --\u003e GL\n    COMPONENTS --\u003e SH\n    COMPONENTS --\u003e MLF\n    ADMIN --\u003e CONFIG\n    ADMIN --\u003e MAINT\n    \n    MLOPS --\u003e USAGE\n    USAGE --\u003e TUT\n    USAGE --\u003e HOWTO\n    HOWTO --\u003e DSWH\n    \n    MLOPS --\u003e API\n    API --\u003e SPEC\n    API --\u003e APIUSE\n```\n\n**Diagram: Documentation Navigation Hierarchy**\n\nThe navigation structure defines four main sections: **Design** (architecture and use cases), **Administration** (deployment and configuration), **Usage** (tutorials and how-to guides), and **API** (reference documentation).\n\n**Sources:** [mkdocs.yml:6-32]()\n\n---\n\n## Material Theme Configuration\n\nThe documentation uses the **Material for MkDocs** theme with extensive feature customization.\n\n### Theme Settings\n\n```yaml\ntheme:\n  name: material\n  logo: img/favicon.ico\n  favicon: img/favicon.ico\n  navigation_depth: 4\n```\n\n**Sources:** [mkdocs.yml:41-45]()\n\n### Enabled Features\n\nThe Material theme features are organized into three categories:\n\n| Feature Category | Enabled Features | Purpose |\n|-----------------|------------------|---------|\n| **Navigation** | `navigation.footer`, `navigation.instant`, `navigation.tracking`, `navigation.tabs`, `navigation.tabs.sticky`, `navigation.sections`, `navigation.top` | Enhanced navigation with sticky tabs, instant loading, URL tracking, and back-to-top button |\n| **Content** | `content.code.copy`, `content.action.edit` | Copy buttons for code blocks and edit page links |\n| **Search** | `search.highlight`, `search.share`, `search.suggest` | Enhanced search with highlighting, sharing, and suggestions |\n\n**Sources:** [mkdocs.yml:50-67]()\n\n### Color Scheme\n\nThe theme supports three color schemes with automatic detection:\n\n```yaml\npalette:\n  - media: \"(prefers-color-scheme)\"\n    toggle:\n      icon: material/brightness-auto\n      name: Switch to light mode\n  - media: \"(prefers-color-scheme: light)\"\n    scheme: default\n  - media: \"(prefers-color-scheme: dark)\"\n    scheme: slate\n```\n\nUsers can toggle between light mode (`default`), dark mode (`slate`), and automatic system preference detection.\n\n**Sources:** [mkdocs.yml:68-82]()\n\n### Custom Styling\n\nCustom CSS is loaded via `extra_css` to apply EOEPCA-specific branding:\n\n```yaml\nextra_css:\n  - css/eoepca.css\n```\n\n**Sources:** [mkdocs.yml:84-85]()\n\n---\n\n## Plugins and Extensions\n\nThe documentation system uses several MkDocs plugins to extend functionality.\n\n### MkDocs Plugins\n\n```mermaid\ngraph LR\n    subgraph \"Plugin Ecosystem\"\n        AUTOREFS[\"autorefs\u003cbr/\u003eCross-references\"]\n        GLIGHTBOX[\"glightbox\u003cbr/\u003eImage Lightbox\"]\n        SEARCH[\"search\u003cbr/\u003eSite Search\"]\n        SWAGGER[\"swagger-ui-tag\u003cbr/\u003eOpenAPI Rendering\"]\n    end\n    \n    subgraph \"Plugin Functions\"\n        XREF[\"Automatic link resolution\u003cbr/\u003ebetween pages\"]\n        IMGPOP[\"Click-to-enlarge\u003cbr/\u003eimage popups\"]\n        INDEXING[\"Full-text search\u003cbr/\u003eindexing\"]\n        APIRENDER[\"Interactive API\u003cbr/\u003edocumentation\"]\n    end\n    \n    AUTOREFS --\u003e XREF\n    GLIGHTBOX --\u003e IMGPOP\n    SEARCH --\u003e INDEXING\n    SWAGGER --\u003e APIRENDER\n```\n\n**Diagram: Plugin Functions**\n\n| Plugin | Version | Purpose |\n|--------|---------|---------|\n| `autorefs` | 1.4.1 | Automatic cross-reference resolution between documentation pages |\n| `glightbox` | 0.4.0 | Image lightbox for viewing images in popups |\n| `search` | Built-in | Full-text search functionality |\n| `swagger-ui-tag` | 0.6.11 | Renders OpenAPI specifications as interactive Swagger UI |\n\n**Sources:** [mkdocs.yml:87-100](), [requirements.txt:3-6]()\n\n### Markdown Extensions\n\nThe documentation supports extensive Markdown extensions for enhanced content authoring:\n\n#### Document Structure Extensions\n\n```yaml\nmarkdown_extensions:\n  - tables              # Markdown tables\n  - toc:                # Table of contents\n      permalink: \n      toc_depth: 4\n  - smarty              # Smart quotes and dashes\n  - sane_lists          # Better list handling\n```\n\n**Sources:** [mkdocs.yml:101-107]()\n\n#### Content Enhancement Extensions\n\n```yaml\nmarkdown_extensions:\n  - admonition          # Callout blocks\n  - pymdownx.details    # Collapsible sections\n  - pymdownx.superfences # Nested code blocks and diagrams\n  - abbr                # Abbreviation definitions\n  - attr_list           # HTML attributes in Markdown\n  - md_in_html          # Markdown inside HTML blocks\n```\n\n**Sources:** [mkdocs.yml:108-118]()\n\n#### Code Highlighting\n\nThe `pymdownx.highlight` extension provides syntax highlighting with additional features:\n\n```yaml\npymdownx.highlight:\n  anchor_linenums: true       # Linkable line numbers\n  line_spans: __span          # Line-level styling support\n  pygments_lang_class: true   # Language-specific CSS classes\n```\n\n**Sources:** [mkdocs.yml:111-114]()\n\n#### Emoji Support\n\n```yaml\npymdownx.emoji:\n  emoji_index: !!python/name:material.extensions.emoji.twemoji\n  emoji_generator: !!python/name:material.extensions.emoji.to_svg\n```\n\nEmoji are rendered using Twemoji icons as inline SVG for consistent cross-platform appearance.\n\n**Sources:** [mkdocs.yml:119-121]()\n\n#### Snippets and Abbreviations\n\n```yaml\npymdownx.snippets:\n  auto_append:\n    - includes/abbreviations.md\n```\n\nThe snippets extension automatically appends `includes/abbreviations.md` to every page, providing consistent abbreviation definitions across the documentation.\n\n**Sources:** [mkdocs.yml:122-124]()\n\n---\n\n## Python Dependencies\n\nThe documentation build requires specific Python packages defined in `requirements.txt`:\n\n| Package | Version | Purpose |\n|---------|---------|---------|\n| `mkdocs` | 1.6.1 | Core static site generator |\n| `mkdocs-material` | 9.6.8 | Material Design theme |\n| `mkdocs-autorefs` | 1.4.1 | Automatic reference linking |\n| `mkdocs-publisher` | 1.4.6 | Publishing utilities |\n| `mkdocs-glightbox` | 0.4.0 | Image lightbox functionality |\n| `mkdocs-swagger-ui-tag` | 0.6.11 | OpenAPI/Swagger UI integration |\n\n**Sources:** [requirements.txt:1-7]()\n\n---\n\n## ReadTheDocs Integration\n\nThe documentation is hosted on ReadTheDocs and automatically built using the configuration in `.readthedocs.yaml`.\n\n### Build Configuration\n\n```yaml\nversion: 2\n\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.12\"\n\nmkdocs:\n  configuration: mkdocs.yml\n\npython:\n  install:\n  - requirements: requirements.txt\n```\n\n**Sources:** [.readthedocs.yaml:1-20]()\n\n### Build Process\n\n```mermaid\ngraph LR\n    subgraph \"ReadTheDocs Build Pipeline\"\n        TRIGGER[\"Git Push\u003cbr/\u003eto Repository\"]\n        WEBHOOK[\"ReadTheDocs\u003cbr/\u003eWebhook\"]\n        CLONE[\"Clone Repository\u003cbr/\u003eubuntu-22.04\"]\n        PYINSTALL[\"Install Python 3.12\u003cbr/\u003e+ requirements.txt\"]\n        MKDOCSBUILD[\"Run mkdocs build\u003cbr/\u003ewith mkdocs.yml\"]\n        DEPLOY[\"Deploy to\u003cbr/\u003eeoepca.readthedocs.io\"]\n    end\n    \n    TRIGGER --\u003e WEBHOOK\n    WEBHOOK --\u003e CLONE\n    CLONE --\u003e PYINSTALL\n    PYINSTALL --\u003e MKDOCSBUILD\n    MKDOCSBUILD --\u003e DEPLOY\n```\n\n**Diagram: ReadTheDocs Build Pipeline**\n\nThe build environment uses:\n- **OS**: Ubuntu 22.04\n- **Python**: 3.12\n- **Configuration**: `mkdocs.yml`\n- **Dependencies**: Installed from `requirements.txt`\n\n**Sources:** [.readthedocs.yaml:8-19]()\n\n---\n\n## Local Development\n\n### Building Locally\n\nTo build and serve the documentation locally:\n\n```bash\n# Install dependencies\npip install -r requirements.txt\n\n# Serve with live reload\nmkdocs serve\n\n# Build static site\nmkdocs build\n```\n\nThe `mkdocs serve` command starts a development server at `http://127.0.0.1:8000` with automatic reloading when source files change.\n\n### File Organization\n\n```\ndocument-mlops/\n mkdocs.yml              # Main configuration\n requirements.txt        # Python dependencies\n .readthedocs.yaml      # ReadTheDocs config\n docs/                  # Documentation source\n    index.md\n    design/\n    admin/\n    usage/\n    api/\n    css/\n       eoepca.css     # Custom styles\n    img/\n        favicon.ico\n site/                  # Generated output (gitignored)\n```\n\nThe `site/` directory is excluded from version control via `.gitignore`.\n\n**Sources:** [.gitignore:1-3]()\n\n---\n\n## Footer and Social Links\n\nThe documentation includes footer links to the EOEPCA GitHub organization:\n\n```yaml\nextra:\n  social:\n    - icon: fontawesome/brands/github\n      link: \"https://github.com/EOEPCA\"\n      name: EOEPCA\n```\n\n**Sources:** [mkdocs.yml:34-39]()\n\n---\n\n## Summary\n\nThe EOEPCA MLOps documentation system is built on MkDocs 1.6.1 with the Material theme 9.6.8, providing a modern, feature-rich documentation experience. The system supports:\n\n- **Automatic builds** via ReadTheDocs on every commit\n- **Interactive API documentation** with Swagger UI integration\n- **Enhanced navigation** with tabs, search, and cross-references\n- **Code syntax highlighting** with copy buttons\n- **Light/dark theme** with automatic system preference detection\n- **Mermaid diagrams** via pymdownx.superfences\n- **Responsive design** optimized for mobile and desktop\n\nAll configuration is centralized in `mkdocs.yml`, dependencies are pinned in `requirements.txt`, and ReadTheDocs build settings are defined in `.readthedocs.yaml`."])</script><script>self.__next_f.push([1,"5:[\"$\",\"$L15\",null,{\"repoName\":\"EOEPCA/document-mlops\",\"hasConfig\":false,\"canSteer\":true,\"children\":[\"$\",\"$L16\",null,{\"wiki\":{\"metadata\":{\"repo_name\":\"EOEPCA/document-mlops\",\"commit_hash\":\"35fba4e4\",\"generated_at\":\"2026-01-13T11:20:20.366354\",\"config\":null,\"config_source\":\"none\"},\"pages\":[{\"page_plan\":{\"id\":\"1\",\"title\":\"Overview\"},\"content\":\"$17\"},{\"page_plan\":{\"id\":\"2\",\"title\":\"Architecture\"},\"content\":\"$18\"},{\"page_plan\":{\"id\":\"2.1\",\"title\":\"Requirements\"},\"content\":\"$19\"},{\"page_plan\":{\"id\":\"2.2\",\"title\":\"Use Cases\"},\"content\":\"$1a\"},{\"page_plan\":{\"id\":\"3\",\"title\":\"Core Components\"},\"content\":\"$1b\"},{\"page_plan\":{\"id\":\"3.1\",\"title\":\"GitLab\"},\"content\":\"$1c\"},{\"page_plan\":{\"id\":\"3.2\",\"title\":\"SharingHub\"},\"content\":\"$1d\"},{\"page_plan\":{\"id\":\"3.3\",\"title\":\"MLflow SharingHub\"},\"content\":\"$1e\"},{\"page_plan\":{\"id\":\"4\",\"title\":\"Workflows and Scenarios\"},\"content\":\"$1f\"},{\"page_plan\":{\"id\":\"4.1\",\"title\":\"Model Training Workflow\"},\"content\":\"$20\"},{\"page_plan\":{\"id\":\"4.2\",\"title\":\"Dataset Management\"},\"content\":\"$21\"},{\"page_plan\":{\"id\":\"4.3\",\"title\":\"Flood Detection Example\"},\"content\":\"$22\"},{\"page_plan\":{\"id\":\"5\",\"title\":\"Deployment Guide\"},\"content\":\"$23\"},{\"page_plan\":{\"id\":\"5.1\",\"title\":\"Prerequisites and Architecture\"},\"content\":\"$24\"},{\"page_plan\":{\"id\":\"5.2\",\"title\":\"GitLab Deployment\"},\"content\":\"$25\"},{\"page_plan\":{\"id\":\"5.3\",\"title\":\"SharingHub Deployment\"},\"content\":\"$26\"},{\"page_plan\":{\"id\":\"5.4\",\"title\":\"MLflow SharingHub Deployment\"},\"content\":\"$27\"},{\"page_plan\":{\"id\":\"6\",\"title\":\"Configuration Reference\"},\"content\":\"$28\"},{\"page_plan\":{\"id\":\"6.1\",\"title\":\"SharingHub Configuration\"},\"content\":\"$29\"},{\"page_plan\":{\"id\":\"6.2\",\"title\":\"MLflow SharingHub Configuration\"},\"content\":\"$2a\"},{\"page_plan\":{\"id\":\"7\",\"title\":\"API Reference\"},\"content\":\"$2b\"},{\"page_plan\":{\"id\":\"7.1\",\"title\":\"STAC API Specification\"},\"content\":\"$2c\"},{\"page_plan\":{\"id\":\"7.2\",\"title\":\"Using the STAC API\"},\"content\":\"$2d\"},{\"page_plan\":{\"id\":\"8\",\"title\":\"Operations and Maintenance\"},\"content\":\"$2e\"},{\"page_plan\":{\"id\":\"8.1\",\"title\":\"Maintenance Guidelines\"},\"content\":\"$2f\"},{\"page_plan\":{\"id\":\"9\",\"title\":\"Documentation System\"},\"content\":\"$30\"}]},\"children\":\"$L31\"}]}]\n"])</script><script>self.__next_f.push([1,"6:[[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"TechArticle\\\",\\\"headline\\\":\\\"Overview\\\",\\\"description\\\":\\\"This document provides an overview of the EOEPCA MLOps Building Block, introducing its purpose, core components, and high-level capabilities. It is intended for technical audiences seeking to understa\\\",\\\"image\\\":\\\"https://deepwiki.com/EOEPCA/document-mlops/og-image.png\\\",\\\"datePublished\\\":\\\"2026-01-13T11:20:20.366354\\\",\\\"dateModified\\\":\\\"2026-01-13T11:20:20.366354\\\",\\\"author\\\":{\\\"@type\\\":\\\"Organization\\\",\\\"name\\\":\\\"DeepWiki\\\",\\\"url\\\":\\\"https://deepwiki.com\\\"},\\\"publisher\\\":{\\\"@type\\\":\\\"Organization\\\",\\\"name\\\":\\\"DeepWiki\\\",\\\"logo\\\":{\\\"@type\\\":\\\"ImageObject\\\",\\\"url\\\":\\\"https://deepwiki.com/icon.png\\\"}},\\\"mainEntityOfPage\\\":{\\\"@type\\\":\\\"WebPage\\\",\\\"@id\\\":\\\"https://deepwiki.com/EOEPCA/document-mlops\\\"}}\"}}],[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]\n"])</script><script>self.__next_f.push([1,"e:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"EOEPCA/document-mlops | DeepWiki\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"This document provides an overview of the EOEPCA MLOps Building Block, introducing its purpose, core components, and high-level capabilities. It is intended for technical audiences seeking to understa\"}],[\"$\",\"meta\",\"2\",{\"name\":\"keywords\",\"content\":\"EOEPCA/document-mlops,EOEPCA,document-mlops,documentation,wiki,codebase,AI documentation,Devin,Overview\"}],[\"$\",\"link\",\"3\",{\"rel\":\"canonical\",\"href\":\"https://deepwiki.com/EOEPCA/document-mlops\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:title\",\"content\":\"EOEPCA/document-mlops | DeepWiki\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:description\",\"content\":\"This document provides an overview of the EOEPCA MLOps Building Block, introducing its purpose, core components, and high-level capabilities. It is intended for technical audiences seeking to understa\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:url\",\"content\":\"https://deepwiki.com/EOEPCA/document-mlops\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:site_name\",\"content\":\"DeepWiki\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:image\",\"content\":\"https://deepwiki.com/EOEPCA/document-mlops/og-image.png?page=1\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"10\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:site\",\"content\":\"@cognition\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:creator\",\"content\":\"@cognition\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:title\",\"content\":\"EOEPCA/document-mlops | DeepWiki\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:description\",\"content\":\"This document provides an overview of the EOEPCA MLOps Building Block, introducing its purpose, core components, and high-level capabilities. It is intended for technical audiences seeking to understa\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:image\",\"content\":\"https://deepwiki.com/EOEPCA/document-mlops/og-image.png?page=1\"}],[\"$\",\"link\",\"16\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"48x48\"}],[\"$\",\"link\",\"17\",{\"rel\":\"icon\",\"href\":\"/icon.png?1ee4c6a68a73a205\",\"type\":\"image/png\",\"sizes\":\"48x48\"}],[\"$\",\"link\",\"18\",{\"rel\":\"apple-touch-icon\",\"href\":\"/apple-icon.png?a4f658907db0ab87\",\"type\":\"image/png\",\"sizes\":\"180x180\"}],[\"$\",\"$L32\",\"19\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"13:\"$e:metadata\"\n"])</script><script>self.__next_f.push([1,"31:[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]\n"])</script></body></html>